{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from functools import reduce\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from datetime import datetime, timedelta\n",
    "from utils import format_number\n",
    "from IPython.display import display  # So that display is recognized in .py files\n",
    "\n",
    "from config import LAST_N_DAYS, COL_NAMES_TO_INCLUDE\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "# Verify that our path is right\n",
    "if \"op_rewards_tracking\" in pwd:\n",
    "    prepend = \"\"\n",
    "else:\n",
    "    prepend = \"op_rewards_tracking/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_source(source_string):\n",
    "    source_list = source_string.split(\"-\")\n",
    "    if len(source_list) > 1:\n",
    "        return source_list[\n",
    "            1\n",
    "        ].strip()  # strip() is used to remove any leading/trailing spaces\n",
    "    else:\n",
    "        return source_string.strip()\n",
    "\n",
    "\n",
    "def cleanup_string(source_string):\n",
    "    return str(source_string).replace(\" \", \"\").lower()\n",
    "\n",
    "\n",
    "def remove_brackets(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def merge_dfs(key=\"app_name_join\", cols=COL_NAMES_TO_INCLUDE, **dfs):\n",
    "    df_combined = reduce(\n",
    "        lambda left, right: pd.merge(left, right, on=key, how=\"left\"), dfs.values()\n",
    "    )\n",
    "    return df_combined[cols]\n",
    "\n",
    "\n",
    "def calculate_metrics(df, op=\"op_deployed\"):\n",
    "    inc_cols = df.filter(like=\"incremental_\").columns\n",
    "    inc_cols = [col for col in inc_cols if \"per_op\" not in col]\n",
    "    # df = df.assign(**{f'incremental_{col.split(\"_\")[1]}_annualized_per_op': df[col] * 365 / df[\"net_op_deployed\"] for col in inc_cols})\n",
    "    df = df.assign(\n",
    "        **{\n",
    "            f'{col.replace(\"_per_day\", \"\")}_annualized_per_op': df[col] * 365 / df[op]\n",
    "            for col in inc_cols\n",
    "        }\n",
    "    )\n",
    "    df[\"net_tvl_per_op\"] = df[\"cumul_last_price_net_dollar_flow\"] / df[op]\n",
    "    df[\"net_tvl_per_op_during\"] = (\n",
    "        df[\"cumul_last_price_net_dollar_flow_at_program_end\"] / df[op]\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incentive Program Summary\n",
    "Status of programs live, completed and to be announced by season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# create app_name_join, coalesce with app name override map, app name and remove any space\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_info[\u001b[39m\"\u001b[39m\u001b[39mapp_name_join\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_info[\u001b[39m\"\u001b[39m\u001b[39mApp Name Map Override\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfillna(df_info[\u001b[39m\"\u001b[39m\u001b[39mApp Name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m df_info[\u001b[39m\"\u001b[39m\u001b[39mapp_name_join\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_info[\u001b[39m\"\u001b[39;49m\u001b[39mapp_name_join\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(cleanup_string)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mcleanup_string\u001b[0;34m(source_string)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcleanup_string\u001b[39m(source_string):\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m source_string\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mlower()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "df_info = pd.read_csv(\"inputs/\" + \"op_incentive_program_info\" + \".csv\")\n",
    "\n",
    "# convert to datetime\n",
    "df_info[\"start_date\"] = pd.to_datetime(\n",
    "    df_info[\"Announced On\"].fillna(df_info[\"Start Date\"])\n",
    ")\n",
    "df_info[\"end_date\"] = pd.to_datetime(df_info[\"End Date\"])\n",
    "\n",
    "# convert program status into ordered categorical type\n",
    "cat_size_order = CategoricalDtype(\n",
    "    [\"Live â€ŽðŸ”¥\", \"Coming soon â€Žâ³\", \"Completed\"], ordered=True\n",
    ")\n",
    "df_info[\"Status\"] = df_info[\"Status\"].astype(cat_size_order)\n",
    "\n",
    "# create app_name_join, coalesce with app name override map, app name and remove any space\n",
    "df_info[\"app_name_join\"] = df_info[\"App Name Map Override\"].fillna(df_info[\"App Name\"])\n",
    "df_info[\"app_name_join\"] = df_info[\"app_name_join\"].apply(cleanup_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"GovFund\", \"GovFund Growth Experiments\", \"All Programs\"]:\n",
    "    # Assign the filters\n",
    "    if i == \"GovFund\":\n",
    "        filter_name = \" - GovFund Only\"\n",
    "        df_choice = df_info[df_info[\"Source\"] != \"Partner Fund\"].copy()\n",
    "    elif i == \"GovFund Growth Experiments\":\n",
    "        filter_name = \" - GovFund Growth Exp.\"\n",
    "        df_choice = df_info[df_info[\"Source\"] != \"Partner Fund\"].copy()\n",
    "        df_choice = df_choice[\n",
    "            df_choice[\"Incentive / Growth Program Included?\"] == \"Yes\"\n",
    "        ]\n",
    "    else:\n",
    "        filter_name = \"\"\n",
    "        df_choice = df_info.copy()\n",
    "\n",
    "    # clean up for columns needed\n",
    "    df_choice = df_choice[\n",
    "        [\n",
    "            \"Source\",\n",
    "            \"Status\",\n",
    "            \"# OP Allocated\",\n",
    "            \"App Name\",\n",
    "            \"start_date\",\n",
    "            \"end_date\",\n",
    "            \"app_name_join\",\n",
    "            \"Incentive / Growth Program Included?\",\n",
    "        ]\n",
    "    ]\n",
    "    summary = pd.pivot_table(\n",
    "        df_choice,\n",
    "        values=[\"# OP Allocated\", \"App Name\"],\n",
    "        index=[\"Status\", \"Source\"],\n",
    "        aggfunc={\"# OP Allocated\": \"sum\", \"App Name\": \"count\"},\n",
    "    )\n",
    "\n",
    "    subtotal_name = \"Subtotal\" + filter_name\n",
    "    # calculate subtotals on program status\n",
    "    result = pd.concat(\n",
    "        [\n",
    "            summary,\n",
    "            summary.groupby(level=0)\n",
    "            .sum()\n",
    "            .assign(item_name=subtotal_name)\n",
    "            .set_index(\"item_name\", append=True),\n",
    "        ]\n",
    "    ).sort_index(level=[0, 1])\n",
    "    result = result.sort_index(level=[0, 1], ascending=[True, False])\n",
    "\n",
    "    # add grand total to summary\n",
    "    result.loc[(\"Grand Total\"), \"# OP Allocated\"] = summary[\"# OP Allocated\"].sum()\n",
    "    result.loc[(\"Grand Total\"), \"App Name\"] = summary[\"App Name\"].sum()\n",
    "\n",
    "    # cleanup display\n",
    "    result[\"# Programs\"] = result[\"App Name\"].astype(int)\n",
    "    result[\"# OP Allocated (M)\"] = result[\"# OP Allocated\"].apply(format_number)\n",
    "\n",
    "    # calculate percentage of total\n",
    "    result.loc[(slice(None), subtotal_name), \"# OP Allocated\"] / summary[\n",
    "        \"# OP Allocated\"\n",
    "    ].sum()\n",
    "    result[\"% OP Allocated\"] = (\n",
    "        round(\n",
    "            result.loc[(slice(None), subtotal_name), \"# OP Allocated\"]\n",
    "            / summary[\"# OP Allocated\"].sum()\n",
    "            * 100\n",
    "        )\n",
    "        .astype(str)\n",
    "        .replace(\"\\.0\", \"\", regex=True)\n",
    "        + \"%\"\n",
    "    )\n",
    "    result[\"% OP Allocated\"].fillna(\"-\", inplace=True)\n",
    "\n",
    "    result = result.replace((0, \"0.0M\", \"0.0\"), \"-\")\n",
    "    print(i)\n",
    "    display(result.drop(columns=[\"# OP Allocated\", \"App Name\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display new programs in last 30 days\n",
    "df_new_programs = df_choice[\n",
    "    df_choice[\"start_date\"] > pd.Timestamp(\"today\") - timedelta(days=LAST_N_DAYS)\n",
    "].sort_values(by=\"start_date\", ascending=False)\n",
    "if not df_new_programs.empty:\n",
    "    df_new_programs[\"end_date\"].fillna(\"-\", inplace=True)\n",
    "    display(df_new_programs.drop(\"app_name_join\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display completed programs in last 30 days\n",
    "df_completed = df_choice[\n",
    "    (df_choice[\"Status\"] == \"Completed\")\n",
    "    & (df_choice[\"end_date\"] > pd.Timestamp(\"today\") - timedelta(days=LAST_N_DAYS))\n",
    "].sort_values(by=\"start_date\", ascending=False)\n",
    "if not df_completed.empty:\n",
    "    display(df_completed.drop(\"app_name_join\", axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage and TVL Attribution\n",
    "To combine all sources of data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in input data\n",
    "df_usage = pd.read_csv(\"csv_outputs/\" + \"dune_op_program_performance_summary\" + \".csv\")\n",
    "# convert to datetime\n",
    "df_usage[\"start_date\"] = pd.to_datetime(df_usage[\"start_date\"])\n",
    "df_usage[\"end_date\"] = pd.to_datetime(df_usage[\"end_date\"])\n",
    "\n",
    "df_usage[\"app_name_join\"] = df_usage[\"app_name_a\"].apply(cleanup_string)\n",
    "df_usage[\"duration_days\"] = (\n",
    "    df_usage[\"end_date\"].fillna(datetime.now()) - df_usage[\"start_date\"]\n",
    ").dt.days + 1  # if start and end date is the same, add 1 to include that day\n",
    "\n",
    "# drop op_deployed from df_usage to avoid duplicates\n",
    "df_usage = df_usage.drop(columns=[\"op_deployed\"])\n",
    "\n",
    "df_tvl = pd.read_csv(\"csv_outputs/op_summer_latest_stats.csv\")\n",
    "df_tvl = df_tvl[df_tvl[\"include_in_summary\"] == 1]\n",
    "df_tvl[\"app_name_join\"] = df_tvl[\"parent_protocol\"].apply(cleanup_string)\n",
    "\n",
    "df_op_distribution = pd.read_csv(\"csv_outputs/dune_op_distribution_type.csv\")\n",
    "df_op_distribution[\"net_op_deployed\"] = (\n",
    "    df_op_distribution[\"op_deployed\"] - df_op_distribution[\"op_from_other_projects\"]\n",
    ").astype(float)\n",
    "df_op_distribution[\"app_name_join\"] = df_op_distribution[\"project_name\"].apply(\n",
    "    cleanup_string\n",
    ")\n",
    "\n",
    "# filter to incentive / growth programs only\n",
    "condition = (df_choice[\"Incentive / Growth Program Included?\"] == \"Yes\") & (\n",
    "    df_choice[\"start_date\"].notnull()\n",
    ")\n",
    "df_choice = df_choice[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_summarize = {\n",
    "    # df | groupby | column to summarize\n",
    "    \"df_choice\": (\"app_name_join\", \"# OP Allocated\"),\n",
    "    \"df_tvl\": (\n",
    "        \"app_name_join\",\n",
    "        [\n",
    "            \"cumul_last_price_net_dollar_flow\",\n",
    "            \"cumul_last_price_net_dollar_flow_at_program_end\",\n",
    "        ],\n",
    "    ),\n",
    "    \"df_op_distribution\": (\"app_name_join\", [\"op_deployed\", \"net_op_deployed\"]),\n",
    "}\n",
    "\n",
    "summary_dfs = {}  # create an empty dictionary to store the resulting DataFrames\n",
    "\n",
    "for df_name, (groupby_col, sum_cols) in df_to_summarize.items():\n",
    "    df = globals()[df_name]  # assuming the dataframes are stored as global variables\n",
    "    if isinstance(sum_cols, str):  # if only one column to sum is specified\n",
    "        sum_cols = [sum_cols]\n",
    "    # groupby and sum the specified columns\n",
    "    grouped = df.groupby(groupby_col)[sum_cols].sum().reset_index()\n",
    "    # create a new variable with the summary DataFrame\n",
    "    first_word = groupby_col.split(\"_\")[0]\n",
    "    summary_df_name = f\"{df_name}_summary_{first_word}\"\n",
    "    summary_dfs[summary_df_name] = grouped\n",
    "\n",
    "# unpack summary_dfs into separate variables with the same names\n",
    "locals().update(summary_dfs)\n",
    "\n",
    "# access each summary DataFrame by its variable name\n",
    "# df_choice_summary_app\n",
    "# df_tvl_summary_app\n",
    "# df_op_distribution_summary_app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by app\n",
    "df_combined_app = merge_dfs(\n",
    "    df_usage=df_usage,\n",
    "    df_tvl_summary_app=df_tvl_summary_app,\n",
    "    df_choice_summary_app=df_choice_summary_app,\n",
    "    df_op_distribution_summary_app=df_op_distribution_summary_app,\n",
    ")\n",
    "\n",
    "# # if op_deployed higher than op allocated, set to op allocated value\n",
    "# mask = df_combined_app['op_deployed'] > df_combined_app['# OP Allocated']\n",
    "# df_combined_app.loc[mask, 'op_deployed'] = df_combined_app.loc[mask, '# OP Allocated']\n",
    "\n",
    "df_combined_app = df_combined_app.dropna(subset=[\"# OP Allocated\"])\n",
    "\n",
    "# calculate metrics\n",
    "result_app = calculate_metrics(\n",
    "    df_combined_app, op=\"op_deployed\"\n",
    ")  # by app use op_deployed\n",
    "# display(result_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by tvl\n",
    "cols = [\n",
    "    \"app_name_a\",\n",
    "    \"# OP Allocated\",\n",
    "    \"op_deployed\",\n",
    "    \"cumul_last_price_net_dollar_flow\",\n",
    "    \"net_tvl_per_op\",\n",
    "]\n",
    "display(\n",
    "    result_app[cols]\n",
    "    .sort_values(\"cumul_last_price_net_dollar_flow\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by txs\n",
    "txs_cols = [\n",
    "    \"app_name_a\",\n",
    "    \"# OP Allocated\",\n",
    "    \"op_deployed\",\n",
    "    \"incremental_txs_per_day\",\n",
    "    \"incremental_txs_annualized_per_op\",\n",
    "    \"incremental_txs_per_day_after\",\n",
    "    \"incremental_txs_after_annualized_per_op\",\n",
    "]\n",
    "\n",
    "# # result_app[txs_cols].to_csv('csv_outputs/transaction_stats_by_app.csv')\n",
    "\n",
    "display(\n",
    "    result_app[txs_cols]\n",
    "    .sort_values(\"incremental_txs_per_day\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "display(\n",
    "    result_app[txs_cols]\n",
    "    .sort_values(\"incremental_txs_after_annualized_per_op\", ascending=False)\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by gas\n",
    "gas_cols = [\n",
    "    \"app_name_a\",\n",
    "    \"# OP Allocated\",\n",
    "    \"op_deployed\",\n",
    "    \"incremental_gas_fee_eth_per_day\",\n",
    "    \"incremental_gas_fee_eth_annualized_per_op\",\n",
    "    \"incremental_gas_fee_eth_per_day_after\",\n",
    "    \"incremental_gas_fee_eth_after_annualized_per_op\",\n",
    "]\n",
    "\n",
    "result_app.loc[\n",
    "    :, result_app.columns.str.contains(\"annualized_per_op\")\n",
    "] = result_app.loc[:, result_app.columns.str.contains(\"annualized_per_op\")].applymap(\n",
    "    \"{:.4f}\".format\n",
    ")\n",
    "\n",
    "display(\n",
    "    result_app[gas_cols]\n",
    "    .sort_values(\"incremental_gas_fee_eth_per_day\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "display(\n",
    "    result_app[gas_cols]\n",
    "    .sort_values(\"incremental_gas_fee_eth_after_annualized_per_op\", ascending=False)\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Fund Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    \"# OP Allocated\": \"sum\",\n",
    "    \"net_op_deployed\": \"sum\",\n",
    "    # \"incremental_addr_per_day\": \"sum\",\n",
    "    \"incremental_txs_per_day\": \"sum\",\n",
    "    \"incremental_gas_fee_eth_per_day\": \"sum\",\n",
    "    \"incremental_txs_per_day_after\": \"sum\",\n",
    "    # \"incremental_addr_per_day_after\": \"sum\",\n",
    "    \"incremental_gas_fee_eth_per_day_after\": \"sum\",\n",
    "    \"cumul_last_price_net_dollar_flow\": \"sum\",\n",
    "    \"cumul_last_price_net_dollar_flow_at_program_end\": \"sum\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_app[\"op_source_length\"] = result_app[\"op_source\"].str.split(\",\").apply(len)\n",
    "result_app[\"op_source_map\"] = np.where(\n",
    "    result_app[\"op_source_length\"] > 1, [\"Multiple\"], result_app[\"op_source\"]\n",
    ")\n",
    "\n",
    "result_source = result_app.groupby(\"op_source_map\").agg(agg_dict)\n",
    "\n",
    "# calculate metrics\n",
    "result_source = calculate_metrics(\n",
    "    result_source, op=\"net_op_deployed\"\n",
    ")  # use net to avoid double counting\n",
    "result_source = result_source.reset_index()\n",
    "result_source[\"op_source_map\"] = result_source[\"op_source_map\"].apply(\n",
    "    lambda x: remove_brackets(x)\n",
    ")\n",
    "result_source.sort_values(\"op_source_map\").reset_index()\n",
    "\n",
    "display(result_source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to csv\n",
    "result_app.to_csv(\"csv_outputs/final_incentive_program_summary_by_app.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_benchmark(\n",
    "    df,\n",
    "    layout_settings,\n",
    "    x=\"incremental_txs_per_day\",\n",
    "    y=\"incremental_txs_annualized_per_op\",\n",
    "    size=\"op_deployed\",\n",
    "):\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        size=size,\n",
    "        hover_name=\"app_name_a\",\n",
    "        color=\"op_source_map\",\n",
    "    )\n",
    "\n",
    "    # calculate percentiles for incremental_txs_annualized_per_op\n",
    "    p25 = df[y].quantile(0.25)\n",
    "    p50 = df[y].quantile(0.50)\n",
    "    p75 = df[y].quantile(0.75)\n",
    "\n",
    "    x_range = [df[x].min(), df[x].max()]\n",
    "\n",
    "    # add vertical lines for percentiles\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_range, y=[p25, p25], mode=\"lines\", name=\"25th percentile\")\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_range, y=[p50, p50], mode=\"lines\", name=\"50th percentile\")\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=x_range, y=[p75, p75], mode=\"lines\", name=\"75th percentile\")\n",
    "    )\n",
    "\n",
    "    fig.update_layout(layout_settings)\n",
    "\n",
    "    fig.write_image(prepend + f\"img_outputs/benchmark/svg/{y}.svg\")\n",
    "    fig.write_image(prepend + f\"img_outputs/benchmark/png/{y}.png\")\n",
    "    fig.write_html(\n",
    "        prepend + f\"img_outputs/benchmark/html/{y}.html\", include_plotlyjs=\"cdn\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def cleanup_data(\n",
    "    df=result_app,\n",
    "    subset=[\n",
    "        \"op_deployed\",\n",
    "        \"incremental_txs_annualized_per_op\",\n",
    "        \"incremental_txs_per_day\",\n",
    "    ],\n",
    "    excl_partnerfund=False,\n",
    "):\n",
    "    df = result_app.dropna(subset=subset)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(\n",
    "        subset=subset\n",
    "    )  # remove rows with infinity values\n",
    "\n",
    "    if excl_partnerfund:\n",
    "        # drop anything with Partner Fund from df\n",
    "        df = df[~df[\"op_source\"].str.contains(\"Partner Fund\")]\n",
    "\n",
    "    df[subset] = df[subset].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_settings = {\n",
    "    \"title\": \"Incremental Txs Performance Benchmark (All Programs)<br><sup>Cutoff at Program End Date (Latest Date if still Live).</sup>\",\n",
    "    \"xaxis_title\": \"Incremental Transactions per Day\",\n",
    "    \"yaxis_title\": \"Annualized Incremental Transactions per OP\",\n",
    "    \"legend_title\": \"Op Source\",\n",
    "}\n",
    "\n",
    "df = cleanup_data()\n",
    "\n",
    "plot_benchmark(\n",
    "    df,\n",
    "    x=\"incremental_txs_per_day\",\n",
    "    y=\"incremental_txs_annualized_per_op\",\n",
    "    size=\"op_deployed\",\n",
    "    layout_settings=layout_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_settings = {\n",
    "    \"title\": \"Incremental Txs Performance Benchmark (Completed Programs)<br><sup>Cutoff at Program End Date + 30 days (Latest Date if not yet reached 30 days).</sup>\",\n",
    "    \"xaxis_title\": \"Incremental Transactions per Day\",\n",
    "    \"yaxis_title\": \"Annualized Incremental Transactions per OP\",\n",
    "    \"legend_title\": \"Op Source\",\n",
    "}\n",
    "\n",
    "df = cleanup_data(\n",
    "    subset=[\n",
    "        \"op_deployed\",\n",
    "        \"incremental_txs_per_day_after\",\n",
    "        \"incremental_txs_after_annualized_per_op\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "plot_benchmark(\n",
    "    df,\n",
    "    x=\"incremental_txs_per_day_after\",\n",
    "    y=\"incremental_txs_after_annualized_per_op\",\n",
    "    size=\"op_deployed\",\n",
    "    layout_settings=layout_settings,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVL Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_settings = {\n",
    "    \"title\": \"Incremental TVL Performance Benchmark (All Programs)<br><sup>Cutoff at Program End Date (Latest Date if still Live).</sup>\",\n",
    "    \"xaxis_title\": \"Incremental TVL\",\n",
    "    \"yaxis_title\": \"Incremental TVL per OP\",\n",
    "    \"legend_title\": \"Op Source\",\n",
    "}\n",
    "\n",
    "df = cleanup_data(\n",
    "    subset=[\n",
    "        \"op_deployed\",\n",
    "        \"net_tvl_per_op_during\",\n",
    "        \"cumul_last_price_net_dollar_flow_at_program_end\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_benchmark(\n",
    "    df,\n",
    "    x=\"cumul_last_price_net_dollar_flow_at_program_end\",\n",
    "    y=\"net_tvl_per_op_during\",\n",
    "    size=\"op_deployed\",\n",
    "    layout_settings=layout_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_settings = {\n",
    "    \"title\": \"Incremental TVL Performance Benchmark (Completed Programs) <br><sup>Cutoff at Program End Date + 30 days (Latest Date if not yet reached 30 days).</sup>\",\n",
    "    \"xaxis_title\": \"Incremental TVL\",\n",
    "    \"yaxis_title\": \"Incremental TVL per OP\",\n",
    "    \"legend_title\": \"Op Source\",\n",
    "}\n",
    "\n",
    "df = cleanup_data(\n",
    "    subset=[\n",
    "        \"op_deployed\",\n",
    "        \"net_tvl_per_op\",\n",
    "        \"cumul_last_price_net_dollar_flow\",\n",
    "        \"incremental_txs_per_day_after\",  # used for filtering completed programs only\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_benchmark(\n",
    "    df,\n",
    "    x=\"cumul_last_price_net_dollar_flow\",\n",
    "    y=\"net_tvl_per_op\",\n",
    "    size=\"op_deployed\",\n",
    "    layout_settings=layout_settings,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fee Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_settings = {\n",
    "    \"title\": \"Incremental ETH Fee Performance Benchmark (All Programs) <br><sup>Cutoff at Program End Date (Latest Date if still Live).</sup>\",\n",
    "    \"xaxis_title\": \"Incremental ETH Fee per Day\",\n",
    "    \"yaxis_title\": \"Annualized Incremental Fee per OP\",\n",
    "    \"legend_title\": \"Op Source\",\n",
    "}\n",
    "\n",
    "df = cleanup_data(\n",
    "    subset=[\n",
    "        \"op_deployed\",\n",
    "        \"incremental_gas_fee_eth_per_day\",\n",
    "        \"incremental_gas_fee_eth_annualized_per_op\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_benchmark(\n",
    "    df,\n",
    "    x=\"incremental_gas_fee_eth_per_day\",\n",
    "    y=\"incremental_gas_fee_eth_annualized_per_op\",\n",
    "    size=\"op_deployed\",\n",
    "    layout_settings=layout_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_settings = {\n",
    "    \"title\": \"Incremental ETH Fee Performance Benchmark (Completed Programs) <br><sup>Cutoff at Program End Date + 30 days (Latest Date if not yet reached 30 days).</sup>\",\n",
    "    \"xaxis_title\": \"Incremental ETH Fee per Day\",\n",
    "    \"yaxis_title\": \"Annualized Incremental Fee per OP\",\n",
    "    \"legend_title\": \"Op Source\",\n",
    "}\n",
    "\n",
    "df = cleanup_data(\n",
    "    subset=[\n",
    "        \"op_deployed\",\n",
    "        \"incremental_gas_fee_eth_per_day_after\",\n",
    "        \"incremental_gas_fee_eth_after_annualized_per_op\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_benchmark(\n",
    "    df,\n",
    "    x=\"incremental_gas_fee_eth_per_day_after\",\n",
    "    y=\"incremental_gas_fee_eth_after_annualized_per_op\",\n",
    "    size=\"op_deployed\",\n",
    "    layout_settings=layout_settings,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
