{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STILL WIP\n",
    "\n",
    "# # Read from:\n",
    "# Dune - OP Deployed by deployer address type\n",
    "# Defillama/Subgraphs - TVL Flows by Program\n",
    "# Notion - OP Budget by Program\n",
    "\n",
    "# Join these datasets together on program & associate anything else to the generalized programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from IPython.display import display #So that display is recognized in .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvl = pd.read_csv(\"csv_outputs/op_summer_latest_stats.csv\")\n",
    "distrib_df = pd.read_csv(\"csv_outputs/dune_op_distribution_type.csv\")\n",
    "program_df = pd.read_csv(\"inputs/op_incentive_program_info.csv\")\n",
    "app_df = pd.read_csv(\"csv_outputs/dune_usage_by_app.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter TVL DF\n",
    "tvl = tvl[tvl[\"include_in_summary\"] == 1]\n",
    "tvl[\"join_key\"] = tvl[\"top_level_name\"].str.replace(\n",
    "    \"*\", \"\"\n",
    ")  # tvl['app_name'] + ' - ' + tvl['top_level_name'].str.replace('*','')\n",
    "# display(tvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_token_columns = [\n",
    "    \"op_claimed\",\n",
    "    \"op_deployed\",\n",
    "    \"op_from_other_projects\",\n",
    "    \"op_to_other_projects\",\n",
    "    \"op_to_project\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Distributions for Mapping\n",
    "distrib_df[\"program_map\"] = np.where(\n",
    "    distrib_df[\"counterparty_type\"].isin(tvl[\"top_level_name\"]),\n",
    "    distrib_df[\"counterparty_type\"],\n",
    "    \"\",\n",
    ")\n",
    "group_cols = [\n",
    "    \"project_name\",\n",
    "    \"counterparty_label\",\n",
    "    \"counterparty_type\",\n",
    "    \"program_map\",\n",
    "] + op_token_columns\n",
    "\n",
    "sum_distrib_df = distrib_df[group_cols].groupby([\"project_name\", \"program_map\"]).sum()\n",
    "sum_distrib_df.reset_index(inplace=True)\n",
    "# Joins should maybe just be the program map OR from name, since Velo operated bribes for a while\n",
    "sum_distrib_df[\"join_key\"] = np.where(\n",
    "    sum_distrib_df[\"program_map\"] == \"\",\n",
    "    sum_distrib_df[\"project_name\"],\n",
    "    sum_distrib_df[\"program_map\"],\n",
    ")\n",
    "# sum_distrib_df['from_name'] + ' - ' \\\n",
    "#     + np.where(sum_distrib_df['program_map'] == '',sum_distrib_df['from_name'],sum_distrib_df['program_map'])\n",
    "\n",
    "# display(sum_distrib_df[sum_distrib_df['join_key'].str.contains('elodr')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase joinkeys\n",
    "tvl[\"join_key\"] = tvl[\"join_key\"].str.lower()\n",
    "sum_distrib_df[\"join_key\"] = sum_distrib_df[\"join_key\"].str.lower()\n",
    "#\n",
    "df = sum_distrib_df.merge(tvl, on=\"join_key\", how=\"outer\")\n",
    "# display(df[df['join_key'].str.contains('velodr')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overrides as needed\n",
    "def replace_program_names(df, overrides):\n",
    "    for program, program_override in overrides.items():\n",
    "        df.loc[df[\"join_key\"] == program, \"from_name\"] = program_override\n",
    "    return df\n",
    "\n",
    "\n",
    "# Overrides if needed\n",
    "overrides = {\n",
    "    \"old name\": \"new name\",\n",
    "}\n",
    "\n",
    "# Replace program names with overrides\n",
    "df = replace_program_names(df, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the aggregate app name field\n",
    "df[\"agg_app_name\"] = df[\"app_name\"].combine_first(df[\"project_name\"])\n",
    "df = df.fillna(0)  # Fill NA with 0\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now union back again\n",
    "\n",
    "data_cols = [\n",
    "    \"agg_app_name\",\n",
    "    \"top_level_name\",\n",
    "    \"program_name\",\n",
    "    \"num_op_override\",\n",
    "    \"period\",\n",
    "    \"op_source\",\n",
    "    \"start_date\",\n",
    "    \"end_date\",\n",
    "    \"cumul_net_dollar_flow_at_program_end\",\n",
    "    \"cumul_net_dollar_flow\",\n",
    "    \"cumul_last_price_net_dollar_flow_at_program_end\",\n",
    "    \"cumul_last_price_net_dollar_flow\",\n",
    "]\n",
    "select_cols = data_cols + op_token_columns\n",
    "\n",
    "group_cols = select_cols[:8]  # group by 1 to 8\n",
    "print(group_cols)\n",
    "\n",
    "# display(df[select_cols])\n",
    "\n",
    "sum_distrib_df = df[select_cols].groupby(group_cols).sum()\n",
    "sum_distrib_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rank by start_date of each program\n",
    "\n",
    "sum_distrib_df = sum_distrib_df.reset_index().rename(columns={\"index\": \"row_num\"})\n",
    "\n",
    "# replace 0s with '9999-12-31'\n",
    "sum_distrib_df[\"start_date\"] = np.where(\n",
    "    sum_distrib_df[\"start_date\"] == 0, \"9999-12-31\", sum_distrib_df[\"start_date\"]\n",
    ")\n",
    "# create a new column 'program_rank' based on the 'start_date' column\n",
    "sum_distrib_df = sum_distrib_df.sort_values([\"agg_app_name\", \"start_date\", \"row_num\"])\n",
    "sum_distrib_df[\"program_rank\"] = sum_distrib_df.groupby(\"agg_app_name\").cumcount() + 1\n",
    "\n",
    "sum_distrib_df = sum_distrib_df.sort_values(\n",
    "    by=[\"agg_app_name\", \"program_rank\"], ascending=[True, True]\n",
    ")\n",
    "# subtract all overridden values fromthe amount I have deployed\n",
    "\n",
    "# create a new column 'cumulative_num_op_override' that contains the cumulative sum of 'num_op_override' for each agg_app_name group\n",
    "sum_distrib_df[\"cumulative_num_op_override\"] = sum_distrib_df.groupby(\"agg_app_name\")[\n",
    "    \"num_op_override\"\n",
    "].cumsum()\n",
    "\n",
    "\n",
    "# create a new column 'op_deployed_net_override' that subtracts 'cumulative_num_op_override' from 'op_deployed'\n",
    "sum_distrib_df[\"op_deployed_net_override\"] = sum_distrib_df[\n",
    "    \"op_deployed\"\n",
    "] - sum_distrib_df.groupby(\"agg_app_name\")[\"cumulative_num_op_override\"].shift(\n",
    "    1\n",
    ").fillna(\n",
    "    0\n",
    ")\n",
    "# drop the 'cumulative_num_op_override' column\n",
    "# sum_distrib_df.drop('cumulative_num_op_override', axis=1, inplace=True)\n",
    "\n",
    "# replace '9999-12-31' with 0s\n",
    "sum_distrib_df[\"start_date\"] = np.where(\n",
    "    sum_distrib_df[\"start_date\"] == \"9999-12-31\", 0, sum_distrib_df[\"start_date\"]\n",
    ")\n",
    "\n",
    "# Drop Row Num\n",
    "sum_distrib_df.drop(\"row_num\", axis=1, inplace=True)\n",
    "# display(sum_distrib_df[sum_distrib_df['agg_app_name'].str.contains('rrakis')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the algorithmic overrides - where we want to redistirbute deployed OP across specific programs (i.e. Uniswap LM w/ Partners)\n",
    "# # replace 0s in 'num_op_override' with the corresponding value in 'op_deployed_net_override'\n",
    "sum_distrib_df[\"og_op_deployed\"] = sum_distrib_df[\"op_deployed\"]\n",
    "# Override # OP Deployed\n",
    "sum_distrib_df[\"op_deployed\"] = np.where(\n",
    "    (sum_distrib_df[\"num_op_override\"] == 0),\n",
    "    sum_distrib_df[\"op_deployed_net_override\"],\n",
    "    sum_distrib_df[\"num_op_override\"],\n",
    ")\n",
    "\n",
    "# Hardcode for Aave - Liquidity Mining since claims came straight from the FND wallet. This should be a one-time edge case\n",
    "sum_distrib_df[\"op_deployed\"] = np.where(\n",
    "    sum_distrib_df[\"top_level_name\"] == \"Aave - Liquidity Mining\",\n",
    "    5_000_000,\n",
    "    sum_distrib_df[\"op_deployed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Select all except the last 4 rows\n",
    "sum_distrib_df = sum_distrib_df.iloc[:, :-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest tvl metrics\n",
    "sum_distrib_df[\"cumul_last_price_net_dollar_flow_at_program_end_ended\"] = np.where(\n",
    "    sum_distrib_df[\"period\"] == \"Post-Program\",\n",
    "    sum_distrib_df[\"cumul_last_price_net_dollar_flow_at_program_end\"],\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "sum_distrib_df[\"cumul_last_price_net_dollar_flow_ended\"] = np.where(\n",
    "    sum_distrib_df[\"period\"] == \"Post-Program\",\n",
    "    sum_distrib_df[\"cumul_last_price_net_dollar_flow\"],\n",
    "    np.nan,\n",
    ")\n",
    "sum_distrib_df[\"net_flows_retention\"] = np.where(\n",
    "    sum_distrib_df[\"period\"] == \"Post-Program\",\n",
    "    sum_distrib_df[\"cumul_last_price_net_dollar_flow_ended\"]\n",
    "    / sum_distrib_df[\"cumul_last_price_net_dollar_flow_at_program_end_ended\"],\n",
    "    np.nan,\n",
    ")\n",
    "# If < 0 then make retention 0\n",
    "sum_distrib_df[\"net_flows_retention\"] = np.where(\n",
    "    sum_distrib_df[\"cumul_last_price_net_dollar_flow\"] < 0,\n",
    "    0,\n",
    "    sum_distrib_df[\"net_flows_retention\"],\n",
    ")\n",
    "\n",
    "# Live Programs\n",
    "\n",
    "sum_distrib_df[\"cumul_last_price_net_dollar_flow_at_program_end_live\"] = np.where(\n",
    "    sum_distrib_df[\"period\"] == \"During Program\",\n",
    "    sum_distrib_df[\"cumul_last_price_net_dollar_flow_at_program_end\"],\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "sum_distrib_df[\"cumul_last_price_net_dollar_flow_live\"] = np.where(\n",
    "    sum_distrib_df[\"period\"] == \"During Program\",\n",
    "    sum_distrib_df[\"cumul_last_price_net_dollar_flow\"],\n",
    "    np.nan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get App Name Mappings from Notion\n",
    "name_mappings = program_df[[\"App Name\", \"App Name Map Override\"]].drop_duplicates()\n",
    "name_mappings = name_mappings[~name_mappings[\"App Name Map Override\"].isna()]\n",
    "name_mappings = name_mappings.rename(columns={\"App Name\": \"agg_app_name\"})\n",
    "sum_distrib_df = sum_distrib_df.merge(name_mappings, on=\"agg_app_name\", how=\"left\")\n",
    "sum_distrib_df[\"App Name Map\"] = (\n",
    "    sum_distrib_df[\"App Name Map Override\"].combine_first(\n",
    "        sum_distrib_df[\"agg_app_name\"]\n",
    "    )\n",
    ").str.lower()\n",
    "\n",
    "sum_distrib_df[\"last_updated\"] = pd.to_datetime(datetime.datetime.now())\n",
    "\n",
    "# Only export apps with a TVL\n",
    "sum_distrib_df_export = sum_distrib_df[sum_distrib_df[\"top_level_name\"] != 0]\n",
    "sum_distrib_df_export.to_csv(\"csv_outputs/incentives_stats_summary.csv\")\n",
    "display(sum_distrib_df_export)\n",
    "# display(sum_distrib_df[sum_distrib_df['agg_app_name'].str.contains('rrakis')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_distrib_df_grouped = sum_distrib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming your dataframe is named `df`\n",
    "program_df[\"App Name Map\"] = (\n",
    "    program_df[\"App Name Map Override\"].combine_first(program_df[\"App Name\"])\n",
    ").str.lower()\n",
    "program_df_grouped = (\n",
    "    program_df.groupby(\"App Name Map\")\n",
    "    .agg({\"# OP Allocated\": \"sum\", \"Source\": lambda x: list(set(x))})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# reset_index() is used to convert the grouped result back to a dataframe\n",
    "# the lambda function for 'Source' column aggregates text entries as a list/array\n",
    "# display(program_df_grouped)\n",
    "\n",
    "# Get Deployments Grouped\n",
    "sum_distrib_df_grouped = sum_distrib_df.groupby(\"App Name Map\").agg(sum).reset_index()\n",
    "sum_distrib_df_grouped = sum_distrib_df_grouped.reset_index()\n",
    "sum_distrib_df_grouped[\"net_flows_retention\"] = np.where(\n",
    "    sum_distrib_df_grouped[\"cumul_last_price_net_dollar_flow_ended\"] < 0,\n",
    "    0,\n",
    "    sum_distrib_df_grouped[\"cumul_last_price_net_dollar_flow_ended\"]\n",
    "    / sum_distrib_df_grouped[\"cumul_last_price_net_dollar_flow_at_program_end_ended\"],\n",
    ")\n",
    "sum_distrib_df_grouped.drop(\n",
    "    [\n",
    "        \"num_op_override\",\n",
    "        \"cumul_net_dollar_flow_at_program_end\",\n",
    "        \"cumul_net_dollar_flow\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# purpose is to make sure we don't double count tokens out\n",
    "# From the app presepctive, we look at deployed\n",
    "# From the overall / by season prespective, we look at net\n",
    "sum_distrib_df_grouped[\"op_net_deployed\"] = (\n",
    "    sum_distrib_df_grouped[\"op_deployed\"]\n",
    "    - sum_distrib_df_grouped[\"op_from_other_projects\"]\n",
    ")\n",
    "\n",
    "display(sum_distrib_df_grouped)\n",
    "sum_distrib_df_grouped.to_csv(\"csv_outputs/incentives_summary_by_app.csv\")\n",
    "print(sum_distrib_df_grouped[\"op_net_deployed\"].sum())\n",
    "\n",
    "print(sum_distrib_df_grouped.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = sum_distrib_df_grouped.merge(\n",
    "    program_df_grouped, on=\"App Name Map\", how=\"outer\"\n",
    ")\n",
    "display(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_cols = [\n",
    "    \"app_name\",\n",
    "    \"txs_per_day_prev\",\n",
    "    \"num_addr_per_day_prev\",\n",
    "    \"gas_fee_eth_per_day_prev\",\n",
    "    \"txs_per_day\",\n",
    "    \"num_addr_per_day\",\n",
    "    \"gas_fee_eth_per_day\",\n",
    "    \"txs_per_day_after\",\n",
    "    \"num_addr_per_day_after\",\n",
    "    \"gas_fee_eth_per_day_after\",\n",
    "]\n",
    "app_df_sm = app_df[app_cols]\n",
    "app_df_sm[\"app_name\"] = app_df_sm[\"app_name\"].str.lower()\n",
    "app_df_sm = app_df_sm.rename(columns={\"app_name\": \"App Name Map\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.merge(app_df_sm, on=\"App Name Map\", how=\"outer\")\n",
    "\n",
    "display(joined_df)\n",
    "\n",
    "joined_df.to_csv(\"csv_outputs/total_stats_summary_by_app.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
