{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade dune-client\n",
    "# ! pip show dune-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get L2 Revenue and post it to a database (csv in github for now)\n",
    "# TODO - Integrate with BQ upload\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "sys.path.append(\"../helper_functions\")\n",
    "# import web3py_utils as w3py\n",
    "# import duneapi_utils as du\n",
    "import google_bq_utils as bqu\n",
    "from web3 import Web3\n",
    "from datetime import datetime, timezone\n",
    "sys.path.pop()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ethereum-optimism/optimism/blob/b86522036ad11a91de1d1dadb6805167add83326/specs/predeploys.md?plain=1#L50\n",
    "\n",
    "# Name, contract\n",
    "fee_vaults = [\n",
    "    ['SequencerFeeVault','0x4200000000000000000000000000000000000011'],\n",
    "    ['BaseFeeVault','0x4200000000000000000000000000000000000019'],\n",
    "    ['L1FeeVault','0x420000000000000000000000000000000000001A'],\n",
    "]\n",
    "\n",
    "# Aiming to eventually read from superchain-resitry + some non-superchain static adds\n",
    "chains_rpcs = pd.read_csv('outputs/chain_metadata.csv', na_filter=False)\n",
    "# print(chains_rpcs.columns)\n",
    "chains_rpcs = chains_rpcs[~(chains_rpcs['rpc_url'] == '') & ~(chains_rpcs['op_based_version'].str.contains('legacy'))]\n",
    "# chains_rpcs = chains_rpcs.values.tolist()\n",
    "# print(chains_rpcs.sample(5))\n",
    "\n",
    "# # Temp\n",
    "# chains_rpcs = chains_rpcs.head(1)\n",
    "# chains_rpcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the method signature hash\n",
    "method_signature = \"totalProcessed()\"\n",
    "method_id = Web3.keccak(text=method_signature)[:4].hex()\n",
    "# Verify the method ID\n",
    "print(f\"Method ID: {method_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = [\n",
    "    'block_time', 'block_number', 'chain_name', 'vault_name', \n",
    "    'vault_address', 'alltime_revenue_native', 'chain_id'\n",
    "    # 'gas_token', 'da_layer', 'is_superchain_registry' # Uncomment these if needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = []\n",
    "\n",
    "def process_chain(chain):\n",
    "    chain_name = chain['chain_name']\n",
    "    chain_id = chain['mainnet_chain_id']\n",
    "\n",
    "    if chain_id:  # Check if chain_id is not empty\n",
    "        chain_id = int(float(chain_id))  # Convert to float first, then to int\n",
    "    else:\n",
    "        chain_id = None  # or keep it as an empty string or any default value you prefer\n",
    "\n",
    "    print(chain_name + ' - ' + str(chain_id))\n",
    "    rpc = chain['rpc_url']\n",
    "    # gas_token = chain['gas_token']\n",
    "    # da_layer = chain['da_layer']\n",
    "    # is_superchain_registry = chain['superchain_registry']\n",
    "\n",
    "    try:\n",
    "        w3_conn = Web3(Web3.HTTPProvider(rpc))\n",
    "        # Get the timestamp of the latest block\n",
    "        block_timestamp = w3_conn.eth.get_block('latest').timestamp\n",
    "        block_number = w3_conn.eth.get_block('latest').number\n",
    "        # Convert the UNIX timestamp to a human-readable format\n",
    "        block_datetime = datetime.fromtimestamp(block_timestamp, tz=timezone.utc)\n",
    "        block_time = block_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        for vault in fee_vaults:\n",
    "            vault_name = vault[0]\n",
    "            vault_address = vault[1]\n",
    "            # Call the function directly using eth_call\n",
    "            response = w3_conn.eth.call({\n",
    "                'to': vault_address,\n",
    "                'data': method_id\n",
    "            })\n",
    "            wei_balance = w3_conn.eth.get_balance(vault_address)\n",
    "            # Decode the result (assuming the function returns a uint256)\n",
    "            proxy_processed_wei = Web3.to_int(hexstr=response.hex())\n",
    "            \n",
    "            alltime_revenue_wei = proxy_processed_wei + wei_balance\n",
    "            alltime_revenue_native = alltime_revenue_wei / 1e18\n",
    "\n",
    "            print(chain_name + ' | ' + vault_name + ': ' \\\n",
    "                + str(proxy_processed_wei) + ' | bal: ' + str(wei_balance)\\\n",
    "                + ' | total eth: ' + str(alltime_revenue_native)\n",
    "                )\n",
    "            \n",
    "            tmp = pd.DataFrame(\n",
    "                    [[block_time, block_number, chain_name, vault_name, vault_address, alltime_revenue_native, chain_id]]#, gas_token, da_layer, is_superchain_registry]]\n",
    "                    , columns=df_columns\n",
    "                    )\n",
    "            data_arr.append(tmp)\n",
    "            time.sleep(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chain {chain_name}: {e}\")\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize the API calls\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_chain, chain) for index, chain in chains_rpcs.iterrows()]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()  # This will raise any exceptions caught during the execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for index, chain in chains_rpcs.iterrows():\n",
    "#     chain_name = chain['chain_name']\n",
    "#     chain_id = chain['mainnet_chain_id']\n",
    "\n",
    "#     # if chain_id:  # Check if chain_id is not empty\n",
    "#     #     chain_id = int(float(chain_id))  # Convert to float first, then to int\n",
    "#     # else:\n",
    "#     #     chain_id = None  # or keep it as an empty string or any default value you prefer\n",
    "        \n",
    "#     print(chain_name + ' - ' + str(chain_id))\n",
    "#     rpc = chain['rpc_url']\n",
    "#     # gas_token = chain['gas_token']\n",
    "#     # da_layer = chain['da_layer']\n",
    "#     # is_superchain_registry = chain['superchain_registry']\n",
    "\n",
    "#     try:\n",
    "#         w3_conn = Web3(Web3.HTTPProvider(rpc))\n",
    "#         # Get the timestamp of the latest block\n",
    "#         block_timestamp = w3_conn.eth.get_block('latest').timestamp\n",
    "#         block_number = w3_conn.eth.get_block('latest').number\n",
    "#         # Convert the UNIX timestamp to a human-readable format\n",
    "#         block_datetime = datetime.fromtimestamp(block_timestamp, tz=timezone.utc)\n",
    "#         block_time = block_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#         for vault in fee_vaults:\n",
    "#             vault_name = vault[0]\n",
    "#             vault_address = vault[1]\n",
    "#             # Call the function directly using eth_call\n",
    "#             response = w3_conn.eth.call({\n",
    "#                 'to': vault_address,\n",
    "#                 'data': method_id\n",
    "#             })\n",
    "#             wei_balance = w3_conn.eth.get_balance(vault_address)\n",
    "#             # Decode the result (assuming the function returns a uint256)\n",
    "#             proxy_processed_wei = Web3.to_int(hexstr=response.hex())\n",
    "            \n",
    "#             alltime_revenue_wei = proxy_processed_wei+wei_balance\n",
    "#             alltime_revenue_native = alltime_revenue_wei/1e18\n",
    "\n",
    "#             print(chain_name + ' | ' + vault_name + ': ' \\\n",
    "#                 + str(proxy_processed_wei) + ' | bal: ' + str(wei_balance)\\\n",
    "#                 + ' | total eth: ' + str( (alltime_revenue_native) )\n",
    "#                 )\n",
    "            \n",
    "#             tmp = pd.DataFrame(\n",
    "#                     [[block_time, block_number, chain_name, vault_name, vault_address, alltime_revenue_native, chain_id]]#, gas_token, da_layer, is_superchain_registry]]\n",
    "#                     ,columns =df_columns\n",
    "#                     )\n",
    "#             data_arr.append(tmp)\n",
    "#             time.sleep(1)\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(data_arr)\n",
    "data_df['block_time'] = pd.to_datetime(data_df['block_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'outputs/all_time_revenue_data.csv'\n",
    "\n",
    "data_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Read the existing CSV file\n",
    "    existing_df = pd.read_csv(file_path)\n",
    "    # Ensure the existing file has the same columns\n",
    "    existing_df = existing_df.reindex(columns=df_columns)\n",
    "    data_df = data_df.reindex(columns=df_columns)\n",
    "    # Append without writing the header\n",
    "    data_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    # If file doesn't exist, create it and write the header\n",
    "    data_df.to_csv(file_path, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Overwrite to Dune Table\n",
    "dune_df = pd.read_csv(file_path)\n",
    "# print(dune_df.sample(5))\n",
    "# du.write_dune_api_from_pandas(dune_df, 'op_stack_chains_cumulative_revenue_snapshots',\\\n",
    "#                              'Snapshots of All-Time (cumulative) revenue for fee vaults on OP Stack Chains. Pulled from RPCs - metadata in op_stack_chains_chain_rpc_metdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Insert Updates to Dune Table\n",
    "# create_namespace = 'oplabspbc'\n",
    "# create_table_name = 'op_stack_chains_cumulative_revenue_snapshots'\n",
    "# create_table_description = 'Snapshots of All-Time (cumulative) revenue for fee vaults on OP Stack Chains. Pulled from RPCs - metadata in op_stack_chains_chain_rpc_metdata'\n",
    "# # try:\n",
    "# # du.create_dune_table(data_df, namespace = create_namespace\n",
    "# #                         , table_name = create_table_name\n",
    "# #                         , table_description = create_table_description)\n",
    "\n",
    "# # except:\n",
    "#         # print('error creating')\n",
    "# du.insert_dune_api_from_pandas(data_df, namespace = create_namespace,table_name = create_table_name)\n",
    "\n",
    "# du.write_dune_api_from_pandas(chains_rpcs, 'op_stack_chains_chain_rpc_metdata',\\\n",
    "#                              'Chain metadata - used to join with op_stack_chains_cumulative_revenue_snapshots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_cols = ['block_time','block_number','chain_name','vault_name','vault_address','alltime_revenue_native','chain_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dune_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['chain_id'] = data_df['chain_id'].astype(float)\n",
    "data_df['block_time'] = pd.to_datetime(data_df['block_time'])\n",
    "# dune_df['block_time'] = pd.to_datetime(dune_df['block_time'])\n",
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'rpc_table_uploads'\n",
    "table_name = 'hourly_cumulative_l2_revenue_snapshots'\n",
    "\n",
    "# Write All to BQ Table\n",
    "# bqu.write_df_to_bq_table(df = dune_df[bq_cols], table_id = table_name, dataset_id = dataset_name)\n",
    "\n",
    "# Write Updates to BQ Table\n",
    "unique_cols = ['block_time', 'chain_name', 'chain_id', 'vault_name']\n",
    "bqu.write_df_to_bq_table(df = data_df[bq_cols], table_id = table_name, dataset_id = dataset_name, write_mode='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
