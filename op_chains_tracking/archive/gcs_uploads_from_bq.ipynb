{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import pandas as pd\n",
    "# from decimal import Decimal\n",
    "# import pandas_gbq\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "import pandas_utils as p\n",
    "sys.path.pop()\n",
    "\n",
    "import time\n",
    "import os\n",
    "import dotenv\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Set the environment variable to the path of your service account key file\n",
    "print(os.environ[\"IS_RUNNING_LOCAL\"])\n",
    "if os.environ[\"IS_RUNNING_LOCAL\"] == 'True': #GH Action was weird with this, so forcing the datatype here\n",
    "        print('running local')\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getenv(\"PATH_TO_BQ_CREDS\")\n",
    "        # pandas_gbq.context.credentials = service_account.Credentials.from_service_account_file(os.getenv(\"PATH_TO_BQ_CREDS\"))\n",
    "else: #Can't get the Github Action version to work\n",
    "        print('not running local')\n",
    "        # Set the Google Cloud service account key from GitHub secret\n",
    "        google_credentials = os.getenv(\"BQ_APPLICATION_CREDENTIALS\")\n",
    "        # Set the environment variable to the path of your service account key file\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = google_credentials\n",
    "\n",
    "        # os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getenv(\"BQ_APPLICATION_CREDENTIALS\")\n",
    "        # pandas_gbq.context.credentials = os.getenv(\"BQ_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getenv(\"BQ_APPLICATION_CREDENTIALS\")\n",
    "# pandas_gbq.context.credentials = service_account.Credentials.from_service_account_file()\n",
    "# pandas_gbq.context.project = \"oplabs-tools-data\"\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_mappings = {\n",
    "        'zora': 'Zora',\n",
    "        'pgn': 'Public Goods Network',\n",
    "        'base': 'Base',\n",
    "        'mode': 'Mode',\n",
    "        'metal': 'Metal',\n",
    "        'frax': 'Fraxtal'\n",
    "        # Add more mappings as needed\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_directory = \"inputs/sql/\"\n",
    "\n",
    "query_names = [\n",
    "        # Must match the file name in inputs/sql\n",
    "        \"frax_allltime_chain_activity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks\n",
    "# print(pandas_gbq.context.project)\n",
    "# print(pandas_gbq.context.credentials)\n",
    "dune_df = []\n",
    "dune_table = 'op_gcs_allltime_chain_activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qn in query_names:\n",
    "        # If we can do it programmatically from UI saved queries\n",
    "        # query = client.get_job(query_name)\n",
    "        # Read the SQL query from file\n",
    "        with open(os.path.join(sql_directory, f\"{qn}.sql\"), \"r\") as file:\n",
    "                query = file.read()\n",
    "        print(qn)\n",
    "        table_name = qn\n",
    "        \n",
    "        # Execute the query\n",
    "        query_job = client.query(query)\n",
    "        # df = pandas_gbq.read_gbq(query)\n",
    "        # Fetch the results\n",
    "        results = query_job.result()\n",
    "        # Convert the results to a DataFrame\n",
    "        df = results.to_dataframe()\n",
    "        \n",
    "        # Write to csv\n",
    "        df.to_csv('outputs/chain_data/' + qn + '.csv', index=False)\n",
    "        # print(df.sample(5))\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Write to Dune\n",
    "        df['chain_raw'] = df['chain']\n",
    "        df['chain'] = df['chain'].replace(chain_mappings)\n",
    "        dune_df.append(df)\n",
    "\n",
    "write_df = pd.concat(dune_df)\n",
    "d.write_dune_api_from_pandas(write_df, dune_table,table_description = dune_table)\n",
    "write_df.to_csv('outputs/chain_data/' + dune_table + '.csv', index=False)\n",
    "# Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dune_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
