{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "from urllib.parse import urlencode\n",
    "import sys\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "import google_bq_utils as bqu\n",
    "import clickhouse_utils as ch\n",
    "sys.path.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIS = {\n",
    "    \"ethereum\": {\n",
    "        \"url\": \"https://api.etherscan.io/api\",\n",
    "        \"key\": os.environ[\"L1_ETHERSCAN_API\"]\n",
    "    },\n",
    "    \"base\": {\n",
    "        \"url\": \"https://api.basescan.org/api\",\n",
    "        \"key\": os.environ[\"BASESCAN_API\"]\n",
    "    },\n",
    "    \"op\": {\n",
    "        \"url\": \"https://api-optimistic.etherscan.io/api\",\n",
    "        \"key\": os.environ[\"OP_ETHERSCAN_API\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_addresses_from_csv(filename: str) -> List[Tuple[str, str, str]]:\n",
    "    addresses = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            chain, address, name = row\n",
    "            addresses.append((chain, address, name))\n",
    "    return addresses\n",
    "\n",
    "def get_balance(network: str, address: str) -> float:\n",
    "    params = {\n",
    "        \"module\": \"account\",\n",
    "        \"action\": \"balance\",\n",
    "        \"address\": address,\n",
    "        \"tag\": \"latest\",\n",
    "        \"apikey\": APIS[network][\"key\"]\n",
    "    }\n",
    "    \n",
    "    # Construct the full URL with parameters\n",
    "    full_url = f\"{APIS[network]['url']}?{urlencode(params)}\"\n",
    "    \n",
    "    # Print the full URL for debugging\n",
    "    # print(f\"Debug - API call URL: {full_url}\")\n",
    "\n",
    "    response = requests.get(APIS[network][\"url\"], params=params)\n",
    "    # print(response.json())\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if result[\"status\"] == \"1\":\n",
    "            balance = int(result[\"result\"]) / 1e18  # Convert wei to ETH\n",
    "            return balance\n",
    "    return None\n",
    "\n",
    "def check_balances(addresses: List[Tuple[str, str, str]]) -> Dict[str, float]:\n",
    "    balances = {}\n",
    "    for chain, address, name in addresses:\n",
    "        balance = get_balance(chain, address)\n",
    "        # print(balance)\n",
    "        if balance is not None:\n",
    "            balances[name] = {\"balance\": balance, \"address\": address}\n",
    "        else:\n",
    "            balances[name] = {\"balance\": None, \"address\": address}\n",
    "        time.sleep(0.1)\n",
    "    return balances\n",
    "\n",
    "def get_inflight_withdrawals():\n",
    "        wds = d.get_dune_data(query_id = 3939869, #https://dune.com/queries/3939869\n",
    "                name = \"l1_to_l2_inflight_withdrawals\",\n",
    "                path = \"outputs\",\n",
    "                performance=\"large\",\n",
    "                num_hours_to_rerun=0 #always rereun\n",
    "                )\n",
    "        wds_bal = wds['amount_eth'].sum()\n",
    "        return wds_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = 'inputs/address_list.csv'  # Make sure this file exists in the same directory as your script\n",
    "addresses = read_addresses_from_csv(csv_filename)\n",
    "balances = check_balances(addresses)\n",
    "balances['l1_to_l2_inflight_withdrawals'] = {\"balance\": get_inflight_withdrawals(), \"address\": 'https://dune.com/embeds/3939869/6626683/'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output balances as JSON\n",
    "json_txt = json.dumps(balances, indent=2)\n",
    "# print(json_txt)\n",
    "# Create DataFrame\n",
    "current_time = datetime.now()\n",
    "df_data = []\n",
    "for name, data in balances.items():\n",
    "    df_data.append({\n",
    "        'dt': pd.Timestamp(current_time.date()),\n",
    "        'timestamp': pd.Timestamp(current_time.isoformat()),\n",
    "        'address_type': name,\n",
    "        'address': data['address'],\n",
    "        'balance': data['balance']\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'op_collective_balances'\n",
    "# Write JSON to file\n",
    "with open(f'outputs/latest_{table_name}.json', 'w') as json_file:\n",
    "        json_file.write(json_txt)\n",
    "print(f\"JSON written\")\n",
    "\n",
    "# # Append DataFrame to CSV\n",
    "# csv_output_file = f'outputs/{table_name}_history.csv'\n",
    "# df.to_csv(csv_output_file, mode='a', header=not pd.io.common.file_exists(csv_output_file), index=False)\n",
    "\n",
    "# print(f\"CSV appended\")\n",
    "\n",
    "# Write latest values to a separate CSV, replacing it on every run\n",
    "latest_csv_file = f'outputs/latest_{table_name}.csv'\n",
    "df.to_csv(latest_csv_file, index=False)\n",
    "print(f\"Latest values written to {latest_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_table = f'daily_{table_name}'\n",
    "#BQ Upload\n",
    "bqu.append_and_upsert_df_to_bq_table(df, upload_table, unique_keys = ['dt','address_type','address'])\n",
    "#CH Upload\n",
    "ch.write_df_to_clickhouse(df, upload_table, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
