name: Run OP Stack Metadata -> csv and Dune

# Controls when the workflow will run
on:
  # Run on a schedule - “At 02:01 on Sunday.” - few mins for dependencies to install
  schedule:
      - cron: '1 2 * * 0'
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
  pull_request:
    types: [closed]
    paths:
      - 'op_chains_tracking/inputs/**'
  

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
  # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3
      
      - name: Display System Info
        run: |
          free -h
          df -h

      # Set up Python and Node.js
      - name: Set up Python and Node.js
        uses: actions/setup-python@v2
        with:
          python-version: '3.10.11'
        # Set max space to see if this helps with timeouts
        env:
          node-version: '16'


      - name: Install pipenv
        run: |
          python -m pip install pipenv

      # Add any missing dependencied to pipfile
      - name: Install Dependencies
        run: |
          pipenv install --dev
    # Runs a single command using the runners shell
      # Generate .py files for each notebook
      - name: Generate py files
        working-directory: op_chains_tracking
        run: |
          pipenv run jupyter nbconvert --to python inputs/clean_chain_metadata_and_upload.ipynb
          pipenv run jupyter nbconvert --to python create_superchain_data_view.ipynb
          
      - name: Generate Chain Metadata
        working-directory: op_chains_tracking/inputs
        run: |
          pipenv run python inputs/clean_chain_metadata_and_upload.py
        env:
          DUNE_API_KEY: ${{ secrets.DUNE_API_KEY }}
          IS_RUNNING_LOCAL: ${{ secrets.IS_RUNNING_LOCAL }}
          BQ_APPLICATION_CREDENTIALS: ${{ secrets.BQ_APPLICATION_CREDENTIALS }}
          BQ_PROJECT_ID: ${{ secrets.BQ_PROJECT_ID }}
      - name: Create View
        working-directory: op_chains_tracking
        run: |
          pipenv run python create_superchain_data_view.py
        env:
          OP_CLICKHOUSE_HOST: ${{ secrets.OP_CLICKHOUSE_HOST }}
          OP_CLICKHOUSE_USER: ${{ secrets.OP_CLICKHOUSE_USER }}
          OP_CLICKHOUSE_PW: ${{ secrets.OP_CLICKHOUSE_PW }}
          OP_CLICKHOUSE_PORT: ${{ secrets.OP_CLICKHOUSE_PORT }}


# commit_results:
    # if: ${{ always() }} #Always runs even if prior jobs fail - so that one bad job doesn't f everything up.
    # needs: build #[build, app_fees, op_summer, total_tvl_flow]
    # runs-on: ubuntu-latest
    # steps:
      # Runs a set of commands using the runners shell
      # - name: Run a multi-line script
      #  run: |
      #    echo Add other actions to build,
      #    echo test, and deploy your project.
      
      # Commit and push output images
      # https://github.com/orgs/community/discussions/26672
      - name: Pull changes
        run: |
          git pull origin main
      - name: Commit files
        id: commit
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "github-actions"
          git add --all
          if [ -z "$(git status --porcelain)" ]; then
            echo "No changes to commit."
            echo "push=false" >> $GITHUB_OUTPUT
          else
            git commit -m "GH Action Update - Metadata" -a
            echo "push=true" >> $GITHUB_OUTPUT
          fi
        shell: bash
      - name: Push changes
        if: steps.commit.outputs.push == 'true'
        uses: ad-m/github-push-action@master
        with:
            github_token: ${{ secrets.GITHUB_TOKEN }}