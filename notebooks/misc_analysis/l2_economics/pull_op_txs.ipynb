{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This uses a modified ethereum-etl here: https://github.com/MSilb7/optimism-etl\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import ethereumetl_utils as eetl\n",
    "import web3py_utils as wpy\n",
    "import pandas_utils as pu\n",
    "import evm_utils as evm\n",
    "sys.path.pop()\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import datetime\n",
    "load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we re-run data\n",
    "run_data = 1\n",
    "# Does l1_gas_used account for overhead? If not, set it to 0, if so, put it here (i.e. 600)\n",
    "fixed_overhead = 0\n",
    "\n",
    "configs = [\n",
    "        # ['base_goerli',os.environ.get('BASE_GOERLI_NODE')]\n",
    "        ['op_goerli_24h_load',os.environ.get('OP_GOERLI_TEAM_NODE')]\n",
    "]\n",
    "\n",
    "max_workers = 8\n",
    "# Dune L1 Goerli Data https://dune.com/queries/2502137\n",
    "# First Test 2023-05-23 05:00:00 - 2023-05-23 17:00:00 (12 hours)\n",
    "# Forward Test 2023-05-23 17:01:00 - 2023-05-24 05:00:00 (12 hours)\n",
    "start_timestamp = pu.convert_text_timestamp_to_int('2023-05-23 05:00:00')\n",
    "end_timestamp = pu.convert_text_timestamp_to_int('2023-05-24 05:00:00')\n",
    "\n",
    "print( pd.to_datetime(start_timestamp, unit='s') )\n",
    "print( pd.to_datetime(end_timestamp, unit='s') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Transactions\n",
    "for i in configs:\n",
    "\n",
    "    folder = i[0]\n",
    "    uri = i[1]\n",
    "#     block_arr = wpy.get_blockrange_by_timedelta(i[1],trailing_hours,'hours')\n",
    "    st_bl = wpy.getBlockByTimestamp(i[1],start_timestamp)# block_arr[0]\n",
    "    en_bl = wpy.getBlockByTimestamp(i[1],end_timestamp) # block_arr[1]\n",
    "    print(st_bl)\n",
    "    print(en_bl)\n",
    "    if run_data == 1:\n",
    "        eetl.get_ethereum_etl(st_bl,en_bl,folder,uri, max_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Receipts\n",
    "for i in configs:\n",
    "    folder = i[0]\n",
    "    uri = i[1]\n",
    "    if run_data == 1:\n",
    "        eetl.get_eth_etl_receipts(folder, uri)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in configs:\n",
    "        folder = i[0]\n",
    "        uri = i[1]\n",
    "        opg_df = pd.read_csv(os.getcwd() + '/downloads/' + folder + '/transactions.csv')\n",
    "        rec_df = pd.read_csv(os.getcwd() + '/downloads/' + folder + '/receipts.csv')\n",
    "        rec_df = rec_df.rename(columns={'transaction_hash':'hash'})\n",
    "        rec_df = rec_df[['hash','l1_gas_used','l1_fee','l1_gas_price','l1_fee_scalar']]\n",
    "\n",
    "        df = opg_df.merge(rec_df,on='hash',how='left')\n",
    "        #REMOVE DSEPOSITS\n",
    "        df = df[df['transaction_type'] != 126]\n",
    "        df['all_data_gas'] = df['l1_gas_used'] - fixed_overhead\n",
    "        df['input_calldata_gas'] = df['input'].apply(evm.count_calldata_gas)\n",
    "        df['effective_l1_gas_used'] = df['l1_fee'] / df['l1_gas_price']\n",
    "        df.to_csv(os.getcwd() + '/downloads/' + folder + '/merged_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['block_number','block_timestamp']\n",
    "\n",
    "for i in configs:\n",
    "        folder = i[0]\n",
    "        uri = i[1]\n",
    "        total_df = pd.read_csv(os.getcwd() + '/downloads/' + folder + '/merged_data.csv')\n",
    "\n",
    "        blocks_df = total_df.groupby(group_cols).agg({\n",
    "                'effective_l1_gas_used':'sum',\n",
    "                'all_data_gas':'sum',\n",
    "                'hash':'count',\n",
    "                'l1_gas_price':'mean',\n",
    "                'gas':'sum',\n",
    "                'gas_price':'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        blocks_df = blocks_df.rename(columns={\n",
    "                'effective_l1_gas_used':'total_l1_gas_used',\n",
    "                'all_data_gas':'total_l1_data_gas_used',\n",
    "                'hash':'num_txs',\n",
    "                'l1_gas_price':'avg_l1_gas_price',\n",
    "                'gas':'total_l2_gas_used',\n",
    "                'gas_price':'avg_gas_price',\n",
    "        })\n",
    "\n",
    "        blocks_df['block_timestamp'] = pd.to_datetime(blocks_df['block_timestamp'], unit='s')\n",
    "        display(blocks_df)\n",
    "\n",
    "        blocks_df.to_csv(os.getcwd() + '/downloads/' + folder + '/by_block_summary.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
