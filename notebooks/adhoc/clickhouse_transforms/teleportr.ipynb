{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-02-20 13:31:27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m1/1 markers pending.          \u001b[0m \u001b[36menv\u001b[0m=\u001b[35mPROD\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mmain.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m54\u001b[0m \u001b[36mprocess\u001b[0m=\u001b[35m30950\u001b[0m\n",
      "\u001b[2m2025-02-20 13:31:27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPrepared 1 transform tasks.   \u001b[0m \u001b[36menv\u001b[0m=\u001b[35mPROD\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mmain.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m68\u001b[0m \u001b[36mprocess\u001b[0m=\u001b[35m30950\u001b[0m\n",
      "\u001b[2m2025-02-20 13:31:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mfact_teleportr_events_v1.sql -> 0 written rows\u001b[0m \u001b[36mddl\u001b[0m=\u001b[35mfact_teleportr_events_v1.sql\u001b[0m \u001b[36mdt\u001b[0m=\u001b[35m2025-02-15\u001b[0m \u001b[36melapsed_ns\u001b[0m=\u001b[35m91187276\u001b[0m \u001b[36menv\u001b[0m=\u001b[35mPROD\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mcreate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m44\u001b[0m \u001b[36mprocess\u001b[0m=\u001b[35m30950\u001b[0m \u001b[36mquery_id\u001b[0m=\u001b[35mea0e2937-c886-4462-a0bb-14056da4ac2d\u001b[0m \u001b[36mread_bytes\u001b[0m=\u001b[35m142\u001b[0m \u001b[36mread_rows\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mresult_bytes\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mresult_rows\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m1/1\u001b[0m \u001b[36mtotal_rows_to_read\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mwritten_bytes\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mwritten_rows\u001b[0m=\u001b[35m0\u001b[0m\n",
      "\u001b[2m2025-02-20 13:31:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrunning ddl 01_fact_teleportr_events_v1.sql\u001b[0m \u001b[36mddl\u001b[0m=\u001b[35m01_fact_teleportr_events_v1.sql\u001b[0m \u001b[36mdt\u001b[0m=\u001b[35m2025-02-15\u001b[0m \u001b[36menv\u001b[0m=\u001b[35mPROD\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mtransform.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m94\u001b[0m \u001b[36mprocess\u001b[0m=\u001b[35m30950\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m1/1\u001b[0m\n",
      "\u001b[2m2025-02-20 13:31:29\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mdatabase error                \u001b[0m \u001b[36mddl\u001b[0m=\u001b[35m01_fact_teleportr_events_v1.sql\u001b[0m \u001b[36mdt\u001b[0m=\u001b[35m2025-02-15\u001b[0m \u001b[36menv\u001b[0m=\u001b[35mPROD\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mtransform.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m103\u001b[0m \u001b[36mprocess\u001b[0m=\u001b[35m30950\u001b[0m \u001b[36mtask\u001b[0m=\u001b[35m1/1\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/chuxinhuang/work/op-analytics/src/op_analytics/transforms/transform.py\", line 97, in run_update\n",
      "    result: QuerySummary = client.command(\n",
      "                           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chuxinhuang/work/op-analytics/.venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py\", line 350, in command\n",
      "    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chuxinhuang/work/op-analytics/.venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py\", line 461, in _raw_request\n",
      "    self._error_handler(response)\n",
      "  File \"/Users/chuxinhuang/work/op-analytics/.venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py\", line 384, in _error_handler\n",
      "    raise OperationalError(err_str) if retried else DatabaseError(err_str) from None\n",
      "clickhouse_connect.driver.exceptions.DatabaseError: HTTPDriver for https://qeyct17r6o.us-central1.gcp.clickhouse.cloud:8443 received ClickHouse error code 46\n",
      " Code: 46. DB::Exception: Function with name `SPLITBYCHAR` does not exist. In scope raw_events AS (SELECT l.block_timestamp AS block_timestamp, l.dt AS dt, l.block_number AS block_number, l.chain AS src_chain, l.chain_id AS src_chain_id, l.address AS contract_address, l.transaction_hash AS transaction_hash, REINTERPRETASUINT64(REVERSE(UNHEX(substring(SPLITBYCHAR(',', l.topics)[3], 3)))) AS deposit_id, concat('0x', substring(substring(l.data, 3), 25, 40)) AS input_token_address, concat('0x', substring(substring(l.data, 3), 89, 40)) AS output_token_address, CAST(REINTERPRETASUINT64(REVERSE(UNHEX(substring(SPLITBYCHAR(',', l.topics)[2], 3)))), 'String') AS dst_chain_id, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 129, 64)))) AS input_amount, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 193, 64)))) AS output_amount, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 257, 64)))) AS quote_timestamp, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 321, 64)))) AS fill_deadline, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 385, 64)))) AS exclusivity_deadline, concat('0x', RIGHT(substring(substring(l.data, 3), 449, 64), 40)) AS recipient_address, concat('0x', RIGHT(substring(substring(l.data, 3), 513, 64), 40)) AS relayer_address, t.from_address AS depositor_address, multiIf(substring(t.input, -10) = '1dc0de0001', 'SuperBridge', substring(t.input, -10) = '1dc0de0002', 'Brid.gg', NULL) AS integrator, l.log_index AS log_index, (t.gas_price * t.gas_used) / 1000000000000000000. AS l2_fee_eth, t.receipt_l1_fee / 1000000000000000000. AS l1_fee_eth, ((t.gas_price * t.gas_used) / 1000000000000000000.) + (t.receipt_l1_fee / 1000000000000000000.) AS total_fee_eth FROM blockbatch_gcs.read_date(rootpath = 'ingestion/logs_v1', chain = '*', dt = _CAST(20134, 'Date ')) AS l INNER JOIN blockbatch_gcs.read_date(rootpath = 'ingestion/transactions_v1', chain = '*', dt = _CAST(20134, 'Date ')) AS t ON (l.transaction_hash = t.hash) AND (l.block_number = t.block_number) AND (l.chain = t.chain) INNER JOIN across_bridge_metadata AS c ON (l.chain = c.chain_name) AND (l.address = c.spokepool_address) WHERE true AND ((SPLITBYCHAR(',', l.topics)[1]) = '0xa123dc29aebf7d0c3322c8eeb5b999e859f39937950ed31056532713d0de396f') AND (t.gas_price > 0) AND (l.data IS NOT NULL) AND (l.data != '')). Maybe you meant: ['splitByChar','splitByAlpha']. (UNKNOWN_FUNCTION) (version 24.10.1.11275 (official build))\n",
      "\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "HTTPDriver for https://qeyct17r6o.us-central1.gcp.clickhouse.cloud:8443 received ClickHouse error code 46\n Code: 46. DB::Exception: Function with name `SPLITBYCHAR` does not exist. In scope raw_events AS (SELECT l.block_timestamp AS block_timestamp, l.dt AS dt, l.block_number AS block_number, l.chain AS src_chain, l.chain_id AS src_chain_id, l.address AS contract_address, l.transaction_hash AS transaction_hash, REINTERPRETASUINT64(REVERSE(UNHEX(substring(SPLITBYCHAR(',', l.topics)[3], 3)))) AS deposit_id, concat('0x', substring(substring(l.data, 3), 25, 40)) AS input_token_address, concat('0x', substring(substring(l.data, 3), 89, 40)) AS output_token_address, CAST(REINTERPRETASUINT64(REVERSE(UNHEX(substring(SPLITBYCHAR(',', l.topics)[2], 3)))), 'String') AS dst_chain_id, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 129, 64)))) AS input_amount, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 193, 64)))) AS output_amount, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 257, 64)))) AS quote_timestamp, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 321, 64)))) AS fill_deadline, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 385, 64)))) AS exclusivity_deadline, concat('0x', RIGHT(substring(substring(l.data, 3), 449, 64), 40)) AS recipient_address, concat('0x', RIGHT(substring(substring(l.data, 3), 513, 64), 40)) AS relayer_address, t.from_address AS depositor_address, multiIf(substring(t.input, -10) = '1dc0de0001', 'SuperBridge', substring(t.input, -10) = '1dc0de0002', 'Brid.gg', NULL) AS integrator, l.log_index AS log_index, (t.gas_price * t.gas_used) / 1000000000000000000. AS l2_fee_eth, t.receipt_l1_fee / 1000000000000000000. AS l1_fee_eth, ((t.gas_price * t.gas_used) / 1000000000000000000.) + (t.receipt_l1_fee / 1000000000000000000.) AS total_fee_eth FROM blockbatch_gcs.read_date(rootpath = 'ingestion/logs_v1', chain = '*', dt = _CAST(20134, 'Date ')) AS l INNER JOIN blockbatch_gcs.read_date(rootpath = 'ingestion/transactions_v1', chain = '*', dt = _CAST(20134, 'Date ')) AS t ON (l.transaction_hash = t.hash) AND (l.block_number = t.block_number) AND (l.chain = t.chain) INNER JOIN across_bridge_metadata AS c ON (l.chain = c.chain_name) AND (l.address = c.spokepool_address) WHERE true AND ((SPLITBYCHAR(',', l.topics)[1]) = '0xa123dc29aebf7d0c3322c8eeb5b999e859f39937950ed31056532713d0de396f') AND (t.gas_price > 0) AND (l.data IS NOT NULL) AND (l.data != '')). Maybe you meant: ['splitByChar','splitByAlpha']. (UNKNOWN_FUNCTION) (version 24.10.1.11275 (official build))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPLABS_ENV\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mop_analytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute_dt_transforms\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_dt_transforms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteleportr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# range_spec=\"@20250210:20250215\",\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m@20250215:+1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_complete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/op-analytics/src/op_analytics/transforms/main.py:80\u001b[0m, in \u001b[0;36mexecute_dt_transforms\u001b[0;34m(group_name, range_spec, update_only, skip_create, raise_if_empty, force_complete, max_tasks)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m bound_contextvars(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mii\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_tasks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m NoWrittenRows:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m==\u001b[39m now_date():\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;66;03m# It is possible that NoWrittenRows is encountered when we are running\u001b[39;00m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;66;03m# close to real time. In that case don't error out the run, log a warning\u001b[39;00m\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;66;03m# and exit gracefully.\u001b[39;00m\n",
      "File \u001b[0;32m~/work/op-analytics/src/op_analytics/transforms/transform.py:56\u001b[0m, in \u001b[0;36mTransformTask.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_create:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_tables()\n\u001b[0;32m---> 56\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m result_dicts \u001b[38;5;241m=\u001b[39m [_\u001b[38;5;241m.\u001b[39mto_dict() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_marker(result_dicts)\n",
      "File \u001b[0;32m~/work/op-analytics/src/op_analytics/transforms/transform.py:75\u001b[0m, in \u001b[0;36mTransformTask.run_updates\u001b[0;34m(self, client)\u001b[0m\n\u001b[1;32m     72\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipping index=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ddl=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     77\u001b[0m     UpdateResult(\n\u001b[1;32m     78\u001b[0m         name\u001b[38;5;241m=\u001b[39mstep\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     79\u001b[0m         result\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39msummary,\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step\u001b[38;5;241m.\u001b[39mstep_type \u001b[38;5;241m==\u001b[39m StepType\u001b[38;5;241m.\u001b[39mEXPORT:\n",
      "File \u001b[0;32m~/work/op-analytics/src/op_analytics/transforms/transform.py:97\u001b[0m, in \u001b[0;36mTransformTask.run_update\u001b[0;34m(self, client, step)\u001b[0m\n\u001b[1;32m     94\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning ddl \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     result: QuerySummary \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtparam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_hive_partitioning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DatabaseError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    103\u001b[0m     log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase error\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n",
      "File \u001b[0;32m~/work/op-analytics/.venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py:350\u001b[0m, in \u001b[0;36mHttpClient.command\u001b[0;34m(self, cmd, parameters, data, settings, use_database, external_data)\u001b[0m\n\u001b[1;32m    347\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_settings(settings \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[1;32m    349\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m payload \u001b[38;5;129;01mor\u001b[39;00m fields \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 350\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_wait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/op-analytics/.venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py:461\u001b[0m, in \u001b[0;36mHttpClient._raw_request\u001b[0;34m(self, data, params, headers, method, retries, stream, server_wait, fields, error_handler)\u001b[0m\n\u001b[1;32m    459\u001b[0m     error_handler(response)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/op-analytics/.venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py:384\u001b[0m, in \u001b[0;36mHttpClient._error_handler\u001b[0;34m(self, response, retried)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe ClickHouse server returned an error.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(err_str) \u001b[38;5;28;01mif\u001b[39;00m retried \u001b[38;5;28;01melse\u001b[39;00m DatabaseError(err_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: HTTPDriver for https://qeyct17r6o.us-central1.gcp.clickhouse.cloud:8443 received ClickHouse error code 46\n Code: 46. DB::Exception: Function with name `SPLITBYCHAR` does not exist. In scope raw_events AS (SELECT l.block_timestamp AS block_timestamp, l.dt AS dt, l.block_number AS block_number, l.chain AS src_chain, l.chain_id AS src_chain_id, l.address AS contract_address, l.transaction_hash AS transaction_hash, REINTERPRETASUINT64(REVERSE(UNHEX(substring(SPLITBYCHAR(',', l.topics)[3], 3)))) AS deposit_id, concat('0x', substring(substring(l.data, 3), 25, 40)) AS input_token_address, concat('0x', substring(substring(l.data, 3), 89, 40)) AS output_token_address, CAST(REINTERPRETASUINT64(REVERSE(UNHEX(substring(SPLITBYCHAR(',', l.topics)[2], 3)))), 'String') AS dst_chain_id, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 129, 64)))) AS input_amount, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 193, 64)))) AS output_amount, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 257, 64)))) AS quote_timestamp, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 321, 64)))) AS fill_deadline, REINTERPRETASUINT256(REVERSE(UNHEX(substring(substring(l.data, 3), 385, 64)))) AS exclusivity_deadline, concat('0x', RIGHT(substring(substring(l.data, 3), 449, 64), 40)) AS recipient_address, concat('0x', RIGHT(substring(substring(l.data, 3), 513, 64), 40)) AS relayer_address, t.from_address AS depositor_address, multiIf(substring(t.input, -10) = '1dc0de0001', 'SuperBridge', substring(t.input, -10) = '1dc0de0002', 'Brid.gg', NULL) AS integrator, l.log_index AS log_index, (t.gas_price * t.gas_used) / 1000000000000000000. AS l2_fee_eth, t.receipt_l1_fee / 1000000000000000000. AS l1_fee_eth, ((t.gas_price * t.gas_used) / 1000000000000000000.) + (t.receipt_l1_fee / 1000000000000000000.) AS total_fee_eth FROM blockbatch_gcs.read_date(rootpath = 'ingestion/logs_v1', chain = '*', dt = _CAST(20134, 'Date ')) AS l INNER JOIN blockbatch_gcs.read_date(rootpath = 'ingestion/transactions_v1', chain = '*', dt = _CAST(20134, 'Date ')) AS t ON (l.transaction_hash = t.hash) AND (l.block_number = t.block_number) AND (l.chain = t.chain) INNER JOIN across_bridge_metadata AS c ON (l.chain = c.chain_name) AND (l.address = c.spokepool_address) WHERE true AND ((SPLITBYCHAR(',', l.topics)[1]) = '0xa123dc29aebf7d0c3322c8eeb5b999e859f39937950ed31056532713d0de396f') AND (t.gas_price > 0) AND (l.data IS NOT NULL) AND (l.data != '')). Maybe you meant: ['splitByChar','splitByAlpha']. (UNKNOWN_FUNCTION) (version 24.10.1.11275 (official build))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Override to force BQ write.\n",
    "os.environ[\"OPLABS_ENV\"] = \"prod\"\n",
    "\n",
    "from op_analytics.transforms.main import execute_dt_transforms\n",
    "\n",
    "results = execute_dt_transforms(\n",
    "    group_name=\"teleportr\",\n",
    "    # range_spec=\"@20250210:20250215\",\n",
    "    range_spec=\"@20250215:+1\",\n",
    "    update_only=[1],\n",
    "    skip_create=False,\n",
    "    raise_if_empty=True,\n",
    "    max_tasks=None,\n",
    "    force_complete=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
