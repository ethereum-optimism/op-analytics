{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245f7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import plotly.express as px\n",
    "\n",
    "from op_analytics.datasources.defillama.dataaccess import DefiLlama\n",
    "from op_analytics.coreutils.request import get_data, new_session\n",
    "\n",
    "import urllib3\n",
    "import warnings\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "urllib3.disable_warnings()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf536b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc55e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERNS_TO_FILTER = [\n",
    "    \"-borrowed\",\n",
    "    \"-vesting\",\n",
    "    \"-staking\",\n",
    "    \"-pool2\",\n",
    "    \"-treasury\",\n",
    "    \"-cex\",\n",
    "    \"^treasury$\",\n",
    "    \"^borrowed$\",\n",
    "    \"^staking$\",\n",
    "    \"^pool2$\",\n",
    "    \"^pool2$\",\n",
    "    \"polygon-bridge-&-staking\",  # Added this as a full match\n",
    "    \".*-cex$\",  # Added this to match anything ending with -cex\n",
    "]\n",
    "\n",
    "CATEGORIES_TO_FILTER = [\"CEX\", \"Chain\"]\n",
    "\n",
    "alignment_dict = {\n",
    "    \"Metis\": \"OP Stack fork\",\n",
    "    \"Blast\": \"OP Stack fork\",\n",
    "    \"Mantle\": \"OP Stack fork\",\n",
    "    \"Zircuit\": \"OP Stack fork\",\n",
    "    \"RSS3\": \"OP Stack fork\",\n",
    "    \"Rollux\": \"OP Stack fork\",\n",
    "    \"Ancient8\": \"OP Stack fork\",\n",
    "    \"Manta\": \"OP Stack fork\",\n",
    "    \"Cyber\": \"OP Chain\",\n",
    "    \"Mint\": \"OP Chain\",\n",
    "    \"Ham\": \"OP Chain\",\n",
    "    \"Polynomial\": \"OP Chain\",\n",
    "    \"Lisk\": \"OP Chain\",\n",
    "    \"BOB\": \"OP Chain\",\n",
    "    \"Mode\": \"OP Chain\",\n",
    "    \"World Chain\": \"OP Chain\",\n",
    "    \"Base\": \"OP Chain\",\n",
    "    \"Kroma\": \"OP Chain\",\n",
    "    \"Boba\": \"OP Chain\",\n",
    "    \"Fraxtal\": \"OP Chain\",\n",
    "    \"Optimism\": \"OP Chain\",\n",
    "    \"Shape\": \"OP Chain\",\n",
    "    \"Zora\": \"OP Chain\"\n",
    "}\n",
    "\n",
    "alignment_df = pd.DataFrame(list(alignment_dict.items()), columns=[\"chain\", \"alignment\"])\n",
    "\n",
    "token_data = [\n",
    "    {\"token\": \"ETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"WETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"SOL\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"wBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "    {\"token\": \"cbBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "    {\"token\": \"MBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "\n",
    "    {\"token\": \"stETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"wstETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"eETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"weETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"sfrxETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"rETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"mETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"rsETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"cbETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"ezETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"rswETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"swETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"frxETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"ETHX\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"lsETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"oETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"EBTC\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"LBTC\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"SUPEROETHB\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"WSUPEROETHB\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"TETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"OSETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"cmETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"WRSETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"WEETH.BASE\", \"token_category\": \"Liquid Restaking\"},\n",
    "    \n",
    "    {\"token\": \"USDC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDT\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"FDUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"PYUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"TUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"DAI\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDE\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"FRAX\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"EURC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"AGEUR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDS\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDB\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"DOLA\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"SUSDE\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD0++\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD0\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"SUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"CRVUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDC+\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDZ\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"STAR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDBC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD+\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"CDXUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"HYUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"STAR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"EURS\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"AXLEUROC\", \"token_category\": \"Stablecoins\"},\n",
    "\n",
    "\n",
    "    # Solana Liquid staking\n",
    "    {\"token\": \"MSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"JUPSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"BNSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"SSOL\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"BBSOL\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"LAINESOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STRONGSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"HUBSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"PATHSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STEPSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"EDGESOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"JITOSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"DSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"BONKSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"VSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"HSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    # {\"token\": \"ARB\", \"token_category\": \"Layer 2 Token\"},\n",
    "    # {\"token\": \"OP\", \"token_category\": \"Layer 2 Token\"},\n",
    "    # {\"token\": \"MODE\", \"token_category\": \"Layer 2 Token\"},\n",
    "]\n",
    "\n",
    "token_categories = pd.DataFrame(token_data)\n",
    "\n",
    "token_categories[\"token\"] = token_categories[\"token\"].str.upper()\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    \"Dexes\": \"Trading\",\n",
    "    \"Liquidity manager\": \"Yield\",\n",
    "    \"Derivatives\": \"Derivatives\",\n",
    "    \"Yield Aggregator\": \"Yield\",\n",
    "    \"Indexes\": \"Yield\",\n",
    "    \"Bridge\": \"Trading\",\n",
    "    \"Leveraged Farming\": \"Yield\",\n",
    "    \"Cross Chain\": \"Trading\",\n",
    "    \"CDP\": \"Lending\",\n",
    "    \"Farm\": \"Yield\",\n",
    "    \"Options\": \"Trading\",\n",
    "    \"DCA Tools\": \"Trading\",\n",
    "    \"Services\": \"TradFi/Fintech\",\n",
    "    \"Chain\": \"TradFi/Fintech\",\n",
    "    \"Privacy\": \"TradFi/Fintech\",\n",
    "    \"RWA\": \"TradFi/Fintech\",\n",
    "    \"Payments\": \"TradFi/Fintech\",\n",
    "    \"Launchpad\": \"TradFi/Fintech\",\n",
    "    \"Synthetics\": \"Derivatives\",\n",
    "    \"SoFi\": \"TradFi/Fintech\",\n",
    "    \"Prediction Market\": \"Trading\",\n",
    "    \"Token Locker\": \"Yield\",\n",
    "    \"Yield Lottery\": \"Yield\",\n",
    "    \"Algo-Stables\": \"Stablecoins\",\n",
    "    \"DEX Aggregator\": \"Trading\",\n",
    "    \"Liquid Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Governance Incentives\": \"Yield\",\n",
    "    \"Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Liquid Staking\": \"Liquid Staking\",\n",
    "    \"Uncollateralized Lending\": \"Lending\",\n",
    "    \"Managed Token Pools\": \"Trading\",\n",
    "    \"Insurance\": \"TradFi/Fintech\",\n",
    "    \"NFT Marketplace\": \"Trading\",\n",
    "    \"NFT Lending\": \"Lending\",\n",
    "    \"Options Vault\": \"Trading\",\n",
    "    \"NftFi\": \"Trading\",\n",
    "    \"Basis Trading\": \"Trading\",\n",
    "    \"Bug Bounty\": \"TradFi/Fintech\",\n",
    "    \"OTC Marketplace\": \"Trading\",\n",
    "    \"Reserve Currency\": \"Stablecoins\",\n",
    "    \"Gaming\": \"Other\",\n",
    "    \"AI Agents\": \"TradFi/Fintech\",\n",
    "    \"Treasury Manager\": \"TradFi/Fintech\",\n",
    "    \"CDP Manager\": \"Lending\",\n",
    "    \"Decentralized Stablecoin\": \"Stablecoins\",\n",
    "    \"Restaked BTC\": \"Restaking/Liquid Restaking\",\n",
    "    \"RWA Lending\": \"Lending\",\n",
    "    \"Staking Pool\": \"Staking/Liquid Staking\",\n",
    "    \"CeDeFi\": \"TradFi/Fintech\",\n",
    "    \"Staking\": \"Staking/Liquid Staking\",\n",
    "    \"Oracle\": \"Other\",\n",
    "    \"Ponzi\": \"Other\",\n",
    "    \"Anchor BTC\": \"Other\",\n",
    "    \"Decentralized BTC\": \"Other\",\n",
    "    \"CEX\": \"Other\",\n",
    "    \"Lending\": \"Lending\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5350965-d78c-4c9d-a2b7-635200d3e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-12-17 09:41:24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mloaded vault from .env file   \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mvault.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m32\u001b[0m\n",
      "\u001b[2m2024-12-17 09:41:24\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mloaded vault: 17 items        \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mvault.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m76\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from op_analytics.coreutils.duckdb_inmem.client import init_client\n",
    "from op_analytics.coreutils.duckdb_inmem.localcopy import dump_local_copy, load_local_copy\n",
    "from op_analytics.datasources.defillama.dataaccess import DefiLlama\n",
    "\n",
    "duckdb_client = init_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0b274",
   "metadata": {},
   "source": [
    "- Pull this data fresh, should be okay to leave protocol metadata date as-is\n",
    "- I would use \"2024-11-30\" as your latest date, we ran into a few data issues with more recent data\n",
    "- Make sure your secrets are up to date, Pedro updated them on Dec 2nd to work with GCS\n",
    "- There could be lingering data issues but Pedro addressed a bunch today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd55048d-53b6-496e-b7c5-118490e380d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-12-17 09:41:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mquerying markers for 'defillama/protocols_token_tvl_v1' DateFilter(min_date=datetime.date(2023, 12, 1), max_date=None, datevals=None)\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdailydata.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m107\u001b[0m\n",
      "\u001b[2m2024-12-17 09:41:25\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mconnecting to OPLABS Clickhouse client...\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mclient.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m25\u001b[0m\n",
      "\u001b[2m2024-12-17 09:41:26\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1minitialized OPLABS Clickhouse client.\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mclient.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m37\u001b[0m\n",
      "\u001b[2m2024-12-17 09:41:26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m480 markers found             \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdailydata.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m121\u001b[0m\n",
      "\u001b[2m2024-12-17 09:41:26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m383 distinct paths            \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdailydata.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m127\u001b[0m\n",
      "\u001b[2m2024-12-17 09:41:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mregistered view: 'defillama_protocols_token_tvl_v1' using 383 parquet paths\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mclient.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m53\u001b[0m\n",
      "┌──────────────────────────────────┐\n",
      "│               name               │\n",
      "│             varchar              │\n",
      "├──────────────────────────────────┤\n",
      "│ defillama_protocols_token_tvl_v1 │\n",
      "└──────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view1 = DefiLlama.PROTOCOLS_TOKEN_TVL.read(min_date=\"2023-12-01\")\n",
    "\n",
    "df_protocol_tvl = duckdb_client.sql(\n",
    "f\"\"\"\n",
    "SELECT\n",
    "    dt,\n",
    "    protocol_slug,\n",
    "    chain,\n",
    "    token,\n",
    "    app_token_tvl,\n",
    "    app_token_tvl_usd\n",
    "FROM {view1}\n",
    "\"\"\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d00107-db79-488f-af4e-0b0957da2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-12-17 09:42:04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mquerying markers for 'defillama/protocols_metadata_v1' DateFilter(min_date=datetime.date(2024, 12, 15), max_date=None, datevals=None)\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdailydata.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m107\u001b[0m\n",
      "\u001b[2m2024-12-17 09:42:04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m3 markers found               \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdailydata.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m121\u001b[0m\n",
      "\u001b[2m2024-12-17 09:42:04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m3 distinct paths              \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdailydata.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m127\u001b[0m\n",
      "\u001b[2m2024-12-17 09:42:05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mregistered view: 'defillama_protocols_metadata_v1' using 3 parquet paths\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mclient.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m53\u001b[0m\n",
      "┌──────────────────────────────────┐\n",
      "│               name               │\n",
      "│             varchar              │\n",
      "├──────────────────────────────────┤\n",
      "│ defillama_protocols_metadata_v1  │\n",
      "│ defillama_protocols_token_tvl_v1 │\n",
      "└──────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view2 = DefiLlama.PROTOCOLS_METADATA.read(min_date=\"2024-12-15\")\n",
    "\n",
    "df_metadata = duckdb_client.sql(\n",
    "f\"\"\"\n",
    "SELECT \n",
    "    protocol_name,\n",
    "    protocol_slug,\n",
    "    protocol_category,\n",
    "    parent_protocol,\n",
    "    CASE WHEN misrepresented_tokens = 'True' THEN 1\n",
    "        WHEN misrepresented_tokens = 'False' THEN 0\n",
    "        ELSE 0\n",
    "    END AS misrepresented_tokens\n",
    "FROM {view2}\n",
    "\"\"\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a11d010-2a7c-4ca4-8f63-610d6baeff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this didn't yield useful results (pun intended)\n",
    "\n",
    "# YIELD_ENDPOINT = \"https://yields.llama.fi/pools\"\n",
    "# session = new_session()\n",
    "# yield_data = get_data(session, YIELD_ENDPOINT)\n",
    "\n",
    "# yield_lists = []\n",
    "\n",
    "# for yield_pool in yield_data[\"data\"]:\n",
    "#     chain = yield_pool[\"chain\"]\n",
    "#     project = yield_pool[\"project\"]\n",
    "#     pool = yield_pool[\"pool\"]\n",
    "#     symbol = yield_pool[\"symbol\"]\n",
    "#     underlying_tokens = yield_pool[\"underlyingTokens\"] \n",
    "#     yield_lists.append(\n",
    "#         {\n",
    "#             \"chain_name\": chain,\n",
    "#             \"protocol_slug\": project,\n",
    "#             \"pool\": pool,\n",
    "#             \"symbol\": symbol\n",
    "#             \"underlying_tokens\": underlying_tokens\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# df_yield = pd.DataFrame(yield_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "65091202-3302-401a-b1da-05f5d1d94554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24351a9c-f1c0-421c-b017-3a715d8318d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1924fc25-9786-4fe7-9821-3f430406ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates due to an ongoing data upload issue\n",
    "df_all = pd.merge(\n",
    "    df_metadata.drop_duplicates(), \n",
    "    df_protocol_tvl.drop_duplicates(), \n",
    "    on=\"protocol_slug\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f611d808-d3e9-4723-ba37-03b057700e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data and join alignment and token categories\n",
    "df_all = pd.merge(df_all, alignment_df, on=\"chain\", how=\"left\")\n",
    "df_all[\"alignment\"] = df_all[\"alignment\"].fillna(\"Other\")\n",
    "df_all = pd.merge(df_all, token_categories, on=\"token\", how=\"left\")\n",
    "df_all[\"token_category\"] = df_all[\"token_category\"].fillna(\"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d1c25dc-58a1-4c19-b8ca-17b3b36e4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain level misrepresented tokens\n",
    "df_misrep = (\n",
    "    df_all[df_all.dt == df_all[\"dt\"].max()-pd.Timedelta(days=1)]\n",
    "    [[\"protocol_slug\", \"chain\", \"misrepresented_tokens\", \"token\"]]\n",
    "    .groupby([\"protocol_slug\", \"chain\", \"misrepresented_tokens\"])\n",
    "    .agg(\n",
    "        token_count=(\"token\", \"nunique\"),\n",
    "        has_usdt=(\"token\", lambda x: 1 if \"USDT\" in x.values else 0)\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_misrep[\"chain_misrepresented_tokens\"] = (\n",
    "    (df_misrep[\"misrepresented_tokens\"] == 1) \n",
    "    & (df_misrep[\"token_count\"] == 1) \n",
    "    & (df_misrep[\"has_usdt\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "df_all = pd.merge(\n",
    "    df_all, \n",
    "    df_misrep[[\"protocol_slug\", \"chain\", \"chain_misrepresented_tokens\"]], \n",
    "    on=[\"protocol_slug\", \"chain\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115af18e-e8e8-41f7-bfb4-d17046e8a8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "797379cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove protocols and chains\n",
    "\n",
    "def matches_filter_pattern(s):\n",
    "    return any(re.search(pattern, s, re.IGNORECASE) for pattern in PATTERNS_TO_FILTER)\n",
    "\n",
    "df_all[\"chain\"] = df_all[\"chain\"].astype(str)\n",
    "\n",
    "df_chain_protocol = df_all[[\"chain\", \"protocol_slug\", \"protocol_category\"]].drop_duplicates()\n",
    "\n",
    "df_chain_protocol[\"protocol_filters\"] = (\n",
    "    df_chain_protocol[\"chain\"].apply(matches_filter_pattern)\n",
    "    | (df_chain_protocol[\"protocol_slug\"] == \"polygon-bridge-&-staking\")\n",
    "    | df_chain_protocol[\"protocol_slug\"].str.endswith(\"-cex\")\n",
    "    | df_chain_protocol.protocol_category.isin(CATEGORIES_TO_FILTER)\n",
    ").astype(int)\n",
    "\n",
    "# small subset for analysis, actual logic will include more (all?) chains\n",
    "df_chain_protocol[\"chains_to_keep\"] = (\n",
    "    (df_all.alignment.isin([\"OP Chain\", \"OP Stack Fork\"]) \n",
    "    | df_all.chain.isin([\"Ethereum\", \"Arbitrum\", \"Solana\", \"Polygon\", \"Sui\"]))\n",
    "    ).astype(int)\n",
    "\n",
    "filter_mask = (df_chain_protocol.protocol_filters == 0) & (df_chain_protocol.chains_to_keep == 1)\n",
    "\n",
    "df_filtered = pd.merge(\n",
    "    df_all,\n",
    "    df_chain_protocol[filter_mask][[\"chain\", \"protocol_slug\", \"protocol_category\"]],\n",
    "    on=[\"chain\", \"protocol_slug\", \"protocol_category\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bd0896e-19c4-4e71-b6b0-054b2e15a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc data processing\n",
    "df_filtered[\"dt\"] = pd.to_datetime(df_filtered[\"dt\"])\n",
    "df_filtered[\"parent_protocol\"] = df_filtered[\"parent_protocol\"].str.replace(\"parent#\", \"\")\n",
    "df_filtered[\"token\"] = df_filtered[\"token\"].str.upper()\n",
    "df_filtered[\"token_category\"] = df_filtered[\"token_category\"].fillna(\"Other\")\n",
    "\n",
    "df_filtered[\"token_category_misrep\"] = np.where(\n",
    "    (df_filtered.chain_misrepresented_tokens == 1),\n",
    "    \"Misrepresented TVL\", \n",
    "    df_filtered.token_category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7cf4092-ce9c-43d7-ac5c-5ea5b3c8b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"protocol_category_mapped\"] = df_filtered[\"protocol_category\"].map(mapping, na_action=\"ignore\")\n",
    "df_filtered.loc[df_filtered[\"protocol_category_mapped\"].isna(), \"protocol_category_mapped\"] = df_filtered[\"protocol_category\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d631d-5359-4026-9e45-c218b4f11231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a89ff0-291d-4507-8aeb-630efba8ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this to find the tokens of interest to manually  map to source protocols\n",
    "\n",
    "chains = [\"Ethereum\", \"Base\", \"Mode\", \"Optimism\", \"Arbitrum\", \"Scroll\"]\n",
    "\n",
    "top_tokens = []\n",
    "for chain in chains:\n",
    "    df_chain =  df_filtered[\n",
    "        (df_filtered.dt == \"2024-12-01\")\n",
    "        * (df_filtered.chain == chain)\n",
    "    ]\n",
    "    top_tvl = df_chain[[\"token\", \"app_token_tvl_usd\"]].groupby(\"token\").sum().reset_index().sort_values(by=\"app_token_tvl_usd\", ascending=False)\n",
    "\n",
    "    top_tvl[\"cumulative_percent\"] = (top_tvl[\"app_token_tvl_usd\"].cumsum() / top_tvl[\"app_token_tvl_usd\"].sum()) * 100\n",
    "    \n",
    "    # Filter rows where the cumulative percentage is less than or equal to 99%\n",
    "    top_pct_tvl = top_tvl[top_tvl[\"cumulative_percent\"] <= 95]\n",
    "    \n",
    "    # Drop the cumulative_percent column if you no longer need it\n",
    "    top_pct_tvl = top_pct_tvl.drop(columns=[\"cumulative_percent\"])\n",
    "\n",
    "    top_tokens += top_tokens.token.to_list()\n",
    "\n",
    "top_tokens = list(set(top_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a38b93-2ac8-4119-a1c6-6755656dd2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe97a287-2da7-4ff4-bebd-fcabd0e6c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.7 environment at /Users/chuck/codebase/op-analytics/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 29ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2718cb23-c8df-4717-8304-f40b142fceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "a60f45ed-bc94-4bea-8aba-35f8fccb5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_token = pd.read_csv(\"source_token_mapping_20241201.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "ae8c44bd-9287-4f6d-9a64-4d56e42477cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_high = df_filtered[\n",
    "     (df_filtered.chain == \"Ethereum\")\n",
    "    & (df_filtered.dt == \"2024-12-10\")\n",
    "]\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_filtered_high, \n",
    "    df_source_token, \n",
    "    on=\"token\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "99b94073-fcf8-4af1-920a-f0a4a9c8613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apps_tvl = (\n",
    "    df_filtered[\n",
    "        (df_filtered.chain == \"Ethereum\")\n",
    "        & (df_filtered.dt == \"2024-12-10\")\n",
    "    ]\n",
    "    .groupby(\"parent_protocol\")\n",
    "    .agg(app_tvl_usd=(\"app_token_tvl_usd\", \"sum\"))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "0b6693cc-b34a-4a80-a77e-bcf25650dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_apps_tvl.rename(columns={\"parent_protocol\": \"source_protocol\", \"app_tvl_usd\": \"source_app_tvl_usd\"}),\n",
    "    on=\"source_protocol\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_apps_tvl.rename(columns={\"app_tvl_usd\": \"parent_app_tvl_usd\"}),\n",
    "    on=\"parent_protocol\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3217b05-6050-4696-8c1a-938401f5240f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "b24ab907-794e-4295-a72b-0a708cd4f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_groups = (\n",
    "    df_merged\n",
    "    .groupby([\"source_protocol\", \"parent_protocol\", \"source_app_tvl_usd\", \"parent_app_tvl_usd\"])\n",
    "    .agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226b6a7-eaa6-4950-9096-9af22aa6fc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "0abd6329-23c2-4f78-a832-44b66b7ed653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_744.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#insane graph chatgpt made for me\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import community as community_louvain\n",
    "\n",
    "def create_protocol_network_graph(df):\n",
    "    # Initialize a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with size attributes (sized by source_app_tvl_usd and parent_app_tvl_usd)\n",
    "    for _, row in df.iterrows():\n",
    "        source = row[\"source_protocol\"]\n",
    "        target = row[\"parent_protocol\"]\n",
    "        source_tvl = row[\"source_app_tvl_usd\"]\n",
    "        parent_tvl = row[\"parent_app_tvl_usd\"]\n",
    "        edge_weight = row[\"app_token_tvl_usd\"]\n",
    "\n",
    "        # Add source and target nodes with TVL as attributes\n",
    "        G.add_node(source, tvl=source_tvl)\n",
    "        G.add_node(target, tvl=parent_tvl)\n",
    "\n",
    "        # Add edge with 'app_token_tvl_usd' as weight\n",
    "        G.add_edge(source, target, weight=edge_weight)\n",
    "\n",
    "    # Detect communities using Louvain method\n",
    "    partition = community_louvain.best_partition(G.to_undirected())\n",
    "\n",
    "    # Add community information to each node\n",
    "    for node, community_id in partition.items():\n",
    "        G.nodes[node][\"community\"] = community_id\n",
    "\n",
    "    # Generate positions using spring layout, adjusting for community clusters\n",
    "    pos = nx.spring_layout(G, k=0.4, seed=42)  # k controls node spacing\n",
    "\n",
    "    # Extract edge data for plotting\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_widths = []\n",
    "    arrows = []\n",
    "\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_widths.append(edge[2]['weight'])\n",
    "\n",
    "        # Add arrow annotation for the edge\n",
    "        arrows.append(\n",
    "            go.layout.Annotation(\n",
    "                x=x1,\n",
    "                y=y1,\n",
    "                ax=x0,\n",
    "                ay=y0,\n",
    "                xref=\"x\",\n",
    "                yref=\"y\",\n",
    "                axref=\"x\",\n",
    "                ayref=\"y\",\n",
    "                showarrow=True,\n",
    "                arrowhead=2,\n",
    "                arrowsize=1,\n",
    "                arrowwidth=1,\n",
    "                arrowcolor=\"#888\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Normalize edge widths for better visualization\n",
    "    max_width = max(edge_widths) if edge_widths else 1\n",
    "    edge_widths = [w / max_width * 5 + 1 for w in edge_widths]\n",
    "\n",
    "    # Create edges with arrows\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        line=dict(width=1, color=\"#888\"),\n",
    "        hoverinfo=\"none\",\n",
    "        mode=\"lines\",\n",
    "    )\n",
    "\n",
    "    # Extract node data for plotting\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_sizes = []\n",
    "    node_text = []\n",
    "    node_colors = []\n",
    "\n",
    "    for node in G.nodes(data=True):\n",
    "        x, y = pos[node[0]]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_sizes.append(node[1][\"tvl\"])\n",
    "        node_text.append(node[0])\n",
    "        node_colors.append(partition[node[0]])  # Color nodes based on their community\n",
    "\n",
    "    # Normalize node sizes for better visualization\n",
    "    max_node_size = max(node_sizes) if node_sizes else 1\n",
    "    node_sizes = [s / max_node_size * 50 + 10 for s in node_sizes]\n",
    "\n",
    "    # Create nodes\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode=\"markers+text\",\n",
    "        text=node_text,\n",
    "        textposition=\"top center\",\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(\n",
    "            size=node_sizes,\n",
    "            color=node_colors,\n",
    "            colorscale=\"Viridis\",\n",
    "            line_width=2,\n",
    "            colorbar=dict(title=\"Community\"),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title=\"Protocol Network Graph with Community Grouping and Directional Arrows\",\n",
    "                        showlegend=False,\n",
    "                        hovermode=\"closest\",\n",
    "                        margin=dict(b=0, l=0, r=0, t=0),\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        annotations=arrows  # Add arrows to the layout\n",
    "                    ))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# # Call the function\n",
    "create_protocol_network_graph(df_app_groups[df_app_groups.parent_app_tvl_usd >= 1_000_000]\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f34601-656b-4132-bfa6-9a7f817e8e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd6d56-edd0-4fc2-8f52-b10f05059121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "op-analytics",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
