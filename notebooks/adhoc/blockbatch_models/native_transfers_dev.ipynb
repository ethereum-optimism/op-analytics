{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from op_analytics.coreutils.partitioned.location import DataLocation\n",
    "from op_analytics.coreutils.partitioned.reader import DataReader\n",
    "from op_analytics.datapipeline.etl.ingestion.reader.byblock import construct_readers_byblock\n",
    "from op_analytics.datapipeline.etl.ingestion.reader.request import BlockBatchRequest\n",
    "from op_analytics.datapipeline.models.compute.modelspec import ModelsDataSpec\n",
    "from op_analytics.datapipeline.models.compute.testutils import setup_execution_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"native_transfers\"\n",
    "\n",
    "\n",
    "# Prepare data raeders\n",
    "data_spec = ModelsDataSpec(models=[model_name],\n",
    "    root_path_prefix=\"blockbatch\")\n",
    "blockbatch_request = BlockBatchRequest.build(\n",
    "    chains=[\"op\"],\n",
    "    range_spec=\"@20241118:+1\",\n",
    "    root_paths_to_read=data_spec.input_root_paths,\n",
    ")\n",
    "readers: list[DataReader] = construct_readers_byblock(\n",
    "    blockbatch_request=blockbatch_request,\n",
    "    read_from=DataLocation.GCS,\n",
    ")\n",
    "\n",
    "\n",
    "# Show details for the batch we are processing.\n",
    "pprint(readers[0])\n",
    "\n",
    "# Set up execution context and get handles to model input args.\n",
    "# In subsequent cells you can use the model input args however you want.\n",
    "ctx, input_datasets, auxiliary_templates = setup_execution_context(\n",
    "    model_name=model_name,\n",
    "    data_reader=readers[0],  # use the first reader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ctx.client.sql(\"SHOW TABLES\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This matches the test's overall count query\n",
    "block_filter_sql = \"(block_number IN (128145990, 128145989) OR block_number % 100 < 2)\"\n",
    "\n",
    "num_native_transfers = ctx.client.sql(\n",
    "    f\"SELECT COUNT(*) as num_native_transfers FROM native_transfers WHERE {block_filter_sql}\"\n",
    ").pl().to_dicts()[0][\"num_native_transfers\"]\n",
    "print(\"num_native_transfers:\", num_native_transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_view = input_datasets[\"ingestion/traces_v1\"].create_view()\n",
    "\n",
    "native_transfers = auxiliary_templates[\"native_transfers\"].to_relation(\n",
    "    duckdb_context=ctx,\n",
    "    template_parameters={\n",
    "        \"raw_traces\": traces_view,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_transfers = (\n",
    "    native_transfers\n",
    "    .filter(\"transfer_type = 'native'\")\n",
    "    .project(\"*\")\n",
    ")\n",
    "df = ctx.client.sql(f\"SELECT * FROM native_transfers\").df()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
