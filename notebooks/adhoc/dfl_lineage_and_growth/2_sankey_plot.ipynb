{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "\n",
    "def group_small_values(df, col, threshold):\n",
    "    \"\"\"\n",
    "    Group values in 'col' whose total TVL < threshold into 'Others'.\n",
    "    \"\"\"\n",
    "    totals = df.groupby(col)[\"app_token_tvl_usd\"].sum()\n",
    "    small_values = totals[totals < threshold].index\n",
    "    df[col] = df[col].apply(lambda x: x if x not in small_values else \"Others\")\n",
    "    return df\n",
    "\n",
    "def build_sankey_df(df, columns_order, threshold=0.03):\n",
    "    \"\"\"\n",
    "    Summarize TVL for a 3-level Sankey chart, e.g. [left, mid, right].e\n",
    "    \"\"\"\n",
    "    left_col, mid_col, right_col = columns_order\n",
    "    df_sankey = df.groupby([left_col, mid_col, right_col], as_index=False).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "\n",
    "    total_val = df_sankey[\"app_token_tvl_usd\"].sum()\n",
    "    cutoff = threshold * total_val\n",
    "\n",
    "    # Consolidate small entries\n",
    "    df_sankey = group_small_values(df_sankey, left_col, cutoff)\n",
    "    df_sankey = group_small_values(df_sankey, mid_col, cutoff)\n",
    "    df_sankey = group_small_values(df_sankey, right_col, cutoff)\n",
    "\n",
    "    # Re-aggregate after grouping\n",
    "    df_sankey = df_sankey.groupby([left_col, mid_col, right_col], as_index=False).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "    return df_sankey\n",
    "\n",
    "def build_sankey_links_and_nodes(df_sankey, columns_order):\n",
    "    \"\"\"\n",
    "    Convert the 3-col DataFrame into Sankey link/node arrays.\n",
    "    \"\"\"\n",
    "    left_col, mid_col, right_col = columns_order\n",
    "\n",
    "    left_vals = df_sankey[left_col].unique().tolist()\n",
    "    mid_vals = df_sankey[mid_col].unique().tolist()\n",
    "    right_vals = df_sankey[right_col].unique().tolist()\n",
    "\n",
    "    idx_left = {v: i for i, v in enumerate(left_vals)}\n",
    "    idx_mid = {v: i + len(left_vals) for i, v in enumerate(mid_vals)}\n",
    "    idx_right = {v: i + len(left_vals) + len(mid_vals) for i, v in enumerate(right_vals)}\n",
    "\n",
    "    # Links left->mid\n",
    "    lm_df = df_sankey.groupby([left_col, mid_col], as_index=False).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "    lm_source = lm_df[left_col].map(idx_left)\n",
    "    lm_target = lm_df[mid_col].map(idx_mid)\n",
    "    lm_value = lm_df[\"app_token_tvl_usd\"]\n",
    "\n",
    "    # Links mid->right\n",
    "    mr_df = df_sankey.groupby([mid_col, right_col], as_index=False).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "    mr_source = mr_df[mid_col].map(idx_mid)\n",
    "    mr_target = mr_df[right_col].map(idx_right)\n",
    "    mr_value = mr_df[\"app_token_tvl_usd\"]\n",
    "\n",
    "    link_source = pd.concat([lm_source, mr_source], ignore_index=True)\n",
    "    link_target = pd.concat([lm_target, mr_target], ignore_index=True)\n",
    "    link_value = pd.concat([lm_value, mr_value], ignore_index=True)\n",
    "\n",
    "    node_labels = left_vals + mid_vals + right_vals\n",
    "    return node_labels, link_source, link_target, link_value\n",
    "\n",
    "def random_color():\n",
    "    r = lambda: random.randint(0,255)\n",
    "    return f'#{r():02X}{r():02X}{r():02X}'\n",
    "\n",
    "def assign_node_colors(node_labels):\n",
    "    \"\"\"\n",
    "    Assign random (but reproducible) colors to each node label. \n",
    "    We'll make \"Others\" gray if present.\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    color_map = {lbl: random_color() for lbl in node_labels}\n",
    "    if \"Others\" in color_map:\n",
    "        color_map[\"Others\"] = \"#999999\"\n",
    "    return [color_map[lbl] for lbl in node_labels]\n",
    "\n",
    "def plot_sankey(df_sankey, column_labels_map, columns_order, snapshot_date, threshold=0.03, note=None):\n",
    "    \"\"\"\n",
    "    Build and show a Sankey chart.\n",
    "    \"\"\"\n",
    "    if df_sankey.empty:\n",
    "        raise ValueError(\"No data available after filters. Sankey would be empty.\")\n",
    "\n",
    "    node_labels, link_source, link_target, link_value = build_sankey_links_and_nodes(df_sankey, columns_order)\n",
    "    node_colors = assign_node_colors(node_labels)\n",
    "\n",
    "    total_tvl = df_sankey[\"app_token_tvl_usd\"].sum()\n",
    "\n",
    "    left_col, mid_col, right_col = columns_order\n",
    "    left_lbl = column_labels_map.get(left_col, left_col)\n",
    "    mid_lbl = column_labels_map.get(mid_col, mid_col)\n",
    "    right_lbl = column_labels_map.get(right_col, right_col)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[go.Sankey(\n",
    "            arrangement='snap',\n",
    "            node=dict(\n",
    "                label=node_labels,\n",
    "                pad=15,\n",
    "                thickness=20,\n",
    "                line=dict(color=\"black\", width=0.5),\n",
    "                color=node_colors\n",
    "            ),\n",
    "            link=dict(\n",
    "                source=link_source,\n",
    "                target=link_target,\n",
    "                value=link_value,\n",
    "                color=\"#cccccc\",  # all links gray, or customize if you'd like\n",
    "                customdata=(link_value / 1e6), \n",
    "                hovertemplate='TVL: %{customdata:.2f}M USD<extra></extra>'\n",
    "            )\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': \"Protocol Token Lineage - \" + snapshot_date,\n",
    "            'font': {'size': 15}\n",
    "        },\n",
    "        annotations=[\n",
    "            dict(\n",
    "                x=0.0,\n",
    "                y=-0.35,\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                text=note,\n",
    "                showarrow=False,\n",
    "                font=dict(size=10),\n",
    "                align='left'\n",
    "            ),\n",
    "            dict(\n",
    "                x=0,\n",
    "                y=1.1,\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                text=f\"<b>{left_lbl}</b>\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=12),\n",
    "                align='center'\n",
    "            ),\n",
    "            dict(\n",
    "                x=0.5,\n",
    "                y=1.1,\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                text=f\"<b>{mid_lbl}</b>\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=12),\n",
    "                align='center'\n",
    "            ),\n",
    "            dict(\n",
    "                x=1,\n",
    "                y=1.1,\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                text=f\"<b>{right_lbl}</b>\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=12),\n",
    "                align='center'\n",
    "            ),\n",
    "            dict(\n",
    "                x=0, y=-0.10, xref='paper', yref='paper',\n",
    "                text=f\"<b>Total TVL Shown: ${total_tvl/1e9:,.2f}B</b>\",\n",
    "                showarrow=False, font=dict(size=12)\n",
    "            )\n",
    "        ],\n",
    "        font_size=10,\n",
    "        margin=dict(l=50, r=50, b=150, t=100),\n",
    "        autosize=True,\n",
    "        width=950, height=600\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"protocol_data_cleaned_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_tokens = pd.read_csv(\"token_mapping.csv\")\n",
    "df_source_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(columns=[\"project\", \"source_protocol\", \"token_category\"], inplace=True)\n",
    "df_all = df_all.merge(df_source_tokens, on=\"token\", how=\"left\")\n",
    "df = df_all[df_all[\"dt\"] == \"2025-01-05\"]\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_category_map = {\n",
    "    \"Dexes\": \"Dexes\",\n",
    "    \"Liquidity manager\": \"Yield\",\n",
    "    \"Derivatives\": \"Derivatives\",\n",
    "    \"Yield Aggregator\": \"Yield\",\n",
    "    \"Indexes\": \"Yield\",\n",
    "    \"Bridge\": \"Bridge\",\n",
    "    \"Leveraged Farming\": \"Yield\",\n",
    "    \"Cross Chain\": \"Bridge\",\n",
    "    \"CDP\": \"Lending\",\n",
    "    \"Farm\": \"Yield\",\n",
    "    \"Options\": \"Other Trading\",\n",
    "    \"DCA Tools\": \"Other Trading\",\n",
    "    \"Services\": \"TradFi/Fintech\",\n",
    "    \"Chain\": \"TradFi/Fintech\",\n",
    "    \"Privacy\": \"TradFi/Fintech\",\n",
    "    \"RWA\": \"TradFi/Fintech\",\n",
    "    \"Payments\": \"TradFi/Fintech\",\n",
    "    \"Launchpad\": \"TradFi/Fintech\",\n",
    "    \"Synthetics\": \"Derivatives\",\n",
    "    \"SoFi\": \"TradFi/Fintech\",\n",
    "    \"Prediction Market\": \"Other Trading\",\n",
    "    \"Token Locker\": \"Yield\",\n",
    "    \"Yield Lottery\": \"Yield\",\n",
    "    \"Algo-Stables\": \"Stablecoins\",\n",
    "    \"DEX Aggregator\": \"Dexes\",\n",
    "    \"Liquid Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Governance Incentives\": \"Yield\",\n",
    "    \"Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Liquid Staking\": \"Liquid Staking\",\n",
    "    \"Uncollateralized Lending\": \"Lending\",\n",
    "    \"Managed Token Pools\": \"Other Trading\",\n",
    "    \"Insurance\": \"TradFi/Fintech\",\n",
    "    \"NFT Marketplace\": \"Other Trading\",\n",
    "    \"NFT Lending\": \"Lending\",\n",
    "    \"Options Vault\": \"Other Trading\",\n",
    "    \"NftFi\": \"Other Trading\",\n",
    "    \"Basis Trading\": \"Other Trading\",\n",
    "    \"Bug Bounty\": \"TradFi/Fintech\",\n",
    "    \"OTC Marketplace\": \"Other Trading\",\n",
    "    \"Reserve Currency\": \"Stablecoins\",\n",
    "    \"Gaming\": \"Other\",\n",
    "    \"AI Agents\": \"TradFi/Fintech\",\n",
    "    \"Treasury Manager\": \"TradFi/Fintech\",\n",
    "    \"CDP Manager\": \"Lending\",\n",
    "    \"Decentralized Stablecoin\": \"Stablecoins\",\n",
    "    \"Restaked BTC\": \"Restaking/Liquid Restaking\",\n",
    "    \"RWA Lending\": \"Lending\",\n",
    "    \"Staking Pool\": \"Staking/Liquid Staking\",\n",
    "    \"CeDeFi\": \"TradFi/Fintech\",\n",
    "    \"Staking\": \"Staking/Liquid Staking\",\n",
    "    \"Oracle\": \"Other\",\n",
    "    \"Ponzi\": \"Other\",\n",
    "    \"Anchor BTC\": \"Other\",\n",
    "    \"Decentralized BTC\": \"Other\",\n",
    "    \"CEX\": \"Other\",\n",
    "    \"Lending\": \"Lending\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the TVL % Share of each protocol category\n",
    "# tvl_by_category = df[df[\"protocol_category_mapped\"] != \"Other\"].groupby(\"protocol_category_mapped\").agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "tvl_by_category = df.groupby(\"protocol_category_mapped\").agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "tvl_by_category[\"app_token_tvl_usd\"] = tvl_by_category[\"app_token_tvl_usd\"] / 1e6  # Convert to millions\n",
    "total_tvl = tvl_by_category[\"app_token_tvl_usd\"].sum()\n",
    "tvl_by_category[\"tvl_share\"] = tvl_by_category[\"app_token_tvl_usd\"] / total_tvl * 100\n",
    "tvl_by_category = tvl_by_category.sort_values(\"app_token_tvl_usd\", ascending=False)\n",
    "tvl_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sankey = df_all.groupby(COLUMNS_ORDER, as_index=False).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "df_sankey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_sankey_df(df, columns_order, threshold=0.03):\n",
    "    \"\"\"\n",
    "    Summarize TVL for a 3-level Sankey chart, e.g. [left, mid, right].e\n",
    "    \"\"\"\n",
    "    left_col, mid_col, right_col = columns_order\n",
    "    df_sankey = df.groupby([left_col, mid_col, right_col], as_index=False).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "\n",
    "    total_val = df_sankey[\"app_token_tvl_usd\"].sum()\n",
    "    cutoff = threshold * total_val\n",
    "\n",
    "    # Consolidate small entries\n",
    "    df_sankey = group_small_values(df_sankey, left_col, cutoff)\n",
    "    df_sankey = group_small_values(df_sankey, mid_col, cutoff)\n",
    "    df_sankey = group_small_values(df_sankey, right_col, cutoff)\n",
    "\n",
    "    # Re-aggregate after grouping\n",
    "    df_sankey = df_sankey.groupby([left_col, mid_col, right_col], as_index=False).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    "    return df_sankey\n",
    "\n",
    "# Column label map for friendlier Sankey headings\n",
    "COLUMN_LABELS_MAP = {\n",
    "    \"source_protocol\": \"Token Issuer\",\n",
    "    \"parent_protocol\": \"Protocol Destination\",\n",
    "    \"token\": \"Token\",\n",
    "    # \"token_category\": \"Token Category\" (if you want a 3rd or 4th dimension)\n",
    "}\n",
    "\n",
    "# %%\n",
    "# 2. Pick a snapshot date & apply filters\n",
    "SNAPSHOT_DATE = \"2025-01-05\"\n",
    "\n",
    "\n",
    "# Example filters\n",
    "selected_chains = df_all.chain.unique().tolist()\n",
    "selected_chains = [\"Base\"]\n",
    "selected_protocol_categories = df_all.protocol_category.unique().tolist()\n",
    "selected_protocols = df_all.protocol_slug.unique().tolist()\n",
    "selected_token_categories = df_all.token_category.unique().tolist()\n",
    "selected_token_categories = [\"Native Asset\"]\n",
    "selected_tokens = df_all.token.unique().tolist()\n",
    "# selected_tokens = [\"ARB\"]\n",
    "\n",
    "\n",
    "# selected_tokens = [t for t in selected_tokens if \"ETH\" in str(t)]\n",
    "\n",
    "df_focus = df_all[df_all[\"dt\"] == SNAPSHOT_DATE]\n",
    "\n",
    "# Filtering Data\n",
    "df_focus = df_focus[\n",
    "    df_all.chain.isin(selected_chains)\n",
    "    & df_all.protocol_category.isin(selected_protocol_categories)\n",
    "    & df_all.token_category.isin(selected_token_categories)\n",
    "    & df_all.protocol_slug.isin(selected_protocols)\n",
    "    & df_all.token.isin(selected_tokens)\n",
    "].copy()\n",
    "\n",
    "print(f\"Rows matching {SNAPSHOT_DATE}: {df_focus.shape[0]}\")\n",
    "\n",
    "# 3. Build the Sankey DF (choose columns for left->middle->right)\n",
    "COLUMNS_ORDER = [\"source_protocol\", \"token\", \"parent_protocol\"]\n",
    "THRESHOLD = 0.025  # Group anything under 3% total TVL into 'Others'\n",
    "\n",
    "df_sankey = build_sankey_df(df_focus, COLUMNS_ORDER, threshold=THRESHOLD)\n",
    "print(f\"df_sankey shape after grouping: {df_sankey.shape}\")\n",
    "\n",
    "def truncate_list(lst, n=10):\n",
    "    return ', '.join(lst[:n]) + (', ...' if len(lst) > n else '')\n",
    "\n",
    "note =(\n",
    "    f\"<b>Filters:</b><br>\"\n",
    "    f\"• <b>Chains:</b> {truncate_list(selected_chains)}<br>\"\n",
    "    f\"• <b>Protocol Categories:</b> {truncate_list(selected_protocol_categories)}<br>\"\n",
    "    f\"• <b>Asset Type:</b> {truncate_list(selected_token_categories)}<br><br>\"\n",
    "    # f\"• <b>Tokens:</b> {truncate_list(selected_tokens)}<br><br>\"\n",
    "    f\"Note: Smaller protocols than {THRESHOLD*100}% of total TVL are grouped under 'Others'.\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "# 4. Plot\n",
    "fig = plot_sankey(\n",
    "    df_sankey=df_sankey,\n",
    "    column_labels_map=COLUMN_LABELS_MAP,\n",
    "    columns_order=COLUMNS_ORDER,\n",
    "    snapshot_date=SNAPSHOT_DATE,\n",
    "    threshold=THRESHOLD,\n",
    "    note = note\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
