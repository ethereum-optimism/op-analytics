{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245f7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from op_analytics.cli.subcommands.pulls.defillama.dataaccess import DefiLlama\n",
    "\n",
    "import urllib3\n",
    "import warnings\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "urllib3.disable_warnings()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf536b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc55e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERNS_TO_FILTER = [\n",
    "    \"-borrowed\",\n",
    "    \"-vesting\",\n",
    "    \"-staking\",\n",
    "    \"-pool2\",\n",
    "    \"-treasury\",\n",
    "    \"-cex\",\n",
    "    \"^treasury$\",\n",
    "    \"^borrowed$\",\n",
    "    \"^staking$\",\n",
    "    \"^pool2$\",\n",
    "    \"^pool2$\",\n",
    "    \"polygon-bridge-&-staking\",  # Added this as a full match\n",
    "    \".*-cex$\",  # Added this to match anything ending with -cex\n",
    "]\n",
    "\n",
    "CATEGORIES_TO_FILTER = [\"CEX\", \"Chain\"]\n",
    "\n",
    "alignment_dict = {\n",
    "    \"Metis\": \"OP Stack fork\",\n",
    "    \"Blast\": \"OP Stack fork\",\n",
    "    \"Mantle\": \"OP Stack fork\",\n",
    "    \"Zircuit\": \"OP Stack fork\",\n",
    "    \"RSS3\": \"OP Stack fork\",\n",
    "    \"Rollux\": \"OP Stack fork\",\n",
    "    \"Ancient8\": \"OP Stack fork\",\n",
    "    \"Manta\": \"OP Stack fork\",\n",
    "    \"Cyber\": \"OP Chain\",\n",
    "    \"Mint\": \"OP Chain\",\n",
    "    \"Ham\": \"OP Chain\",\n",
    "    \"Polynomial\": \"OP Chain\",\n",
    "    \"Lisk\": \"OP Chain\",\n",
    "    \"BOB\": \"OP Chain\",\n",
    "    \"Mode\": \"OP Chain\",\n",
    "    \"World Chain\": \"OP Chain\",\n",
    "    \"Base\": \"OP Chain\",\n",
    "    \"Kroma\": \"OP Chain\",\n",
    "    \"Boba\": \"OP Chain\",\n",
    "    \"Fraxtal\": \"OP Chain\",\n",
    "    \"Optimism\": \"OP Chain\",\n",
    "    \"Shape\": \"OP Chain\",\n",
    "    \"Zora\": \"OP Chain\"\n",
    "}\n",
    "\n",
    "alignment_df = pd.DataFrame(list(alignment_dict.items()), columns=[\"chain\", \"alignment\"])\n",
    "\n",
    "token_data = [\n",
    "    {\"token\": \"ETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"WETH\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"SOL\", \"token_category\": \"Native Asset\"},\n",
    "    {\"token\": \"wBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "    {\"token\": \"cbBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "    {\"token\": \"MBTC\", \"token_category\": \"Wrapped Assets\"},\n",
    "\n",
    "    {\"token\": \"stETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"wstETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"eETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"weETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"sfrxETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"rETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"mETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"rsETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"cbETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"ezETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"rswETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"swETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"frxETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"ETHX\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"lsETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"oETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"EBTC\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"LBTC\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"SUPEROETHB\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"WSUPEROETHB\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"TETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"OSETH\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"cmETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"WRSETH\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"WEETH.BASE\", \"token_category\": \"Liquid Restaking\"},\n",
    "    \n",
    "    {\"token\": \"USDC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDT\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"FDUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"PYUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"TUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"DAI\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDE\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"FRAX\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"EURC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"AGEUR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDS\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDB\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"DOLA\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"SUSDE\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD0++\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD0\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"SUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"CRVUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDC+\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDZ\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"STAR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USDBC\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"USD+\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"CDXUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"HYUSD\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"STAR\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"EURS\", \"token_category\": \"Stablecoins\"},\n",
    "    {\"token\": \"AXLEUROC\", \"token_category\": \"Stablecoins\"},\n",
    "\n",
    "\n",
    "    # Solana Liquid staking\n",
    "    {\"token\": \"MSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"JUPSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"BNSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"SSOL\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"BBSOL\", \"token_category\": \"Liquid Restaking\"},\n",
    "    {\"token\": \"LAINESOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STRONGSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"HUBSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"PATHSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"STEPSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"EDGESOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"JITOSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"DSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"BONKSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"VSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    {\"token\": \"HSOL\", \"token_category\": \"Liquid Staking\"},\n",
    "    # {\"token\": \"ARB\", \"token_category\": \"Layer 2 Token\"},\n",
    "    # {\"token\": \"OP\", \"token_category\": \"Layer 2 Token\"},\n",
    "    # {\"token\": \"MODE\", \"token_category\": \"Layer 2 Token\"},\n",
    "]\n",
    "\n",
    "token_categories = pd.DataFrame(token_data)\n",
    "\n",
    "token_categories[\"token\"] = token_categories[\"token\"].str.upper()\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    \"Dexes\": \"Trading\",\n",
    "    \"Liquidity manager\": \"Yield\",\n",
    "    \"Derivatives\": \"Derivatives\",\n",
    "    \"Yield Aggregator\": \"Yield\",\n",
    "    \"Indexes\": \"Yield\",\n",
    "    \"Bridge\": \"Trading\",\n",
    "    \"Leveraged Farming\": \"Yield\",\n",
    "    \"Cross Chain\": \"Trading\",\n",
    "    \"CDP\": \"Lending\",\n",
    "    \"Farm\": \"Yield\",\n",
    "    \"Options\": \"Trading\",\n",
    "    \"DCA Tools\": \"Trading\",\n",
    "    \"Services\": \"TradFi/Fintech\",\n",
    "    \"Chain\": \"TradFi/Fintech\",\n",
    "    \"Privacy\": \"TradFi/Fintech\",\n",
    "    \"RWA\": \"TradFi/Fintech\",\n",
    "    \"Payments\": \"TradFi/Fintech\",\n",
    "    \"Launchpad\": \"TradFi/Fintech\",\n",
    "    \"Synthetics\": \"Derivatives\",\n",
    "    \"SoFi\": \"TradFi/Fintech\",\n",
    "    \"Prediction Market\": \"Trading\",\n",
    "    \"Token Locker\": \"Yield\",\n",
    "    \"Yield Lottery\": \"Yield\",\n",
    "    \"Algo-Stables\": \"Stablecoins\",\n",
    "    \"DEX Aggregator\": \"Trading\",\n",
    "    \"Liquid Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Governance Incentives\": \"Yield\",\n",
    "    \"Restaking\": \"Restaking/Liquid Restaking\",\n",
    "    \"Liquid Staking\": \"Liquid Staking\",\n",
    "    \"Uncollateralized Lending\": \"Lending\",\n",
    "    \"Managed Token Pools\": \"Trading\",\n",
    "    \"Insurance\": \"TradFi/Fintech\",\n",
    "    \"NFT Marketplace\": \"Trading\",\n",
    "    \"NFT Lending\": \"Lending\",\n",
    "    \"Options Vault\": \"Trading\",\n",
    "    \"NftFi\": \"Trading\",\n",
    "    \"Basis Trading\": \"Trading\",\n",
    "    \"Bug Bounty\": \"TradFi/Fintech\",\n",
    "    \"OTC Marketplace\": \"Trading\",\n",
    "    \"Reserve Currency\": \"Stablecoins\",\n",
    "    \"Gaming\": \"Other\",\n",
    "    \"AI Agents\": \"TradFi/Fintech\",\n",
    "    \"Treasury Manager\": \"TradFi/Fintech\",\n",
    "    \"CDP Manager\": \"Lending\",\n",
    "    \"Decentralized Stablecoin\": \"Stablecoins\",\n",
    "    \"Restaked BTC\": \"Restaking/Liquid Restaking\",\n",
    "    \"RWA Lending\": \"Lending\",\n",
    "    \"Staking Pool\": \"Staking/Liquid Staking\",\n",
    "    \"CeDeFi\": \"TradFi/Fintech\",\n",
    "    \"Staking\": \"Staking/Liquid Staking\",\n",
    "    \"Oracle\": \"Other\",\n",
    "    \"Ponzi\": \"Other\",\n",
    "    \"Anchor BTC\": \"Other\",\n",
    "    \"Decentralized BTC\": \"Other\",\n",
    "    \"CEX\": \"Other\",\n",
    "    \"Lending\": \"Lending\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5350965-d78c-4c9d-a2b7-635200d3e12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec0b274",
   "metadata": {},
   "source": [
    "- Pull this data fresh, should be okay to leave protocol metadata date as-is\n",
    "- I would use \"2024-11-30\" as your latest date, we ran into a few data issues with more recent data\n",
    "- Make sure your secrets are up to date, Pedro updated them on Dec 2nd to work with GCS\n",
    "- There could be lingering data issues but Pedro addressed a bunch today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd55048d-53b6-496e-b7c5-118490e380d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-12-06 13:33:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mloaded vault from .env file   \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mvault.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m32\u001b[0m\n",
      "\u001b[2m2024-12-06 13:33:14\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mloaded vault: 17 items        \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mvault.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m76\u001b[0m\n",
      "\u001b[2m2024-12-06 13:33:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mquerying markers for 'protocols_token_tvl_v1' DateFilter(min_date=datetime.date(2023, 12, 1), max_date=None, datevals=None)\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m203\u001b[0m\n",
      "\u001b[2m2024-12-06 13:33:14\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mconnecting to OPLABS Clickhouse client...\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mclient.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m26\u001b[0m\n",
      "\u001b[2m2024-12-06 13:33:15\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1minitialized OPLABS Clickhouse client.\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mclient.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m38\u001b[0m\n",
      "\u001b[2m2024-12-06 13:33:15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m384 markers found             \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m217\u001b[0m\n",
      "\u001b[2m2024-12-06 13:33:15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m369 distinct paths            \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m223\u001b[0m\n",
      "\u001b[2m2024-12-06 13:33:17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mregistered view 'protocols_token_tvl_v1' using 369 parquet paths\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m233\u001b[0m\n",
      "┌────────────────────────┐\n",
      "│          name          │\n",
      "│        varchar         │\n",
      "├────────────────────────┤\n",
      "│ protocols_token_tvl_v1 │\n",
      "└────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duckdb_client = DefiLlama.PROTOCOLS_TOKEN_TVL.read(min_date=\"2023-12-01\")\n",
    "\n",
    "df_protocol_tvl = duckdb_client.sql(\n",
    "\"\"\"\n",
    "SELECT\n",
    "    dt,\n",
    "    protocol_slug,\n",
    "    chain,\n",
    "    token,\n",
    "    app_token_tvl,\n",
    "    app_token_tvl_usd\n",
    "FROM protocols_token_tvl_v1\n",
    "\"\"\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d00107-db79-488f-af4e-0b0957da2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-12-06 13:35:09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mquerying markers for 'protocols_metadata_v1' DateFilter(min_date=datetime.date(2024, 12, 3), max_date=None, datevals=None)\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m203\u001b[0m\n",
      "\u001b[2m2024-12-06 13:35:09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m1 markers found               \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m217\u001b[0m\n",
      "\u001b[2m2024-12-06 13:35:09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m1 distinct paths              \u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m223\u001b[0m\n",
      "\u001b[2m2024-12-06 13:35:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mregistered view 'protocols_metadata_v1' using 1 parquet paths\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mdataaccess.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m233\u001b[0m\n",
      "┌────────────────────────┐\n",
      "│          name          │\n",
      "│        varchar         │\n",
      "├────────────────────────┤\n",
      "│ protocols_metadata_v1  │\n",
      "│ protocols_token_tvl_v1 │\n",
      "└────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duckdb_client = DefiLlama.PROTOCOLS_METADATA.read(min_date=\"2024-12-03\")\n",
    "\n",
    "df_metadata = duckdb_client.sql(\n",
    "\"\"\"\n",
    "SELECT \n",
    "    protocol_name,\n",
    "    protocol_slug,\n",
    "    protocol_category,\n",
    "    parent_protocol,\n",
    "    CASE WHEN misrepresented_tokens = 'True' THEN 1\n",
    "        WHEN misrepresented_tokens = 'False' THEN 0\n",
    "        ELSE 0\n",
    "    END AS misrepresented_tokens\n",
    "FROM protocols_metadata_v1\n",
    "\"\"\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1924fc25-9786-4fe7-9821-3f430406ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates due to an ongoing data upload issue\n",
    "df_all = pd.merge(\n",
    "    df_metadata.drop_duplicates(), \n",
    "    df_protocol_tvl.drop_duplicates(), \n",
    "    on=\"protocol_slug\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f611d808-d3e9-4723-ba37-03b057700e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data and join alignment and token categories\n",
    "df_all = pd.merge(df_all, alignment_df, on=\"chain\", how=\"left\")\n",
    "df_all[\"alignment\"] = df_all[\"alignment\"].fillna(\"Other\")\n",
    "df_all = pd.merge(df_all, token_categories, on=\"token\", how=\"left\")\n",
    "df_all[\"token_category\"] = df_all[\"token_category\"].fillna(\"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1c25dc-58a1-4c19-b8ca-17b3b36e4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain level misrepresented tokens\n",
    "df_misrep = (\n",
    "    df_all[df_all.dt == df_all[\"dt\"].max()-pd.Timedelta(days=1)]\n",
    "    [[\"protocol_slug\", \"chain\", \"misrepresented_tokens\", \"token\"]]\n",
    "    .groupby([\"protocol_slug\", \"chain\", \"misrepresented_tokens\"])\n",
    "    .agg(\n",
    "        token_count=(\"token\", \"nunique\"),\n",
    "        has_usdt=(\"token\", lambda x: 1 if \"USDT\" in x.values else 0)\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_misrep[\"chain_misrepresented_tokens\"] = (\n",
    "    (df_misrep[\"misrepresented_tokens\"] == 1) \n",
    "    & (df_misrep[\"token_count\"] == 1) \n",
    "    & (df_misrep[\"has_usdt\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "df_all = pd.merge(\n",
    "    df_all, \n",
    "    df_misrep[[\"protocol_slug\", \"chain\", \"chain_misrepresented_tokens\"]], \n",
    "    on=[\"protocol_slug\", \"chain\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115af18e-e8e8-41f7-bfb4-d17046e8a8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "797379cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove protocols and chains\n",
    "\n",
    "def matches_filter_pattern(s):\n",
    "    return any(re.search(pattern, s, re.IGNORECASE) for pattern in PATTERNS_TO_FILTER)\n",
    "\n",
    "df_all[\"chain\"] = df_all[\"chain\"].astype(str)\n",
    "\n",
    "df_chain_protocol = df_all[[\"chain\", \"protocol_slug\", \"protocol_category\"]].drop_duplicates()\n",
    "\n",
    "df_chain_protocol[\"protocol_filters\"] = (\n",
    "    df_chain_protocol[\"chain\"].apply(matches_filter_pattern)\n",
    "    | (df_chain_protocol[\"protocol_slug\"] == \"polygon-bridge-&-staking\")\n",
    "    | df_chain_protocol[\"protocol_slug\"].str.endswith(\"-cex\")\n",
    "    | df_chain_protocol.protocol_category.isin(CATEGORIES_TO_FILTER)\n",
    ").astype(int)\n",
    "\n",
    "# small subset for analysis, actual logic will include more (all?) chains\n",
    "df_chain_protocol[\"chains_to_keep\"] = (\n",
    "    (df_all.alignment.isin([\"OP Chain\", \"OP Stack Fork\"]) \n",
    "    | df_all.chain.isin([\"Ethereum\", \"Arbitrum\", \"Solana\", \"Polygon\", \"Sui\"]))\n",
    "    ).astype(int)\n",
    "\n",
    "filter_mask = (df_chain_protocol.protocol_filters == 0) & (df_chain_protocol.chains_to_keep == 1)\n",
    "\n",
    "df_filtered = pd.merge(\n",
    "    df_all,\n",
    "    df_chain_protocol[filter_mask][[\"chain\", \"protocol_slug\", \"protocol_category\"]],\n",
    "    on=[\"chain\", \"protocol_slug\", \"protocol_category\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd0896e-19c4-4e71-b6b0-054b2e15a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc data processing\n",
    "df_filtered[\"dt\"] = pd.to_datetime(df_filtered[\"dt\"])\n",
    "df_filtered[\"parent_protocol\"] = df_filtered[\"parent_protocol\"].str.replace(\"parent#\", \"\")\n",
    "df_filtered[\"token\"] = df_filtered[\"token\"].str.upper()\n",
    "df_filtered[\"token_category\"] = df_filtered[\"token_category\"].fillna(\"Other\")\n",
    "\n",
    "df_filtered[\"token_category_misrep\"] = np.where(\n",
    "    (df_filtered.chain_misrepresented_tokens == 1),\n",
    "    \"Misrepresented TVL\", \n",
    "    df_filtered.token_category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7cf4092-ce9c-43d7-ac5c-5ea5b3c8b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"protocol_category_mapped\"] = df_filtered[\"protocol_category\"].map(mapping, na_action=\"ignore\")\n",
    "df_filtered.loc[df_filtered[\"protocol_category_mapped\"].isna(), \"protocol_category_mapped\"] = df_filtered[\"protocol_category\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe6c95-1fc6-48c3-b8f4-afbef4c524df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85c4855-7437-43d7-8e7b-14aa07b12c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot token category TVL breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a890a1f8-9164-43c0-a6a5-dd636df4dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = (df_filtered[\n",
    "    (df_filtered.dt == \"2024-12-01\")\n",
    " & (df_filtered.chain.isin([\"Base\", \"Optimism\", \"Mode\", \"Solana\", \"Arbitrum\", \"Sui\", \"Polygon\"]))\n",
    " & (df_filtered.parent_protocol != \"hyperliquid-bridge\")\n",
    "    ].groupby([\"chain\", \"token_category_misrep\"]).agg({\"app_token_tvl_usd\": \"sum\"})\n",
    " .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edc881-ab53-44d0-b18d-e67a09dc62c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bf39ae15-1336-4c73-8be3-b0872012718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_192.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_category_order = [\n",
    "    \"Native Asset\", \n",
    "    \"Liquid Staking\", \n",
    "    \"Liquid Restaking\", \n",
    "    \"Stablecoins\", \n",
    "    \"Wrapped Assets\", \n",
    "    \"Other\", \n",
    "    \"Misrepresented TVL\"\n",
    "]\n",
    "\n",
    "fig = px.bar(\n",
    "    token_df,\n",
    "    x=\"chain\",\n",
    "    y=\"percentage\",\n",
    "    color=\"token_category_misrep\",\n",
    "    title=\"Token Category Breakdown by Chain (Percentage)\",\n",
    "    labels={\n",
    "        \"percentage\": \"Percentage (%)\",\n",
    "        \"chain\": \"Chain\",\n",
    "        \"token_category_misrep\": \"Token Category\"\n",
    "    },\n",
    "    category_orders={\n",
    "        \"chain\": order,\n",
    "        \"token_category_misrep\": token_category_order\n",
    "    },\n",
    "    barmode=\"stack\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    xaxis_title=\"Chain\",\n",
    "    yaxis_title=\"Percentage (%)\",\n",
    "    legend_title_text=\"Token Category\",\n",
    "    margin=dict(t=50, l=25, r=25, b=50),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd6d56-edd0-4fc2-8f52-b10f05059121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3375562d-d7db-47fb-8305-3c0d1cdda6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_df(df, target_date, agg_cols, return_tokens=False):\n",
    "    target_date = pd.to_datetime(target_date)\n",
    "\n",
    "    target_df = df.loc[\n",
    "        df.dt == target_date, agg_cols + [\"token\", \"app_token_tvl\", \"app_token_tvl_usd\"]\n",
    "    ]\n",
    "    target_df_grouped = target_df.groupby(agg_cols + [\"token\"], as_index=False).sum()\n",
    "    target_df_grouped[\"usd_conversion_rate\"] = (\n",
    "        (target_df_grouped.app_token_tvl_usd / target_df_grouped.app_token_tvl)\n",
    "        .replace([float(\"inf\"), -float(\"inf\")], 0)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    previous_df = df.loc[\n",
    "        df.dt <= target_date,\n",
    "        [\"dt\"] + agg_cols + [\"token\", \"app_token_tvl\", \"app_token_tvl_usd\"],\n",
    "    ]\n",
    "    previous_df_grouped = previous_df.groupby([\"dt\"] + agg_cols + [\"token\"], as_index=False).sum()\n",
    "\n",
    "    # Merge target and previous data\n",
    "    df_flows = pd.merge(\n",
    "        target_df_grouped,\n",
    "        previous_df_grouped,\n",
    "        on=agg_cols + [\"token\"],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_previous\"),\n",
    "    )\n",
    "    df_flows[\"app_token_tvl_previous\"] = df_flows[\"app_token_tvl_previous\"].fillna(0)\n",
    "    df_flows[\"app_token_tvl_usd_previous\"] = df_flows[\"app_token_tvl_usd_previous\"].fillna(0)\n",
    "    df_flows[\"app_token_tvl_usd_previous_adjusted\"] = (\n",
    "        df_flows.app_token_tvl_previous * df_flows.usd_conversion_rate\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Group and aggregate\n",
    "    group_cols = [\"dt\"] + agg_cols + [\"token\"] if return_tokens else [\"dt\"] + agg_cols\n",
    "    df_flows_grouped = df_flows.groupby(group_cols, as_index=False).agg(\n",
    "        app_tvl_usd_target=(\"app_token_tvl_usd\", \"sum\"),\n",
    "        app_tvl_usd_previous=(\"app_token_tvl_usd_previous\", \"sum\"),\n",
    "        app_tvl_usd_previous_adjusted=(\"app_token_tvl_usd_previous_adjusted\", \"sum\"),\n",
    "        app_token_count=(\"token\", \"nunique\"),\n",
    "    )\n",
    "\n",
    "    # Calculate metrics\n",
    "    df_flows_grouped[\"net_flow_usd\"] = (\n",
    "        df_flows_grouped.app_tvl_usd_target - df_flows_grouped.app_tvl_usd_previous_adjusted\n",
    "    )\n",
    "    df_flows_grouped[\"net_change_tvl\"] = (\n",
    "        df_flows_grouped.app_tvl_usd_target - df_flows_grouped.app_tvl_usd_previous\n",
    "    )\n",
    "    df_flows_grouped[\"flow_percent_change\"] = (\n",
    "        df_flows_grouped.net_flow_usd / df_flows_grouped.app_tvl_usd_previous_adjusted * 100\n",
    "    )\n",
    "    df_flows_grouped[\"tvl_percent_change\"] = (\n",
    "        df_flows_grouped.net_change_tvl / df_flows_grouped.app_tvl_usd_previous * 100\n",
    "    )\n",
    "\n",
    "    # Replace infs and fillna\n",
    "    df_flows_grouped[\"flow_percent_change\"] = (\n",
    "        df_flows_grouped.flow_percent_change.replace([float(\"inf\"), -float(\"inf\")], 0).fillna(0) \n",
    "    )\n",
    "    df_flows_grouped[\"tvl_percent_change\"] = (\n",
    "        df_flows_grouped.tvl_percent_change.replace([float(\"inf\"), -float(\"inf\")], 0).fillna(0) \n",
    "    )\n",
    "    \n",
    "    return df_flows_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5c95c-d215-474d-a30b-e9cbce9a8e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6712e0d4-efea-47be-8696-a5fb507a67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = get_flow_df(df_filtered, \"2024-12-01\", [\"chain\", \"parent_protocol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa870611-3931-4a21-9b7f-6538a5e4cbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da1f9f07-d486-4efc-b083-1e6a31f11030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_top_protocols_over_time(flow_df, date_diff, chain, top_n=10):\n",
    "\n",
    "    max_date = pd.to_datetime(flow_df[\"dt\"].max())\n",
    "    previous_date = max_date - pd.Timedelta(days=date_diff)\n",
    "\n",
    "    chain_df = flow_df[(flow_df[\"chain\"] == chain) ]\n",
    "    n_day_df = chain_df[(chain_df[\"dt\"] == previous_date.strftime(\"%Y-%m-%d\"))]\n",
    "    \n",
    "    top_protocols = n_day_df.nlargest(top_n, \"net_flow_usd\")[\"parent_protocol\"]\n",
    "\n",
    "    top_protocols_df = chain_df[chain_df[\"parent_protocol\"].isin(top_protocols)]\n",
    "\n",
    "    fig = px.line(\n",
    "        top_protocols_df,\n",
    "        x=\"dt\",\n",
    "        y=\"app_tvl_usd_previous_adjusted\",\n",
    "        color=\"parent_protocol\",\n",
    "        title=f\"Growth of Top {top_n} Protocols on {chain} in Last {date_diff} Days\",\n",
    "        labels={\"app_tvl_usd_previous_adjusted\": \"Previous Adjusted TVL (USD)\", \"dt\": \"Date\", \"parent_protocol\": \"Protocol\"},\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_white\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Target Date Adjusted TVL (USD)\",\n",
    "        margin=dict(t=50, l=25, r=25, b=50),\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cbde7090-8a75-4daf-8dfe-529bc86e0756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_158.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_top_protocols_over_time(flow_df, 30, \"Base\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0925a33a-8273-4705-adbc-e00fdc6aa04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some treemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b3c119d-a056-4719-821d-707e5770a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nested_protocol_breakdown(data, date, chain, date_diff=90):\n",
    "\n",
    "    data[\"dt\"] = pd.to_datetime(data[\"dt\"])\n",
    "    target_date = pd.to_datetime(date)\n",
    "    previous_date = (target_date - pd.Timedelta(days=date_diff)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    filtered_data = data[\n",
    "        (data[\"dt\"] == target_date) & (data[\"chain\"] == chain) & (data[\"app_token_tvl_usd\"] >= 10_000)\n",
    "    ]\n",
    "\n",
    "    previous_data = data[\n",
    "        (data[\"dt\"] == previous_date) & (data[\"chain\"] == chain)\n",
    "    ]\n",
    "\n",
    "    merged_data = filtered_data.merge(\n",
    "        previous_data[[ \"protocol_category\", \"parent_protocol\", \"token_category\", \"app_token_tvl_usd\"]],\n",
    "        on=[ \"protocol_category\", \"parent_protocol\", \"token_category\"],\n",
    "        suffixes=(\"\", \"_previous\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    merged_data[\"app_token_tvl_usd_previous\"].fillna(0.01, inplace=True)\n",
    "\n",
    "    merged_data[\"percent_change\"] = (\n",
    "        (merged_data[\"app_token_tvl_usd\"] - merged_data[\"app_token_tvl_usd_previous\"])\n",
    "        / merged_data[\"app_token_tvl_usd_previous\"]\n",
    "    ) * 100\n",
    "\n",
    "    merged_data[\"percent_change\"] = merged_data[\"percent_change\"].clip(lower=-500, upper=500)\n",
    "\n",
    "    fig = px.treemap(\n",
    "        merged_data,\n",
    "        path=[px.Constant(\"Total\"), \"protocol_category\", \"parent_protocol\", \"token_category\"],\n",
    "        values=\"app_token_tvl_usd\", \n",
    "        color=\"percent_change\", \n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        range_color=[-100, 100],\n",
    "        title=f\"{chain}: Token Category <> App TVL Last {date_diff} Days\",\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return merged_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333644d-d11e-4e65-9405-10cd9e76cb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbb3b0fe-73f0-4c2f-b29f-de8292c8d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_breakdown = df_filtered.groupby([\"dt\", \"chain\", \"protocol_category\", \"parent_protocol\", \"token_category_misrep\"]).agg(\n",
    "    {\"app_token_tvl_usd\": \"sum\"}\n",
    ").reset_index().rename(columns={\"token_category_misrep\": \"token_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "340d1b60-0ee5-4411-b947-f54fab4f0f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_35.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = plot_nested_protocol_breakdown(protocol_breakdown, \"2024-11-20\", \"Solana\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e998ff7-5201-433f-b397-5acbdaa578e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74a4f01b-9dc2-4681-a2de-d43005e4cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_token_breakdown = df_filtered.groupby([\"dt\", \"chain\", \"protocol_category\", \"parent_protocol\", \"token_category_misrep\",  \"token\"]).agg(\n",
    "    {\"app_token_tvl_usd\": \"sum\"}\n",
    ").reset_index().rename(columns={\"token_category_misrep\": \"token_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974a5163-6367-4c39-a67b-f84ae0c084d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nested_protocol_token_breakdown(data, date, chain, date_diff=90):\n",
    "\n",
    "    data[\"dt\"] = pd.to_datetime(data[\"dt\"])\n",
    "    target_date = pd.to_datetime(date)\n",
    "    previous_date = (target_date - pd.Timedelta(days=date_diff)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    filtered_data = data[\n",
    "        (data[\"dt\"] == target_date) & (data[\"chain\"] == chain) & (data[\"app_token_tvl_usd\"] >= 10_000)\n",
    "    ]\n",
    "\n",
    "    previous_data = data[\n",
    "        (data[\"dt\"] == previous_date) & (data[\"chain\"] == chain)\n",
    "    ]\n",
    "\n",
    "    merged_data = filtered_data.merge(\n",
    "        previous_data[[ \"protocol_category\", \"parent_protocol\", \"token_category\", \"token\", \"app_token_tvl_usd\"]],\n",
    "        on=[ \"protocol_category\", \"parent_protocol\", \"token_category\", \"token\"],\n",
    "        suffixes=(\"\", \"_previous\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    merged_data[\"app_token_tvl_usd_previous\"].fillna(0.01, inplace=True)\n",
    "\n",
    "    merged_data[\"percent_change\"] = (\n",
    "        (merged_data[\"app_token_tvl_usd\"] - merged_data[\"app_token_tvl_usd_previous\"])\n",
    "        / merged_data[\"app_token_tvl_usd_previous\"]\n",
    "    ) * 100\n",
    "\n",
    "    merged_data[\"percent_change\"] = merged_data[\"percent_change\"].clip(lower=-500, upper=500)\n",
    "\n",
    "    fig = px.treemap(\n",
    "        merged_data,\n",
    "        path=[px.Constant(\"Total\"), \"protocol_category\", \"parent_protocol\", \"token_category\", \"token\"], \n",
    "        values=\"app_token_tvl_usd\", \n",
    "        color=\"percent_change\",\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        range_color=[-100, 100], \n",
    "        title=f\"{chain}: Token Category <> App TVL Last {date_diff} Days\",\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e984c76c-74ab-4425-9f37-8e4888208a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_nested_protocol_token_breakdown(protocol_token_breakdown, \"2024-12-01\", \"Base\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7887ca-3dba-4ac6-b6fb-d1ef273f08ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cd277-29b4-45d8-bb29-7465bafda761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a13fc6-ad4d-4ebd-b022-122318dcce18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8925ce9f-290b-429c-a3d7-dbdd25f16975",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_flows_stables = get_flow_df(\n",
    "    df_filtered[df_filtered.token_category_misrep == \"Stablecoins\"],\n",
    "    \"2024-12-01\", \n",
    "    [\"chain\", \"protocol_category\", \"parent_protocol\"],\n",
    "    return_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2e4c6181-b846-4deb-91ba-911920669a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_treemap_with_date_diff(df, date_diff, column_list):\n",
    "    \"\"\"\n",
    "    Plots a treemap based on a specified date calculated using max date minus date_diff.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        date_diff (int): The number of days to subtract from the max date to determine the target date.\n",
    "        column_list (list): List of columns to use as treemap layers (hierarchy).\n",
    "        value_col (str): Column to use for treemap values. Default is \"app_tvl_usd_target\".\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the treemap.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is in datetime format\n",
    "    df[\"dt\"] = pd.to_datetime(df[\"dt\"])\n",
    "\n",
    "    # Calculate the target date\n",
    "    max_date = df[\"dt\"].max()\n",
    "    target_date = max_date - pd.Timedelta(days=date_diff)\n",
    "\n",
    "    # Filter the DataFrame for the target date\n",
    "    filtered_df = df[df[\"dt\"] == target_date]\n",
    "\n",
    "    # Check if the filtered DataFrame is empty\n",
    "    if filtered_df.empty:\n",
    "        print(f\"No data available for the date {target_date.strftime('%Y-%m-%d')}.\")\n",
    "        return\n",
    "\n",
    "    # Create the treemap\n",
    "    fig = px.treemap(\n",
    "        filtered_df,\n",
    "        path=column_list,  # Add the hierarchy\n",
    "        values=\"app_tvl_usd_target\",  # Values for size\n",
    "        color=\"flow_percent_change\",  # Color based on the same column\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        range_color=[-200, 200],\n",
    "        title=f\"Treemap for {target_date.strftime('%Y-%m-%d')} (Layered by {', '.join(column_list)})\",\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        margin=dict(t=50, l=25, r=25, b=25),\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951112fe-ce19-4a1f-aa00-0a6b1638e04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be3d57-3ada-4f45-8c99-00b805bcd89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dad678b4-a39a-4f57-873e-eb1d03450f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_86.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_flows_stables = get_flow_df(\n",
    "    df_filtered[(df_filtered.token_category_misrep == \"Stablecoins\") & (df_filtered.protocol_category != \"Bridge\")],\n",
    "    \"2024-12-03\", \n",
    "    [\"chain\", \"protocol_category\", \"parent_protocol\"],\n",
    "    return_tokens=True\n",
    ")\n",
    "\n",
    "plot_treemap_with_date_diff(\n",
    "    net_flows_stables[(net_flows_stables.app_tvl_usd_target > 10_000)],\n",
    "    date_diff=30,\n",
    "    column_list=[\"chain\", \"protocol_category\", \"parent_protocol\", \"token\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b5adb62-673c-4e85-9493-79f3101a3696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_92.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_flows_stables = get_flow_df(\n",
    "    df_filtered[\n",
    "    (df_filtered.token_category_misrep == \"Stablecoins\") \n",
    "    & (df_filtered.protocol_category != \"Bridge\") \n",
    "    & (df_filtered.chain != \"Ethereum\")\n",
    "    ],\n",
    "    \"2024-12-03\", \n",
    "    [\"chain\", \"protocol_category\", \"parent_protocol\"],\n",
    "    return_tokens=True\n",
    ")\n",
    "\n",
    "plot_treemap_with_date_diff(\n",
    "    net_flows_stables[(net_flows_stables.app_tvl_usd_target > 10_000)],\n",
    "    date_diff=30,\n",
    "    column_list=[\"chain\", \"protocol_category\", \"parent_protocol\", \"token\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2574f4f0-591e-47b7-9a17-1f5efd874a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_90.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_flows_stables = get_flow_df(\n",
    "    df_filtered[(df_filtered.token_category_misrep == \"Native Asset\") & (df_filtered.protocol_category != \"Bridge\")],\n",
    "    \"2024-12-03\", \n",
    "    [\"chain\", \"protocol_category\", \"parent_protocol\"],\n",
    "    return_tokens=True\n",
    ")\n",
    "\n",
    "plot_treemap_with_date_diff(\n",
    "    net_flows_stables[(net_flows_stables.app_tvl_usd_target > 10_000)],\n",
    "    date_diff=30,\n",
    "    column_list=[\"chain\", \"protocol_category\", \"parent_protocol\", \"token\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120fcacc-2adf-4aaf-a21e-f0f3c8174033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea1d2f-a6b7-4da6-856b-5419f346a315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235dea3-6fdd-4c56-b142-7d15619f594e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "79a106f7-97a2-4c19-851f-989712457cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_242.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_flows = get_flow_df(\n",
    "    df_filtered[\n",
    "      (  df_filtered.chain.isin([\"Optimism\",]))\n",
    "        & (df_filtered.protocol_category != \"Bridge\")\n",
    "    \n",
    "    ],\n",
    "    \"2024-12-03\", \n",
    "    [\"chain\", \"protocol_category\", \"parent_protocol\"],\n",
    "    return_tokens=True\n",
    ")\n",
    "\n",
    "plot_treemap_with_date_diff(\n",
    "    net_flows[(net_flows.app_tvl_usd_target > 10_000)],\n",
    "    date_diff=30,\n",
    "    column_list=[\"chain\", \"protocol_category\", \"parent_protocol\", \"token\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c74370-2127-4ff1-9763-54078c5d4897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1fdebc4-c82a-42b3-ae3f-59fa6e337115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_stacked_tvl_over_time(df, chain_name, cat_col):\n",
    "    \"\"\"\n",
    "    Plots the percentage of Total TVL by category over time for a specified blockchain chain, with legend for only the top 10 categories by the last available date.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing 'date', 'chain', category column, and 'total_app_tvl_7d_avg'.\n",
    "        chain_name (str): The name of the chain to filter for (e.g., 'Ethereum').\n",
    "        cat_col (str): The name of the column representing categories.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a stacked bar plot.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specified chain\n",
    "    df_chain = df[df[\"chain\"] == chain_name]\n",
    "\n",
    "    # Check if there is data for the specified chain\n",
    "    if df_chain.empty:\n",
    "        print(f\"No data available for chain: {chain_name}\")\n",
    "        return\n",
    "\n",
    "    # Group by date and category and sum the TVLs\n",
    "    grouped = df_chain.groupby([\"dt\", cat_col]).app_token_tvl_usd.sum().reset_index()\n",
    "\n",
    "    # Calculate the total TVL per date to find percentages\n",
    "    total_per_date = grouped.groupby(\"dt\").app_token_tvl_usd.transform(\"sum\")\n",
    "\n",
    "    # Calculate percentage\n",
    "    grouped[\"percentage\"] = 100 * grouped[\"app_token_tvl_usd\"] / total_per_date\n",
    "\n",
    "    # Determine the maximum date\n",
    "    max_date = grouped[\"dt\"].max()\n",
    "\n",
    "    # Find the top 10 categories by percentage on the maximum date\n",
    "    top_categories = (\n",
    "        grouped[grouped[\"dt\"] == max_date]\n",
    "        .sort_values(by=\"percentage\", ascending=False)\n",
    "        .head(10)[cat_col]\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # Plot using Plotly Express\n",
    "    fig = px.bar(\n",
    "        grouped,\n",
    "        x=\"dt\",\n",
    "        y=\"percentage\",\n",
    "        color=cat_col,\n",
    "        labels={\"percentage\": \"Percentage of Total TVL\", cat_col: \"Category\"},\n",
    "        title=f\"Percentage of Total TVL by Category Over Time for {chain_name}\",\n",
    "        template=\"plotly_white\",\n",
    "        width=900,\n",
    "        height=600,\n",
    "    )\n",
    "    fig.update_layout(barmode=\"stack\", xaxis_title=\"Date\", yaxis_title=\"Percentage of Total TVL\")\n",
    "\n",
    "    # Update legend to show only top 10 categories\n",
    "    fig.for_each_trace(\n",
    "        lambda trace: trace.update(showlegend=True if trace.name in top_categories else False)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# plot_tvl_over_time(your_dataframe, 'Ethereum', 'parent_protocol')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00b41abd-7639-4d81-a1a3-47393d2bf1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_25.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stacked_tvl_over_time(\n",
    "    df_filtered,\n",
    "    \"Ethereum\",\n",
    "    \"protocol_category\"\n",
    "    \n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea42d434-3e32-40a8-82cd-e83cd8709592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_stacked_tvl_over_time(df, chain_name, cat_col):\n",
    "    \"\"\"\n",
    "    Plots the percentage of Total TVL by category over time for a specified blockchain chain, \n",
    "    with legend for only the top 10 categories by the last available date, ensuring categories\n",
    "    are ordered from largest to smallest at the final date, and styling the bars to appear \n",
    "    smooth without white gaps. The title is moved closer to the graph.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing 'dt', 'chain', category column, \n",
    "                           and 'app_token_tvl_usd' columns.\n",
    "        chain_name (str): The name of the chain to filter for (e.g., 'Ethereum').\n",
    "        cat_col (str): The name of the column representing categories.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a stacked bar plot.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the specified chain\n",
    "    df_chain = df[df[\"chain\"] == chain_name]\n",
    "\n",
    "    # Check if there is data for the specified chain\n",
    "    if df_chain.empty:\n",
    "        print(f\"No data available for chain: {chain_name}\")\n",
    "        return\n",
    "\n",
    "    # Group by date and category and sum the TVLs\n",
    "    grouped = df_chain.groupby([\"dt\", cat_col]).app_token_tvl_usd.sum().reset_index()\n",
    "\n",
    "    # Calculate the total TVL per date to find percentages\n",
    "    total_per_date = grouped.groupby(\"dt\").app_token_tvl_usd.transform(\"sum\")\n",
    "\n",
    "    # Calculate percentage\n",
    "    grouped[\"percentage\"] = 100 * grouped[\"app_token_tvl_usd\"] / total_per_date\n",
    "\n",
    "    # Determine the maximum date\n",
    "    max_date = grouped[\"dt\"].max()\n",
    "\n",
    "    # Find the top 10 categories by percentage on the maximum date\n",
    "    top_categories = (\n",
    "        grouped[grouped[\"dt\"] == max_date]\n",
    "        .sort_values(by=\"percentage\", ascending=False)\n",
    "        .head(10)[cat_col]\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # Create the bar plot, including category ordering\n",
    "    fig = px.bar(\n",
    "        grouped,\n",
    "        x=\"dt\",\n",
    "        y=\"percentage\",\n",
    "        color=cat_col,\n",
    "        labels={\"percentage\": \"Percentage of Total TVL\", cat_col: \"Category\"},\n",
    "        title=f\"Percentage of Total TVL by Category Over Time for {chain_name}\",\n",
    "        template=\"plotly_white\",\n",
    "        width=900,\n",
    "        height=600,\n",
    "        category_orders={cat_col: top_categories}  # Keep category ordering\n",
    "    )\n",
    "\n",
    "    # Set barmode to stack, remove gaps between bars, and remove outlines\n",
    "    fig.update_layout(\n",
    "        barmode=\"stack\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Percentage of Total TVL\",\n",
    "        bargap=0,\n",
    "        title=dict(\n",
    "            # Move title closer by adjusting the vertical position\n",
    "            y=0.95,\n",
    "            x=0.4,\n",
    "            xanchor='center',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        # Reduce the top margin to bring title closer to the plot area\n",
    "        margin=dict(t=50)\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker_line_width=0)\n",
    "\n",
    "    # Update legend to show only top 10 categories\n",
    "    fig.for_each_trace(\n",
    "        lambda trace: trace.update(showlegend=(trace.name in top_categories))\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3581d118-8f35-4c86-af5d-acb7f87cfcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_52.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stacked_tvl_over_time(\n",
    "    df_filtered[\n",
    "        (df_filtered.dt <= \"2024-10-15\")\n",
    "        & (df_filtered.protocol_category != \"Bridge\")\n",
    "    ],\n",
    "    \"Ethereum\",\n",
    "    \"protocol_category\"\n",
    "    \n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a08649c-ce31-4e76-b70a-8e5c9ea905b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_54.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stacked_tvl_over_time(\n",
    "    df_filtered[\n",
    "        (df_filtered.dt <= \"2024-10-15\")\n",
    "        & (df_filtered.protocol_category != \"Bridge\")\n",
    "    ],\n",
    "    \"Arbitrum\",\n",
    "    \"protocol_category\"\n",
    "    \n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83736f25-912f-4920-bf06-fa944ebfc90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_56.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stacked_tvl_over_time(\n",
    "    df_filtered[\n",
    "        (df_filtered.dt <= \"2024-10-15\")\n",
    "        & (df_filtered.protocol_category != \"Bridge\")\n",
    "    ],\n",
    "    \"Base\",\n",
    "    \"protocol_category\"\n",
    "    \n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2735d7e-8742-412b-b082-d71295117ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = \"2024-12-01\"\n",
    "exclude_categories = [\"Chain\", \"CEX\", \"Infrastructure\", \"Staking Pool\", \"Liquid Staking\", \"RWA\", \"CeDeFi\", \"Basis Trading\"]\n",
    "\n",
    "today_df = df_filtered[(df_filtered.dt == todays_date) & (df_filtered.protocol_category != \"Bridge\")]\n",
    "\n",
    "op_chain_totals = today_df[today_df[\"alignment\"] == \"OP Chain\"].groupby(\"token_category\")[\"app_token_tvl_usd\"].sum()\n",
    "\n",
    "# Convert the result to a DataFrame and set 'Superchain' as the index name\n",
    "op_chain_row = pd.DataFrame(op_chain_totals).transpose()\n",
    "op_chain_row.index = pd.Index([\"Superchain\"], name=\"chain\")  # Set 'Superchain' as the index\n",
    "\n",
    "# Add a 'Grand Total' column by summing across all token categories\n",
    "op_chain_row[\"Grand Total\"] = op_chain_row.sum(axis=1)\n",
    "\n",
    "\n",
    "today_tvl_pivot = today_df[(~today_df.protocol_category.isin(exclude_categories))].pivot_table(\n",
    "    values=\"app_token_tvl_usd\",\n",
    "    index=\"chain\",\n",
    "    columns=\"token_category\",\n",
    "    aggfunc=\"sum\",\n",
    "    margins=True,  # Adds a grand total row and column\n",
    "    margins_name=\"Grand Total\"  # Name of the grand total column and row\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39fad0-877a-44d3-b0d3-261f0753fe5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdbd58a8-f630-4cb3-9ec0-22c365888623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_76.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define the list of chains to include in the plot\n",
    "chains_to_include = [\"Solana\", \"Arbitrum\", \"Base\", \"Optimism\", \"Mode\", \"Sui\", \"Polygon\"]\n",
    "\n",
    "# Reset the index of `today_tvl_pivot` to make `chain` a column, then filter\n",
    "pivot_table_reset = today_tvl_pivot.reset_index().sort_values(by=\"Grand Total\", ascending=False)\n",
    "pivot_filtered = pivot_table_reset.query(\"chain in @chains_to_include\")\n",
    "\n",
    "# Filter columns to include only the categories of interest\n",
    "categories_to_plot = [\"Native Asset\", \"Liquid Staking\", \"Liquid Restaking\", \"Stablecoins\", \"Wrapped Assets\", \"Other\"]\n",
    "pivot_filtered = pivot_filtered.set_index(\"chain\")[categories_to_plot]\n",
    "\n",
    "# Create the stacked bar plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add a bar for each category to the stacked bar plot\n",
    "for category in categories_to_plot:\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=pivot_filtered.index,\n",
    "            y=pivot_filtered[category],\n",
    "            name=category\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Update layout for clarity and aesthetics\n",
    "fig.update_layout(\n",
    "    barmode=\"stack\",  # Stacked bars\n",
    "    title=\"USD Value by Chain and Token Category\",\n",
    "    xaxis_title=\"Chain\",\n",
    "    yaxis_title=\"Total USD Value\",\n",
    "    width=900,\n",
    "    height=600,\n",
    "    legend_title=\"Token Category\",\n",
    "    # yaxis_type=\"log\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "# fig.update_axes(type=\"log\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a8ce133c-027e-45e3-b983-a163abfa36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_stablecoin_tokens_by_chain(df, date, token_category=\"Stablecoins\", exclude_protocol=\"Bridge\", min_tvl=100000):\n",
    "    \"\"\"\n",
    "    Plots a stacked bar chart of total TVL for each token in a given token category \n",
    "    across multiple chains on a specific date, excluding a specified protocol category.\n",
    "    Only includes tokens with TVL >= min_tvl. The chains are ordered by total TVL,\n",
    "    and tokens are ordered by their global aggregate TVL across all chains.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing:\n",
    "                           - 'dt' (datetime): dates\n",
    "                           - 'chain' (str): chain name\n",
    "                           - 'token_category_misrep' (str): token category label\n",
    "                           - 'protocol_category' (str): protocol category label\n",
    "                           - 'token' (str): token identifier\n",
    "                           - 'app_token_tvl_usd' (float): raw TVL values\n",
    "        date (str or datetime): The date to filter on (e.g., '2024-12-01').\n",
    "        token_category (str): The token category to filter for (default: 'Stablecoins').\n",
    "        exclude_protocol (str): The protocol category to exclude (default: 'Bridge').\n",
    "        min_tvl (float): Minimum TVL threshold for tokens to be included (default: 100000).\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a stacked bar chart.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame based on the provided conditions\n",
    "    df_filtered = df[\n",
    "        (df.token_category_misrep == token_category) &\n",
    "        (df.protocol_category != exclude_protocol) &\n",
    "        (df.dt == pd.to_datetime(date))\n",
    "    ]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data available for the given filters on {date}.\")\n",
    "        return\n",
    "\n",
    "    # Group by chain and token, summing the TVL\n",
    "    grouped = df_filtered.groupby([\"chain\", \"token\"]).app_token_tvl_usd.sum().reset_index()\n",
    "\n",
    "    # Exclude tokens with total TVL under the specified threshold\n",
    "    grouped = grouped[grouped[\"app_token_tvl_usd\"] >= min_tvl]\n",
    "    if grouped.empty:\n",
    "        print(f\"No tokens meet the minimum TVL requirement of {min_tvl} USD on {date}.\")\n",
    "        return\n",
    "\n",
    "    # Determine the order of chains from largest to smallest total TVL\n",
    "    chain_totals = (\n",
    "        grouped.groupby(\"chain\")\n",
    "        .app_token_tvl_usd.sum()\n",
    "        .reset_index()\n",
    "        .sort_values(\"app_token_tvl_usd\", ascending=False)\n",
    "    )\n",
    "    chain_order = chain_totals[\"chain\"].tolist()\n",
    "\n",
    "    # Order tokens by their global aggregate TVL across all chains\n",
    "    token_totals = (\n",
    "        grouped.groupby(\"token\")\n",
    "        .app_token_tvl_usd.sum()\n",
    "        .reset_index()\n",
    "        .sort_values(\"app_token_tvl_usd\", ascending=False)\n",
    "    )\n",
    "    token_order = token_totals[\"token\"].tolist()\n",
    "\n",
    "    # Create the stacked bar chart\n",
    "    fig = px.bar(\n",
    "        grouped,\n",
    "        x=\"chain\",\n",
    "        y=\"app_token_tvl_usd\",\n",
    "        color=\"token\",\n",
    "        title=f\"Total {token_category} TVL by Token Across Chains on {date}\",\n",
    "        labels={\"chain\": \"Chain\", \"app_token_tvl_usd\": \"TVL (USD)\", \"token\": \"Token\"},\n",
    "        category_orders={\"chain\": chain_order, \"token\": token_order},  # Ordering chains and tokens by global totals\n",
    "        template=\"plotly_white\",\n",
    "        width=900,\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    # Configure layout for a stacked appearance without gaps\n",
    "    fig.update_layout(\n",
    "        barmode=\"stack\",\n",
    "        bargap=0.1,\n",
    "        xaxis_title=\"\",\n",
    "        yaxis_title=\"TVL (USD)\"\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker_line_width=0)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_stablecoin_tokens_by_chain(df_filtered, '2024-12-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e69f3e66-c2c9-48bf-9d6b-88958e875f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_118.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stablecoin_tokens_by_chain(df_filtered[\n",
    "    (df_filtered.chain.isin([\"Ethereum\", \"Solana\", \"Arbitrum\", \"Base\", \"Optimism\", \"Mode\", \"Sui\", \"Polygon\"]))\n",
    "],\n",
    "                                \"2024-12-01\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8ad83286-c616-4b1d-b301-30b5f97180f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_124.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stacked_tvl_over_time(\n",
    "    df_filtered[\n",
    "       (df_filtered.protocol_category != \"Bridge\")\n",
    "        # & (df_filtered.dt <= \"2024-10-15\")\n",
    "        & (df_filtered.token_category == \"Stablecoins\")\n",
    "    ],\n",
    "    \"Ethereum\",\n",
    "    \"token\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63061d9b-00b0-4db1-8222-5ac7b83a0b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "op-analytics",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
