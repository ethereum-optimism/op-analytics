{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto update imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from op_analytics.datasources.github.metrics.execute import execute_pull_pr_metrics\n",
    "from op_analytics.datasources.github.dataaccess import Github\n",
    "from op_analytics.coreutils.logger import structlog\n",
    "from op_analytics.coreutils.partitioned.dailydatautils import dt_summary\n",
    "\n",
    "log = structlog.get_logger()\n",
    "\n",
    "# Cell 2: Load and Verify Activity Data\n",
    "# Use the DailyDataset read functionality to load data\n",
    "try:\n",
    "    # Read all available data without date filters initially\n",
    "    activity_views = {\n",
    "        \"prs\": Github.PRS.read(),\n",
    "        \"pr_comments\": Github.PR_COMMENTS.read(),\n",
    "        \"pr_reviews\": Github.PR_REVIEWS.read(),\n",
    "    }\n",
    "    \n",
    "    # Query the data using DuckDB context\n",
    "    from op_analytics.coreutils.duckdb_inmem.client import init_client\n",
    "    duckdb_ctx = init_client()\n",
    "    \n",
    "    activity_dfs = {}\n",
    "    for name, view in activity_views.items():\n",
    "        df = duckdb_ctx.client.sql(f\"SELECT * FROM {view}\").pl()\n",
    "        activity_dfs[name] = df\n",
    "        \n",
    "        # Show data summary\n",
    "        summary = dt_summary(df)\n",
    "        log.info(\n",
    "            f\"loaded {name} data\",\n",
    "            rows=df.height,\n",
    "            date_range=[min(list(summary[\"dts\"].items())), max(list(summary[\"dts\"].items()))],\n",
    "            repos=df[\"repo\"].unique().to_list()\n",
    "        )\n",
    "        print(name)\n",
    "        print(view)\n",
    "        display(summary)\n",
    "except Exception as e:\n",
    "    log.error(\"Failed to load activity data\", error=str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in activity_dfs.items():\n",
    "    print(f\"Name: {name}, Columns: {df.columns}, df.schema: {df.schema}\")\n",
    "    print(df[\"dt\"].min(), df[\"dt\"].max())\n",
    "# Assert that all data is in the same date range\n",
    "assert activity_dfs[\"prs\"][\"dt\"].min() == activity_dfs[\"pr_comments\"][\"dt\"].min() == activity_dfs[\"pr_reviews\"][\"dt\"].min()\n",
    "assert activity_dfs[\"prs\"][\"dt\"].max() == activity_dfs[\"pr_comments\"][\"dt\"].max() == activity_dfs[\"pr_reviews\"][\"dt\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKFILL_START = activity_dfs[\"prs\"][\"dt\"].min()\n",
    "BACKFILL_END = activity_dfs[\"prs\"][\"dt\"].max()\n",
    "# Process all data at once\n",
    "log.info(\n",
    "    \"processing full date range\",\n",
    "    start=BACKFILL_START, \n",
    "    end=BACKFILL_END\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Execute metrics computation and write to GCS for full date range\n",
    "    summary = execute_pull_pr_metrics(\n",
    "        min_date=BACKFILL_START,\n",
    "        max_date=BACKFILL_END\n",
    "    )\n",
    "    log.info(\n",
    "        \"completed full date range\",\n",
    "        start=BACKFILL_START,\n",
    "        end=BACKFILL_END, \n",
    "        summary=summary\n",
    "    )\n",
    "except Exception as e:\n",
    "    log.error(\n",
    "        \"failed to process full date range\",\n",
    "        start=BACKFILL_START,\n",
    "        end=BACKFILL_END,\n",
    "        error=str(e)\n",
    "    )\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from op_analytics.coreutils.partitioned.dailydata import DataLocation\n",
    "pr_metrics = Github.PR_METRICS.read(location=DataLocation.LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: Create Clickhouse View\n",
    "Github.PR_METRICS.create_clickhouse_view()\n",
    "log.info(\"backfill and view creation completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
