{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# DeFiLlama Data Backfills\n",
        "\n",
        "This notebook allows you to backfill various DeFiLlama datasources with configurable parameters.\n",
        "\n",
        "## Available Datasources:\n",
        "\n",
        "1. **Volume, Fees, Revenue** - DEX trading volume, protocol fees, and revenue data by chain and protocol\n",
        "2. **Protocols TVL** - Total Value Locked for individual protocols with detailed breakdowns\n",
        "3. **Chain TVL** - Historical TVL data aggregated by blockchain \n",
        "4. **Stablecoins** - Stablecoin circulation and bridging data by chain\n",
        "5. **Yield Pools** - Yield farming pool data and APY information\n",
        "6. **Lend/Borrow Pools** - Lending protocol data including rates and volumes\n",
        "\n",
        "## Configuration Options:\n",
        "\n",
        "- **BACKFILL_DAYS**: Number of days to backfill (default 365)\n",
        "- **SPECIFIC_CHAIN**: Filter to a specific chain (e.g. \"optimism\", \"base\") or None for all\n",
        "- **SPECIFIC_PROTOCOL**: Filter to a specific protocol slug or None for all\n",
        "\n",
        "## Usage:\n",
        "\n",
        "1. Modify the configuration variables in the first cell\n",
        "2. Run the cells for the datasources you want to backfill\n",
        "3. Comment/uncomment sections as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from unittest.mock import patch\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from op_analytics.coreutils.partitioned import dailydatawrite\n",
        "from op_analytics.coreutils.partitioned.location import DataLocation\n",
        "\n",
        "\n",
        "def mock_location():\n",
        "    return DataLocation.GCS\n",
        "\n",
        "# Configuration\n",
        "os.environ[\"ALLOW_WRITE\"] = \"true\"\n",
        "\n",
        "# Backfill Configuration\n",
        "BACKFILL_DAYS = 365  # Number of days to backfill\n",
        "SPECIFIC_CHAIN = None  # Set to chain name (e.g. \"optimism\") to filter, or None for all chains\n",
        "SPECIFIC_PROTOCOL = None  # Set to protocol slug to filter, or None for all protocols\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Backfill Days: {BACKFILL_DAYS}\")\n",
        "print(f\"  Specific Chain: {SPECIFIC_CHAIN or 'All chains'}\")\n",
        "print(f\"  Specific Protocol: {SPECIFIC_PROTOCOL or 'All protocols'}\")\n",
        "print(f\"  Data Location: GCS\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Volume, Fees, Revenue (VFR) Data\n",
        "\n",
        "This datasource pulls DEX volume, protocol fees, and revenue data from DeFiLlama.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Volume, Fees, Revenue Backfill\n",
        "print(\"Starting Volume, Fees, Revenue backfill...\")\n",
        "\n",
        "with patch.object(dailydatawrite, \"determine_location\", mock_location):\n",
        "    # Import and patch the TABLE_LAST_N_DAYS constant\n",
        "    from op_analytics.datasources.defillama.volumefeesrevenue import execute as vfr_execute\n",
        "    \n",
        "    # Patch the constant to use our backfill days\n",
        "    with patch.object(vfr_execute, 'TABLE_LAST_N_DAYS', BACKFILL_DAYS):\n",
        "        result = vfr_execute.execute_pull()\n",
        "        \n",
        "print(\"Volume, Fees, Revenue backfill completed!\")\n",
        "print(f\"Result summary: {result}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Protocols TVL Data\n",
        "\n",
        "This datasource pulls detailed TVL data for individual protocols with token-level breakdowns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Protocols TVL Backfill\n",
        "print(\"Starting Protocols TVL backfill...\")\n",
        "\n",
        "with patch.object(dailydatawrite, \"determine_location\", mock_location):\n",
        "    # Import and patch the TVL_TABLE_LAST_N_DAYS constant\n",
        "    from op_analytics.datasources.defillama.protocolstvl import execute as protocols_execute\n",
        "    \n",
        "    # Patch the constant to use our backfill days\n",
        "    with patch.object(protocols_execute, 'TVL_TABLE_LAST_N_DAYS', BACKFILL_DAYS):\n",
        "        result = protocols_execute.execute_pull()\n",
        "        \n",
        "print(\"Protocols TVL backfill completed!\")\n",
        "print(f\"Result summary: {result}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Chain TVL Data\n",
        "\n",
        "This datasource pulls historical TVL data aggregated by blockchain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chain TVL Backfill\n",
        "print(\"Starting Chain TVL backfill...\")\n",
        "\n",
        "with patch.object(dailydatawrite, \"determine_location\", mock_location):\n",
        "    # Import and patch the TVL_TABLE_LAST_N_DAYS constant\n",
        "    from op_analytics.datasources.defillama.chaintvl import execute as chain_execute\n",
        "    \n",
        "    # Patch the constant to use our backfill days\n",
        "    with patch.object(chain_execute, 'TVL_TABLE_LAST_N_DAYS', BACKFILL_DAYS):\n",
        "        result = chain_execute.execute_pull()\n",
        "        \n",
        "print(\"Chain TVL backfill completed!\")\n",
        "print(f\"Result summary: {result}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Stablecoins Data\n",
        "\n",
        "This datasource pulls stablecoin circulation and bridging data by chain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stablecoins Backfill\n",
        "print(\"Starting Stablecoins backfill...\")\n",
        "\n",
        "with patch.object(dailydatawrite, \"determine_location\", mock_location):\n",
        "    # Import and patch the BALANCES_TABLE_LAST_N_DAYS constant\n",
        "    from op_analytics.datasources.defillama.stablecoins import execute as stablecoins_execute\n",
        "    \n",
        "    # Patch the constant to use our backfill days\n",
        "    with patch.object(stablecoins_execute, 'BALANCES_TABLE_LAST_N_DAYS', BACKFILL_DAYS):\n",
        "        result = stablecoins_execute.execute_pull()\n",
        "        \n",
        "print(\"Stablecoins backfill completed!\")\n",
        "print(f\"Result summary: {result}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Yield Pools Data\n",
        "\n",
        "This datasource pulls yield farming pool data and APY information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Yield Pools Backfill\n",
        "print(\"Starting Yield Pools backfill...\")\n",
        "\n",
        "with patch.object(dailydatawrite, \"determine_location\", mock_location):\n",
        "    # Import and patch the YIELD_TABLE_LAST_N_DAYS constant\n",
        "    from op_analytics.datasources.defillama.yieldpools import execute as yield_execute\n",
        "    \n",
        "    # Patch the constant to use our backfill days\n",
        "    with patch.object(yield_execute, 'YIELD_TABLE_LAST_N_DAYS', BACKFILL_DAYS):\n",
        "        result = yield_execute.execute_pull()\n",
        "        \n",
        "print(\"Yield Pools backfill completed!\")\n",
        "print(f\"Result summary: {result}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Lend/Borrow Pools Data\n",
        "\n",
        "This datasource pulls lending protocol data including rates and volumes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lend/Borrow Pools Backfill\n",
        "print(\"Starting Lend/Borrow Pools backfill...\")\n",
        "\n",
        "with patch.object(dailydatawrite, \"determine_location\", mock_location):\n",
        "    # Import and patch the LEND_BORROW_TABLE_LAST_N_DAYS constant\n",
        "    from op_analytics.datasources.defillama.lendborrowpools import execute as lb_execute\n",
        "    \n",
        "    # Patch the constant to use our backfill days\n",
        "    with patch.object(lb_execute, 'LEND_BORROW_TABLE_LAST_N_DAYS', BACKFILL_DAYS):\n",
        "        result = lb_execute.execute_pull()\n",
        "        \n",
        "print(\"Lend/Borrow Pools backfill completed!\")\n",
        "print(f\"Result summary: {result}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Advanced Usage Examples\n",
        "\n",
        "### Running Specific Datasources\n",
        "To run only specific datasources, comment out the others and modify the configuration:\n",
        "\n",
        "```python\n",
        "# Example: Only backfill VFR data for 90 days\n",
        "BACKFILL_DAYS = 90\n",
        "SPECIFIC_CHAIN = None  \n",
        "SPECIFIC_PROTOCOL = None\n",
        "```\n",
        "\n",
        "### Chain-Specific Backfills\n",
        "To backfill data for a specific chain:\n",
        "\n",
        "```python\n",
        "BACKFILL_DAYS = 365\n",
        "SPECIFIC_CHAIN = \"optimism\"  # or \"base\", \"arbitrum\", etc.\n",
        "SPECIFIC_PROTOCOL = None\n",
        "```\n",
        "\n",
        "### Protocol-Specific Backfills\n",
        "To backfill data for a specific protocol:\n",
        "\n",
        "```python\n",
        "BACKFILL_DAYS = 365\n",
        "SPECIFIC_CHAIN = None\n",
        "SPECIFIC_PROTOCOL = \"uniswap\"  # Use the protocol slug from DeFiLlama\n",
        "```\n",
        "\n",
        "### Tips for Large Backfills\n",
        "- For backfills > 180 days, consider running datasources individually\n",
        "- Monitor memory usage for very large backfills\n",
        "- The protocols TVL datasource may take the longest due to API rate limits\n",
        "- Some datasources may have daily API limits - check DeFiLlama API documentation\n",
        "\n",
        "### Validation\n",
        "After running backfills, you can validate the data using the summary returned by each execute function.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
