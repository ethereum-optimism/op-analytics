{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "44CAq8xTFUwT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "import csv\n",
        "from statistics import median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gOF8XXMdkO8R"
      },
      "outputs": [],
      "source": [
        "\n",
        "ballot_df = pd.read_csv('/data/rf5_synthetic_ballots.csv')  # Replace 'data.csv' with your actual file path\n",
        "df = ballot_df[ballot_df['Status'].eq('SUBMITTED')]\n",
        "\n",
        "json_data = df.to_json(orient='records')\n",
        "\n",
        "parsed_json = json.loads(json_data)\n",
        "pretty_data = json.dumps(parsed_json, indent=4)\n",
        "\n",
        "data = parsed_json\n",
        "num_raw_ballots = len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "deF8POLh2HhQ"
      },
      "outputs": [],
      "source": [
        "url = \"https://optimism.easscan.org/graphql\"\n",
        "headers = {\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "attestations = pd.DataFrame()\n",
        "schemaID = \"0x41513aa7b99bfea09d389c74aacedaeb13c28fb748569e9e2400109cbe284ee5\"\n",
        "\n",
        "# Query to filter by schemaID\n",
        "attest_data = {\n",
        "    \"query\": f\"\"\"\n",
        "        query Attestations {{\n",
        "            attestations(where: {{\n",
        "                schemaId: {{ equals: \"{schemaID}\" }},\n",
        "\n",
        "            }}) {{\n",
        "                id\n",
        "                attester\n",
        "                recipient\n",
        "                refUID\n",
        "                decodedDataJson\n",
        "            }}\n",
        "        }}\n",
        "    \"\"\",\n",
        "    \"variables\": {}\n",
        "}\n",
        "\n",
        "# Send the request using POST and json parameter\n",
        "response = requests.post(url, headers=headers, json=attest_data)\n",
        "dataset = response.json()\n",
        "\n",
        "attest_df = pd.json_normalize(dataset['data']['attestations'])\n",
        "voting_group = []\n",
        "round = []\n",
        "\n",
        "for i in attest_df['decodedDataJson']:\n",
        "  dataset = json.loads(i)\n",
        "  voting_group.append(dataset[3]['value']['value'])\n",
        "  round.append(dataset[1]['value']['value'])\n",
        "\n",
        "attest_df['voting_group'] = voting_group\n",
        "attest_df['round'] = round\n",
        "\n",
        "def group_naming(group):\n",
        "    match group:\n",
        "        case 'A':\n",
        "            return 'ETHEREUM_CORE_CONTRIBUTIONS'\n",
        "        case 'B':\n",
        "            return 'OP_STACK_RESEARCH_AND_DEVELOPMENT'\n",
        "        case 'C':\n",
        "            return 'OP_STACK_TOOLING'\n",
        "\n",
        "attest_df['category_assignment'] = attest_df['voting_group'].apply(group_naming)\n",
        "# attest_df.to_csv(\"rpgf5_category_assignment.csv\", encoding='utf-8') # [FOR AUDIT/TESTING]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-o_yLipC3ghm"
      },
      "outputs": [],
      "source": [
        "### Calculate Budget allocation\n",
        "\n",
        "budget_allocation =[]\n",
        "\n",
        "addresses = []\n",
        "# Collect budgets based on category assignment\n",
        "for entry in data:\n",
        "\n",
        "    if entry['Address'].lower() not in attest_df['recipient'].str.lower().unique():\n",
        "      continue\n",
        "\n",
        "    addresses.append(entry['Address'])\n",
        "    entry_payload = json.loads(entry[\"Payload\"])\n",
        "    budget = entry_payload[\"budget\"]\n",
        "    budget_allocation.append(budget)\n",
        "\n",
        "budget_median = np.median(budget_allocation)\n",
        "\n",
        "# print(budget_median) # [FOR AUDIT/TESTING]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "urucMZ0cxTRh"
      },
      "outputs": [],
      "source": [
        "### Calculate Category allocation\n",
        "\n",
        "# 1. Isolate the category budget votes: Each badgeholder will have voted on how to allocate OP to all categories (e.g. [Category1: 33%; Category2: 33%; Category3: 34%])\n",
        "# 2. Calculate the median of Category allocation\n",
        "# 3. Adjust category allocations to match 100%\n",
        "\n",
        "category_scores = {\n",
        "    'ETHEREUM_CORE_CONTRIBUTIONS': [],\n",
        "    'OP_STACK_RESEARCH_AND_DEVELOPMENT': [],\n",
        "    'OP_STACK_TOOLING': []\n",
        "}\n",
        "\n",
        "for entry in data:\n",
        "\n",
        "    if entry['Address'].lower() not in attest_df['recipient'].str.lower().unique():\n",
        "      print(entry['Address'])\n",
        "      continue\n",
        "\n",
        "    entry_payload = json.loads(entry[\"Payload\"])\n",
        "    allocations = entry_payload[\"category_allocations\"]\n",
        "    for item in allocations:\n",
        "      for category, score in item.items():\n",
        "          category_scores[category].append(float(score))\n",
        "\n",
        "# Calculate the median for each category\n",
        "category_medians = {category: np.median(scores) for category, scores in category_scores.items()}\n",
        "\n",
        "# Normalize the category medians\n",
        "total_median = sum(category_medians.values())\n",
        "normalized_category_medians = {category: (median / total_median) * 100 for category, median in category_medians.items()}\n",
        "\n",
        "# Output the normalized category allocations [FOR AUDIT/TESTING]\n",
        "# for category, score in normalized_category_medians.items():\n",
        "#     print(f\"{category}: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ViODlHQ-8YJO"
      },
      "outputs": [],
      "source": [
        "### Calculate Project Scores\n",
        "\n",
        "# 1. Isolate the Project votes: Each badgeholder will have voted by submitting percentages reflecting the allocation of OP to the projects within a category (e.g. [Project1: 10; Project2: 4;â€¦.]).\n",
        "# 2. Remove Project votes with a COI: For each badgeholder, they will have a number of `null` votes. These should not be considered for results calculation\n",
        "# 3. Calculate the median scores of projects\n",
        "# 4. Adjust scores to match 100%\n",
        "# 5. Repeat step 1 - 4 for all 3 categories\n",
        "\n",
        "# Calculate median project allocation under each category\n",
        "project_allocations_by_category = {\n",
        "    'ETHEREUM_CORE_CONTRIBUTIONS': {},\n",
        "    'OP_STACK_RESEARCH_AND_DEVELOPMENT': {},\n",
        "    'OP_STACK_TOOLING': {}\n",
        "}\n",
        "\n",
        "accepted_entries = []\n",
        "\n",
        "# Collect project allocations based on category assignment\n",
        "for entry in data:\n",
        "    filtered_df = attest_df.loc[((attest_df['recipient'].str.lower() == entry['Address'].lower()) & (attest_df['round'] == str(5)))]\n",
        "    entry_update = json.loads(entry[\"Payload\"])\n",
        "\n",
        "    if not filtered_df.empty:\n",
        "\n",
        "      entry_update = json.loads(entry[\"Payload\"])\n",
        "\n",
        "      category = filtered_df.iloc[0][\"category_assignment\"]\n",
        "      project_allocations = entry_update[\"project_allocations\"]\n",
        "      accepted_entries.append(entry['Address'])\n",
        "\n",
        "      for item in project_allocations:\n",
        "        for project_id, allocation in item.items():\n",
        "            if allocation is not None:  # Exclude None values\n",
        "                if project_id not in project_allocations_by_category[category]:\n",
        "                    project_allocations_by_category[category][project_id] = []\n",
        "                project_allocations_by_category[category][project_id].append(allocation)\n",
        "    else:\n",
        "      print(entry['Address'])\n",
        "\n",
        "# Calculate median project allocation for each project under each category\n",
        "median_project_allocations = {}\n",
        "for category, projects in project_allocations_by_category.items():\n",
        "    median_project_allocations[category] = {}\n",
        "\n",
        "    for project_id, allocations in projects.items():\n",
        "        median_project_allocations[category][project_id] = median(map(float, allocations))\n",
        "\n",
        "normalized_project_scores = {}\n",
        "\n",
        "for category, scores in median_project_allocations.items():\n",
        "    total_score = sum(scores.values())\n",
        "    normalized_project_scores[category] = {project_id: (score / total_score) * 100 for project_id, score in scores.items()}\n",
        "\n",
        "\n",
        "# Output the normalized project scores [FOR TESTING]\n",
        "# for category, scores in normalized_project_scores.items():\n",
        "#     print(f\"\\n{category}:\")\n",
        "#     print(f\"no. of prjects: {len(scores)}\")\n",
        "#     for project_id, normalized_score in scores.items():\n",
        "#         print(f\"Project ID: {project_id}, Normalized Score: {normalized_score:.2f}%\")\n",
        "\n",
        "# print(f\"\\n\\nAccepted total of {len(accepted_entries)} ballots (out of {num_raw_ballots} submitted).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9gejHZ6CYywb"
      },
      "outputs": [],
      "source": [
        "\n",
        "### Calculate Results (weighted proportional distribution)\n",
        "\n",
        "# 1. Multiply Project Scores with category scores - done\n",
        "# 2. Adjust scores to match 100% (there should be no need to readjust) - done\n",
        "# 3. Implement Max scores and redistribute excess\n",
        "# 4. Implement min and redistribute excess (while not breaking max rule)\n",
        "\n",
        "# Constants\n",
        "total_amount = budget_median\n",
        "max_amount = total_amount*0.125\n",
        "min_amount = 1000\n",
        "\n",
        "# Total allocation for each category\n",
        "category_total_allocations = {category: (allocation / 100) * total_amount for category, allocation in normalized_category_medians.items()}\n",
        "final_allocations = {}\n",
        "\n",
        "# Sort projects within each category\n",
        "for category, scores in normalized_project_scores.items():\n",
        "    normalized_project_scores[category] = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "# Calculate project allocations using weighted proportional distribution\n",
        "for category, scores in normalized_project_scores.items():\n",
        "    total_allocation = category_total_allocations[category]\n",
        "    project_allocations = {}\n",
        "\n",
        "    # Total score for the category\n",
        "    total_score = sum(scores.values())\n",
        "\n",
        "    # Weighted proportional allocations\n",
        "    for project, score in scores.items():\n",
        "        allocation = (score / total_score) * total_allocation\n",
        "        project_allocations[project] = allocation\n",
        "\n",
        "    # Remove projects below min_amount\n",
        "    project_allocations = {project: allocation for project, allocation in project_allocations.items() if allocation >= min_amount}\n",
        "\n",
        "    # Normalize allocations\n",
        "    total_allocated = sum(project_allocations.values())\n",
        "\n",
        "    if total_allocated > 0:\n",
        "        normalized_allocations = {project: (allocation / total_allocated) * total_allocation for project, allocation in project_allocations.items()}\n",
        "    else:\n",
        "        normalized_allocations = {}\n",
        "\n",
        "    # Cap allocations at max_amount\n",
        "    normalized_allocations = {project: min(allocation, max_amount) for project, allocation in normalized_allocations.items()}\n",
        "\n",
        "    # Store the final allocations for the category\n",
        "    final_allocations[category] = normalized_allocations\n",
        "\n",
        "# Display the final allocations [FOR TESTING]\n",
        "# for category, allocations in final_allocations.items():\n",
        "#     print(f\"Allocations for {category}:\")\n",
        "#     for project, allocation in allocations.items():\n",
        "#         print(f\"  Project {project}: {allocation:,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwwC1HBmbZxx",
        "outputId": "d96d4461-e6ff-4c4d-c5f7-f7a3942ef8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocations have been written to rpgf5_allocations_final_result.csv\n"
          ]
        }
      ],
      "source": [
        "# Write results into CSV file\n",
        "csv_file_name = 'rpgf5_allocations_final_result.csv'\n",
        "\n",
        "\n",
        "with open(csv_file_name, mode='w', newline='') as csv_file:\n",
        "\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow(['Category', 'Project', 'Allocation'])\n",
        "    for category, allocations in final_allocations.items():\n",
        "        for project, allocation in allocations.items():\n",
        "            writer.writerow([category, project, f\"{allocation:,.2f}\"])\n",
        "\n",
        "print(f\"Allocations have been written to {csv_file_name}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
