{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pipenv run jupyter nbconvert --to python get_all_txs.ipynb\n",
    "# !uv pip install dune_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print('get all txs')\n",
    "import sys\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "# NOTE: google_bq_utils imported later (before BQ write) to avoid stale OIDC token in CI\n",
    "sys.path.pop()\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\n",
    "        'dt','blockchain','name','layer','chain_id'\n",
    "        , 'num_raw_txs', 'num_success_txs','num_qualified_txs','source'\n",
    "        ]\n",
    "query_name = 'dune_all_txs'\n",
    "query_gas_name = 'dune_all_gas'\n",
    "query_fees_name = 'dune_all_fees'\n",
    "rerun_hrs = 0#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Config\n",
    "run_all_txs = 1 #0\n",
    "run_gas = 1 #0\n",
    "run_metrics = 1 #0\n",
    "run_chain_level = 1 #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "trailing_days = 28 #45\n",
    "ending_days = 0\n",
    "chunk_size = 3  # Process in 3-day chunks to avoid Dune timeout\n",
    "parallel_chunks = True  # Run chunks in parallel for faster execution\n",
    "max_workers = 3  # Number of parallel workers\n",
    "\n",
    "single_chain = 'none' ## if 'none' then there will be no filter applied\n",
    "print('trailing days: ' + str(trailing_days))\n",
    "print('chunk size: ' + str(chunk_size))\n",
    "print('single chain: ' + str(single_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_config = [\n",
    "    ### #blockchain, display_name, count_func, count_block_func_param, transactions_table_param, tx_fee_func_param, tx_fee_currency_param, chain_id_param\n",
    "    ['bitcoin','Bitcoin','COUNT_IF(fee > 0)','COUNT(DISTINCT block_height)','transactions','fee','BTC','NULL'],\n",
    "    ['near','Near','COUNT(distinct case when gas_price > 0 then tx_hash else null end)','COUNT(DISTINCT block_height)','actions','cast(NULL as double)','NULL','397'],\n",
    "    ['aptos','Aptos','COUNT_IF(gas_used>0)','COUNT(DISTINCT block_height)','user_transactions','(gas_used*gas_unit_price/1e8)','APT','NULL'],\n",
    "    # ['stellar','Stellar','COUNT_IF(fee_charged>0)','COUNT(DISTINCT block_height)','fee_charged','history_transactions'], --not date partitioned\n",
    "    ['kaia','Kaia','COUNT_IF(gas_price>0)','COUNT(DISTINCT block_number)','transactions','cast(NULL as double)','NULL','8217'],\n",
    "    ['ton','TON','COUNT_IF(compute_gas_fees>0)','COUNT(DISTINCT block_seqno)','transactions','cast(NULL as double)','NULL','NULL'],\n",
    "    ['berachain','Berachain','COUNT_IF(gas_price>0)','COUNT(DISTINCT block_number)','transactions','cast(gas_price/1e9*gas_used/1e9 as double)','BERA','80094'],\n",
    "    ['hyperevm','Hyperliquid L1','COUNT_IF(gas_price>0)','COUNT(DISTINCT block_number)','transactions','cast(gas_price/1e9*gas_used/1e9 as double)','HYPE','999'],\n",
    "    ['sonic','Sonic','COUNT_IF(gas_price>0)','COUNT(DISTINCT block_number)','transactions','cast(gas_price/1e9*gas_used/1e9 as double)','S','146'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These params are still used by fee_metrics and chain_level queries\n",
    "days_param = d.generate_query_parameter(input=trailing_days,field_name='trailing_days',dtype='number')\n",
    "end_days_param = d.generate_query_parameter(input=ending_days,field_name='ending_days',dtype='number')\n",
    "single_chain_param = d.generate_query_parameter(input=single_chain,field_name='single_chain',dtype='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def fetch_fees_chunk(days_start, days_end, single_chain):\n",
    "    \"\"\"Fetch a single chunk of fee data from Dune.\n",
    "    \n",
    "    For the date range query:\n",
    "    - trailing_days = how far back from NOW() to start (e.g., 25 = start 25 days ago)\n",
    "    - ending_days = how far back from NOW() to end (e.g., 22 = end 22 days ago)\n",
    "    So chunk (22, 25) means: trailing_days=25, ending_days=22 → data from 25 to 22 days ago\n",
    "    \"\"\"\n",
    "    days_param = d.generate_query_parameter(input=days_end, field_name='trailing_days', dtype='number')\n",
    "    end_days_param = d.generate_query_parameter(input=days_start, field_name='ending_days', dtype='number')\n",
    "    single_chain_param = d.generate_query_parameter(input=single_chain, field_name='single_chain', dtype='text')\n",
    "    \n",
    "    return d.get_dune_data(query_id = 4229341,\n",
    "        name = query_name,\n",
    "        path = \"outputs\",\n",
    "        performance=\"large\",\n",
    "        params = [days_param, end_days_param, single_chain_param],\n",
    "        num_hours_to_rerun=rerun_hrs\n",
    "    )\n",
    "\n",
    "if run_all_txs == 1:\n",
    "    print('     dune runs - fees (chunked)')\n",
    "    fees_dfs = []\n",
    "    \n",
    "    # Generate chunk ranges\n",
    "    chunk_ranges = []\n",
    "    days_remaining = trailing_days - ending_days\n",
    "    current_end = trailing_days\n",
    "    while days_remaining > 0:\n",
    "        days_start = max(current_end - chunk_size, ending_days)\n",
    "        chunk_ranges.append((days_start, current_end))\n",
    "        current_end = days_start\n",
    "        days_remaining = current_end - ending_days\n",
    "    \n",
    "    try:\n",
    "        if parallel_chunks and len(chunk_ranges) > 1:\n",
    "            print(f'     Running {len(chunk_ranges)} chunks in parallel with {max_workers} workers')\n",
    "            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                futures = {\n",
    "                    executor.submit(fetch_fees_chunk, start, end, single_chain): (start, end)\n",
    "                    for start, end in chunk_ranges\n",
    "                }\n",
    "                for future in as_completed(futures):\n",
    "                    start, end = futures[future]\n",
    "                    try:\n",
    "                        chunk_df = future.result()\n",
    "                        if not chunk_df.empty:\n",
    "                            fees_dfs.append(chunk_df)\n",
    "                        print(f'     Completed chunk days {start}-{end}')\n",
    "                    except Exception as e:\n",
    "                        print(f'     Failed chunk days {start}-{end}: {e}')\n",
    "        else:\n",
    "            for days_start, days_end in chunk_ranges:\n",
    "                print(f'     dune: day range {days_start}-{days_end}')\n",
    "                chunk_df = fetch_fees_chunk(days_start, days_end, single_chain)\n",
    "                if not chunk_df.empty:\n",
    "                    fees_dfs.append(chunk_df)\n",
    "        \n",
    "        if fees_dfs:\n",
    "            fees_df = pd.concat(fees_dfs, ignore_index=True)\n",
    "            # Remove duplicates from overlapping chunk boundaries (BETWEEN is inclusive)\n",
    "            dedupe_cols = ['blockchain', 'dt', 'tx_fee_currency']\n",
    "            before_count = len(fees_df)\n",
    "            fees_df = fees_df.drop_duplicates(subset=dedupe_cols, keep='first')\n",
    "            after_count = len(fees_df)\n",
    "            if before_count != after_count:\n",
    "                print(f'     Removed {before_count - after_count} duplicate rows from chunk overlaps')\n",
    "        else:\n",
    "            fees_df = pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Dune API failed: {e}\")\n",
    "        fees_df = pd.DataFrame()\n",
    "else:\n",
    "    fees_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_gas_chunk(days_start, days_end, single_chain):\n",
    "    \"\"\"Fetch a single chunk of gas data from Dune.\n",
    "    \n",
    "    For the date range query:\n",
    "    - trailing_days = how far back from NOW() to start (e.g., 25 = start 25 days ago)\n",
    "    - ending_days = how far back from NOW() to end (e.g., 22 = end 22 days ago)\n",
    "    So chunk (22, 25) means: trailing_days=25, ending_days=22 → data from 25 to 22 days ago\n",
    "    \"\"\"\n",
    "    days_param = d.generate_query_parameter(input=days_end, field_name='trailing_days', dtype='number')\n",
    "    end_days_param = d.generate_query_parameter(input=days_start, field_name='ending_days', dtype='number')\n",
    "    single_chain_param = d.generate_query_parameter(input=single_chain, field_name='single_chain', dtype='text')\n",
    "    \n",
    "    return d.get_dune_data(query_id = 4758295,  # https://dune.com/queries/4758295\n",
    "        name = query_name,\n",
    "        path = \"outputs\",\n",
    "        performance=\"large\",\n",
    "        params = [days_param, end_days_param, single_chain_param],\n",
    "        num_hours_to_rerun=rerun_hrs\n",
    "    )\n",
    "\n",
    "if run_gas == 1:\n",
    "    print('run dune - gas level (chunked)')\n",
    "    gas_dfs = []\n",
    "    \n",
    "    # Generate chunk ranges (reuse same logic as fees)\n",
    "    chunk_ranges = []\n",
    "    days_remaining = trailing_days - ending_days\n",
    "    current_end = trailing_days\n",
    "    while days_remaining > 0:\n",
    "        days_start = max(current_end - chunk_size, ending_days)\n",
    "        chunk_ranges.append((days_start, current_end))\n",
    "        current_end = days_start\n",
    "        days_remaining = current_end - ending_days\n",
    "    \n",
    "    try:\n",
    "        if parallel_chunks and len(chunk_ranges) > 1:\n",
    "            print(f'     Running {len(chunk_ranges)} gas chunks in parallel with {max_workers} workers')\n",
    "            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                futures = {\n",
    "                    executor.submit(fetch_gas_chunk, start, end, single_chain): (start, end)\n",
    "                    for start, end in chunk_ranges\n",
    "                }\n",
    "                for future in as_completed(futures):\n",
    "                    start, end = futures[future]\n",
    "                    try:\n",
    "                        chunk_df = future.result()\n",
    "                        if not chunk_df.empty:\n",
    "                            gas_dfs.append(chunk_df)\n",
    "                        print(f'     Completed gas chunk days {start}-{end}')\n",
    "                    except Exception as e:\n",
    "                        print(f'     Failed gas chunk days {start}-{end}: {e}')\n",
    "        else:\n",
    "            for days_start, days_end in chunk_ranges:\n",
    "                print(f'     dune gas: day range {days_start}-{days_end}')\n",
    "                chunk_df = fetch_gas_chunk(days_start, days_end, single_chain)\n",
    "                if not chunk_df.empty:\n",
    "                    gas_dfs.append(chunk_df)\n",
    "        \n",
    "        if gas_dfs:\n",
    "            gas_df = pd.concat(gas_dfs, ignore_index=True)\n",
    "            # Remove duplicates from overlapping chunk boundaries (BETWEEN is inclusive)\n",
    "            dedupe_cols = ['chain_id', 'dt']\n",
    "            before_count = len(gas_df)\n",
    "            gas_df = gas_df.drop_duplicates(subset=dedupe_cols, keep='first')\n",
    "            after_count = len(gas_df)\n",
    "            if before_count != after_count:\n",
    "                print(f'     Removed {before_count - after_count} duplicate rows from chunk overlaps')\n",
    "        else:\n",
    "            gas_df = pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Dune gas API failed: {e}\")\n",
    "        gas_df = pd.DataFrame()\n",
    "else:\n",
    "    gas_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_all_txs == 1:\n",
    "    fees_df.sample(5)\n",
    "    unique_blockchains = fees_df['blockchain'].unique().tolist()\n",
    "else:\n",
    "    unique_blockchains = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_metrics == 1:\n",
    "    print('run dune - fees metrics')\n",
    "    fee_metrics_df = d.get_dune_data(query_id = 4902405, #https://dune.com/queries/4902405\n",
    "        name = \"dune fees metrics\",\n",
    "        path = \"outputs\",\n",
    "        performance=\"large\",\n",
    "        params = [days_param, end_days_param],\n",
    "        num_hours_to_rerun=rerun_hrs\n",
    "    )\n",
    "    if single_chain != 'none':\n",
    "        fee_metrics_df = fee_metrics_df[fee_metrics_df['blockchain'] == single_chain]\n",
    "else:\n",
    "    fee_metrics_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_df_agg = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_chain_level == 1:\n",
    "    print('run dune - chain level')\n",
    "    chain_df_agg = pd.DataFrame()\n",
    "    chain_dfs = []\n",
    "    for row in chain_config:\n",
    "        blockchain = row[0]\n",
    "        print(blockchain)\n",
    "        if blockchain in unique_blockchains:\n",
    "            continue\n",
    "        else:\n",
    "            #blockchain, display_name, count_func, gas_field, transactions_table\n",
    "            blockchain_param = d.generate_query_parameter(input=blockchain,field_name='blockchain',dtype='text')\n",
    "            display_name_param = d.generate_query_parameter(input=row[1],field_name='display_name',dtype='text')\n",
    "            count_func_param = d.generate_query_parameter(input=row[2],field_name='count_func',dtype='text')\n",
    "            count_block_func_param = d.generate_query_parameter(input=row[3],field_name='count_block_func',dtype='text')\n",
    "            # gas_field_param = d.generate_query_parameter(input=row[4],field_name='gas_field',dtype='text')\n",
    "            transactions_table_param = d.generate_query_parameter(input=row[4],field_name='transactions_table',dtype='text')\n",
    "            tx_fee_func_param = d.generate_query_parameter(input=row[5],field_name='tx_fee_func_internal',dtype='text')\n",
    "            tx_fee_currency_param = d.generate_query_parameter(input=row[6],field_name='tx_fee_currency',dtype='text')\n",
    "            chain_id_param = d.generate_query_parameter(input=row[7],field_name='chain_id_param',dtype='text')\n",
    "\n",
    "            chain_df = d.get_dune_data(query_id = 4230061, #https://dune.com/queries/4230061\n",
    "                name = query_name + '_by_chain',\n",
    "                path = \"outputs\",\n",
    "                performance=\"large\",\n",
    "                params = [\n",
    "                        days_param,end_days_param,blockchain_param,display_name_param,count_func_param,count_block_func_param\n",
    "                        ,transactions_table_param,tx_fee_func_param,tx_fee_currency_param,chain_id_param\n",
    "                        ],\n",
    "                num_hours_to_rerun=rerun_hrs\n",
    "            )\n",
    "            # print(chain_df.sample(3))\n",
    "            chain_dfs.append(chain_df)\n",
    "\n",
    "    chain_df_agg = pd.concat(chain_dfs)\n",
    "else:\n",
    "    chain_df_agg = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fees_df.columns)\n",
    "# print(chain_df_agg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not chain_df_agg.empty:\n",
    "    dune_df = pd.concat([fees_df,chain_df_agg])\n",
    "else: \n",
    "    dune_df = fees_df.copy()\n",
    "\n",
    "if run_metrics == 1:\n",
    "# First, find chains that are only in metric_fees_df\n",
    "    unique_fee_metrics_df = fee_metrics_df[~fee_metrics_df['blockchain'].isin(dune_df['blockchain'])]\n",
    "    dune_df = pd.concat([dune_df, unique_fee_metrics_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dune_df.empty:\n",
    "    dune_df['source'] = 'dune'\n",
    "    dune_df['dt'] = dune_df['dt'].str.replace(' UTC', '', regex=False)\n",
    "    dune_df['dt'] = pd.to_datetime(dune_df['dt'], format='mixed').dt.tz_localize(None)\n",
    "    dune_df = dune_df[dune_df['dt'].dt.date < datetime.datetime.now(datetime.timezone.utc).date()]\n",
    "    dune_df['chain_id'] = dune_df['chain_id'].astype(str)\n",
    "    dune_df['chain_id'] = dune_df['chain_id'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "    dune_df['num_blocks'] = dune_df['num_blocks'].fillna(0).astype('Int64')\n",
    "    dune_df['num_txs'] = dune_df['num_txs'].fillna(0).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not gas_df.empty:\n",
    "    gas_df['source'] = 'dune'\n",
    "    gas_df['dt'] = pd.to_datetime(gas_df['dt']).dt.tz_localize(None)\n",
    "    gas_df = gas_df[gas_df['dt'].dt.date < datetime.datetime.now(datetime.timezone.utc).date()]\n",
    "    gas_df['chain_id'] = gas_df['chain_id'].astype(str)\n",
    "    gas_df['chain_id'] = gas_df['chain_id'].astype(str).str.replace(r'\\.0$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all elements are strings\n",
    "assert dune_df['chain_id'].apply(type).eq(str).all(), \"Not all elements are strings\"\n",
    "# print(dune_df['chain_id'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fee_metrics_df.empty:\n",
    "    fee_metrics_df['dt'] = pd.to_datetime(fee_metrics_df['dt']).dt.tz_localize(None)\n",
    "    fee_metrics_df['chain_id'] = fee_metrics_df['chain_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not gas_df.empty:\n",
    "    assert gas_df['chain_id'].apply(type).eq(str).all(), \"Not all elements are strings\"\n",
    "if not fee_metrics_df.empty:\n",
    "    assert fee_metrics_df['chain_id'].apply(type).eq(str).all(), \"Not all elements are strings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dune_df.sample(5)\n",
    "print(dune_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dune_df shape: {dune_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cols = ['blockchain', 'dt','tx_fee_currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicate combinations\n",
    "duplicates = dune_df.duplicated(subset=unique_cols, keep=False)\n",
    "\n",
    "# View the duplicate rows\n",
    "duplicate_rows = dune_df[duplicates]\n",
    "\n",
    "# Display the duplicate rows\n",
    "print(duplicate_rows)\n",
    "\n",
    "# Get a count of duplicates for each combination\n",
    "duplicate_counts = dune_df.groupby(unique_cols).size().reset_index(name='count')\n",
    "duplicate_counts = duplicate_counts[duplicate_counts['count'] > 1]\n",
    "\n",
    "print(\"\\nDuplicate combination counts:\")\n",
    "print(duplicate_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dune_df['num_blocks'] = pd.to_numeric(dune_df['num_blocks'], errors='coerce').fillna(0).round().astype(int)\n",
    "dune_df['num_txs'] = pd.to_numeric(dune_df['num_txs'], errors='coerce').fillna(0).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check\n",
    "if not dune_df.empty:\n",
    "    print(dune_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BQ utils here (right before use) to get fresh OIDC token in CI\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import google_bq_utils as bqu\n",
    "sys.path.pop()\n",
    "\n",
    "# Prepare credentials before BQ operations (refreshes OIDC token if needed)\n",
    "bqu.prepare_bq_credentials()\n",
    "\n",
    "#BQ Upload\n",
    "if not dune_df.empty:\n",
    "    bqu.append_and_upsert_df_to_bq_table(dune_df, query_name, unique_keys = unique_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not gas_df.empty:\n",
    "    bqu.append_and_upsert_df_to_bq_table(gas_df, query_gas_name, unique_keys = ['chain_id','dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fee_metrics_df[fee_metrics_df['blockchain']=='tron'].sort_values(by='dt',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fee_metrics_df.empty:\n",
    "    bqu.append_and_upsert_df_to_bq_table(fee_metrics_df, query_fees_name, unique_keys = ['blockchain','dt'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
