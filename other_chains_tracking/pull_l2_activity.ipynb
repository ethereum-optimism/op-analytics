{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pipenv run jupyter nbconvert --to python pull_l2_activity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Print all environment variables\n",
    "# for key, value in os.environ.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start l2 activity\n"
     ]
    }
   ],
   "source": [
    "print(\"start l2 activity\")\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "import growthepieapi_utils as gtp\n",
    "import l2beat_utils as ltwo\n",
    "import csv_utils as cu\n",
    "import google_bq_utils as bqu\n",
    "import pandas_utils as pu\n",
    "import clickhouse_utils as ch\n",
    "import opstack_metadata_utils as ops\n",
    "\n",
    "sys.path.pop()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting metadata - l2beat\n",
      "Failed to fetch metadata from GitHub API: 401 Client Error: Unauthorized for url: https://api.github.com/repos/l2beat/l2beat/contents/packages/config/src/projects\n",
      "This is likely due to authentication issues or L2Beat repository changes.\n",
      "Returning minimal metadata DataFrame.\n",
      "No metadata files found. Returning minimal DataFrame with basic chain information.\n"
     ]
    }
   ],
   "source": [
    "# L2Beat removed metadata files, comment out\n",
    "\n",
    "print(\"getting metadata - l2beat\")\n",
    "l2beat_meta = ltwo.get_l2beat_metadata()\n",
    "l2beat_meta[\"chain\"] = l2beat_meta[\"slug\"]\n",
    "# l2beat_meta[\"is_upcoming\"] = l2beat_meta[\"is_upcoming\"].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>slug</th>\n",
       "      <th>file_name</th>\n",
       "      <th>chainId</th>\n",
       "      <th>name</th>\n",
       "      <th>explorerUrl</th>\n",
       "      <th>rpcUrl</th>\n",
       "      <th>category</th>\n",
       "      <th>provider</th>\n",
       "      <th>hostChain</th>\n",
       "      <th>da_provider_name</th>\n",
       "      <th>badges</th>\n",
       "      <th>is_upcoming</th>\n",
       "      <th>is_archived</th>\n",
       "      <th>is_current_chain</th>\n",
       "      <th>websites</th>\n",
       "      <th>documentation</th>\n",
       "      <th>repositories</th>\n",
       "      <th>provider_entity</th>\n",
       "      <th>chain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown Chain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  layer     slug file_name chainId           name explorerUrl rpcUrl category  \\\n",
       "0    L2  unknown   unknown    None  Unknown Chain        None   None     None   \n",
       "\n",
       "  provider hostChain da_provider_name badges  is_upcoming  is_archived  \\\n",
       "0     None      None             None   None        False        False   \n",
       "\n",
       "   is_current_chain websites documentation repositories provider_entity  \\\n",
       "0              True     None          None         None            None   \n",
       "\n",
       "     chain  \n",
       "0  unknown  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2beat_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected response structure from L2Beat API\n",
      "Response keys: ['chart', 'projects']\n"
     ]
    }
   ],
   "source": [
    "# L2B Meta\n",
    "l2b_summary = ltwo.get_l2beat_chain_summary()\n",
    "l2b_summary['dt'] = pd.to_datetime(datetime.now(timezone.utc).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(l2b_summary.head(5))\n",
    "# print(l2b_summary.dtypes)\n",
    "\n",
    "# bqu.append_and_upsert_df_to_bq_table(\n",
    "#     l2b_summary,\n",
    "#     \"daily_l2beat_chain_summary\",\n",
    "#     unique_keys=[\"dt\", \"id\",\"slug\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.growthepie.xyz/v1/fundamentals.json\n"
     ]
    }
   ],
   "source": [
    "# # # Usage\n",
    "try:\n",
    "    gtp_api = gtp.get_growthepie_api_data()\n",
    "    gtp_meta_api = gtp.get_growthepie_api_meta()\n",
    "    gtp_api = gtp_api.rename(columns={\"date\": \"dt\"})\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(f\"Exception type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtp_api.sort_values(by='dt', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update datatype for bq uploads\n",
    "if \"enable_contracts\" in gtp_meta_api:\n",
    "    gtp_meta_api[\"enable_contracts\"] = gtp_meta_api[\"enable_contracts\"].astype(bool)\n",
    "\n",
    "if \"colors\" in gtp_meta_api:\n",
    "    gtp_meta_api[\"colors\"] = gtp_meta_api[\"colors\"].astype(str)\n",
    "\n",
    "# ensure 'active_tabs' exists to match schema (fallback to 'tab_status' or empty)\n",
    "if \"active_tabs\" not in gtp_meta_api.columns:\n",
    "    if \"tab_status\" in gtp_meta_api.columns:\n",
    "        gtp_meta_api[\"active_tabs\"] = gtp_meta_api[\"tab_status\"]\n",
    "    else:\n",
    "        gtp_meta_api[\"active_tabs\"] = \"\"\n",
    "# cast to string for BQ compatibility\n",
    "if \"active_tabs\" in gtp_meta_api.columns:\n",
    "    gtp_meta_api[\"active_tabs\"] = gtp_meta_api[\"active_tabs\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting assets onchain - l2beat\n"
     ]
    }
   ],
   "source": [
    "print(\"getting assets onchain - l2beat\")\n",
    "# l2beat_aoc = ltwo.get_daily_aoc_by_token()\n",
    "# l2beat_aoc = l2beat_aoc.rename(columns={\"project\": \"chain\", \"date\": \"dt\"})\n",
    "time.sleep(3)  # rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data - l2beat\n"
     ]
    }
   ],
   "source": [
    "print(\"getting data - l2beat\")\n",
    "# l2beat_df = ltwo.get_all_l2beat_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2beat_meta[l2beat_meta['chainId'] == '324']\n",
    "# l2beat_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_l2b_df = l2beat_df.merge(\n",
    "#     l2beat_meta[\n",
    "#         [\n",
    "#             \"chain\",\n",
    "#             \"name\",\n",
    "#             \"layer\",\n",
    "#             \"chainId\",\n",
    "#             \"provider\",\n",
    "#             \"provider_entity\",\n",
    "#             \"category\",\n",
    "#             \"is_upcoming\",\n",
    "#             \"is_archived\",\n",
    "#             \"is_current_chain\",\n",
    "#         ]\n",
    "#     ],\n",
    "#     on=\"chain\",\n",
    "#     how=\"outer\",\n",
    "# )\n",
    "\n",
    "# combined_l2b_df[\"chainId\"] = combined_l2b_df[\"chainId\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data - growthepie\n"
     ]
    }
   ],
   "source": [
    "print(\"getting data - growthepie\")\n",
    "try:\n",
    "    if not gtp_api.empty and not gtp_meta_api.empty:\n",
    "        combined_gtp_df = gtp_api.merge(\n",
    "            gtp_meta_api[[\"origin_key\", \"chain_name\", \"evm_chain_id\"]],\n",
    "            on=\"origin_key\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        combined_gtp_df[\"dt\"] = pd.to_datetime(combined_gtp_df[\"dt\"], errors=\"coerce\")\n",
    "\n",
    "        combined_gtp_df = combined_gtp_df.drop(columns=(\"index\"))\n",
    "        # combined_gtp_df.sample(5)\n",
    "    else:\n",
    "        print(\"GrowThePie API data is empty, skipping merge\")\n",
    "        combined_gtp_df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(f\"Exception type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())\n",
    "    combined_gtp_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Columns\n",
    "try:\n",
    "    if not combined_gtp_df.empty:\n",
    "        column_names = combined_gtp_df.columns\n",
    "\n",
    "        # If we have *_usd columns, ensure matching *_eth columns exist\n",
    "        for col in column_names:\n",
    "            if col.endswith(\"_usd\"):\n",
    "                new_col_name = col.replace(\"_usd\", \"_eth\")\n",
    "                if new_col_name not in combined_gtp_df.columns:\n",
    "                    combined_gtp_df[new_col_name] = np.nan\n",
    "\n",
    "        # Some columns are provided without a \"_usd\" suffix but schema expects *_eth pairs\n",
    "        required_base_cols = [\"tvl\", \"stables_mcap\"]\n",
    "        for base in required_base_cols:\n",
    "            eth_col = f\"{base}_eth\"\n",
    "            if base in combined_gtp_df.columns and eth_col not in combined_gtp_df.columns:\n",
    "                combined_gtp_df[eth_col] = np.nan\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(f\"Exception type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Metadata\n",
    "opstack_metadata = ops.get_op_stack_metadata_df()\n",
    "# combined_l2b_df[\"l2beat_slug\"] = combined_l2b_df[\"chain\"]\n",
    "# meta_cols = [\n",
    "#     \"l2beat_slug\",\n",
    "#     \"is_op_chain\",\n",
    "#     \"mainnet_chain_id\",\n",
    "#     \"op_based_version\",\n",
    "#     \"alignment\",\n",
    "#     \"chain_name\",\n",
    "#     \"display_name\",\n",
    "# ]\n",
    "\n",
    "# l2b_enriched_df = combined_l2b_df.merge(\n",
    "#     opstack_metadata[meta_cols], on=\"l2beat_slug\", how=\"left\"\n",
    "# )\n",
    "\n",
    "# l2b_enriched_df[\"alignment\"] = l2b_enriched_df[\"alignment\"].fillna(\"Other EVMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = [\"is_op_chain\", \"is_upcoming\", \"is_archived\", \"is_current_chain\"]\n",
    "dfs = [l2beat_meta]#[l2b_enriched_df, l2beat_meta]\n",
    "\n",
    "for df in dfs:\n",
    "    for column in boolean_columns:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define aggregation functions for each column\n",
    "aggregations = {\n",
    "    \"totalUsd\": [\"min\", \"last\", \"mean\"],  # valueUsd\n",
    "    \"transactions\": [\"sum\", \"mean\"],\n",
    "    \"canonicalUsd\": [\"min\", \"last\", \"mean\"],  # cbvUsd\n",
    "    \"externalUsd\": [\"min\", \"last\", \"mean\"],  # ebvUsd\n",
    "    \"nativeUsd\": [\"min\", \"last\", \"mean\"],  # nmvUsd\n",
    "}\n",
    "\n",
    "\n",
    "# Function to perform aggregation based on frequency\n",
    "def aggregate_data(df, freq, date_col=\"timestamp\", groupby_cols=None, aggs=None):\n",
    "    if groupby_cols is None:\n",
    "        groupby_cols = [\n",
    "            \"chain\",\n",
    "            \"chainId\",\n",
    "            \"layer\",\n",
    "            \"is_op_chain\",\n",
    "            \"mainnet_chain_id\",\n",
    "            \"op_based_version\",\n",
    "            \"alignment\",\n",
    "            \"chain_name\",\n",
    "            \"display_name\",\n",
    "            \"provider\",\n",
    "            \"is_upcoming\",\n",
    "            \"is_archived\",\n",
    "            \"is_current_chain\",\n",
    "        ]\n",
    "    if aggs is None:\n",
    "        aggs = aggregations\n",
    "\n",
    "    # Group by the specified frequency and other columns, then apply aggregations\n",
    "    df_agg = (\n",
    "        df.groupby([pd.Grouper(key=date_col, freq=freq)] + groupby_cols, dropna=False)\n",
    "        .agg(aggs)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Flatten the hierarchical column index and concatenate aggregation function names with column names\n",
    "    df_agg.columns = [\"_\".join(filter(None, col)).rstrip(\"_\") for col in df_agg.columns]\n",
    "\n",
    "    # Rename the 'timestamp' column based on the frequency\n",
    "    date_col_name = \"month\" if freq == \"MS\" else \"week\"\n",
    "    df_agg.rename(columns={date_col: date_col_name}, inplace=True)\n",
    "\n",
    "    # Group by 'chain' and rank the rows within each group based on the date column\n",
    "    df_agg[f\"{date_col_name}s_live\"] = df_agg.groupby(\"chain\")[date_col_name].rank(\n",
    "        method=\"min\"\n",
    "    )\n",
    "\n",
    "    return df_agg\n",
    "\n",
    "\n",
    "# # Perform monthly aggregation\n",
    "# l2b_monthly_df = aggregate_data(l2b_enriched_df, freq=\"MS\")\n",
    "# # Perform weekly aggregation\n",
    "# l2b_weekly_df = aggregate_data(l2b_enriched_df, freq=\"W-MON\")\n",
    "\n",
    "# Sample output\n",
    "# l2b_weekly_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "folder = \"outputs/\"\n",
    "# combined_gtp_df.to_csv(folder + \"growthepie_l2_activity.csv\", index=False)\n",
    "# gtp_meta_api.to_csv(folder + \"growthepie_l2_metadata.csv\", index=False)\n",
    "# l2b_enriched_df.to_csv(folder + \"l2beat_l2_activity.csv\", index=False)\n",
    "# l2beat_meta.to_csv(folder + \"l2beat_l2_metadata.csv\", index=False)\n",
    "# l2b_monthly_df.to_csv(folder + \"l2beat_l2_activity_monthly.csv\", index=False)\n",
    "# l2b_weekly_df.to_csv(folder + \"l2beat_l2_activity_weekly.csv\", index=False)\n",
    "# l2beat_aoc.to_csv(folder + \"l2beat_aoc_by_token.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gtp_meta_api.dtypes\n",
    "# gtp_meta_api['logo'] = gtp_meta_api['logo'].astype(str)\n",
    "# gtp_meta_api['l2beat_stage'] = gtp_meta_api['l2beat_stage'].astype(str)\n",
    "# # gtp_meta_api['stack'] = gtp_meta_api['stack'].astype(str)\n",
    "# gtp_meta_api['block_explorers'] = gtp_meta_api['block_explorers'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtp_meta_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_gtp_df['evm_chain_id'] = combined_gtp_df['evm_chain_id'].astype(str).replace('.0','').fillna('-')\n",
    "# gtp_meta_api['evm_chain_id'] = gtp_meta_api['evm_chain_id'].astype(str).replace('.0','').fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_key</th>\n",
       "      <th>dt</th>\n",
       "      <th>aa_last7d</th>\n",
       "      <th>app_fees_usd</th>\n",
       "      <th>costs_blobs_usd</th>\n",
       "      <th>costs_l1_usd</th>\n",
       "      <th>costs_total_usd</th>\n",
       "      <th>daa</th>\n",
       "      <th>fdv_usd</th>\n",
       "      <th>fees_paid_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>costs_l1_eth</th>\n",
       "      <th>costs_total_eth</th>\n",
       "      <th>fdv_eth</th>\n",
       "      <th>fees_paid_eth</th>\n",
       "      <th>market_cap_eth</th>\n",
       "      <th>profit_eth</th>\n",
       "      <th>rent_paid_eth</th>\n",
       "      <th>txcosts_median_eth</th>\n",
       "      <th>tvl_eth</th>\n",
       "      <th>stables_mcap_eth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>zora</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.783436e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>imx</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.019553e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>unichain</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.861856e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>ethereum</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>worldchain</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.421315e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>linea</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>121068.0</td>\n",
       "      <td>3.258809e+04</td>\n",
       "      <td>4.091013e-08</td>\n",
       "      <td>16.138379</td>\n",
       "      <td>16.138379</td>\n",
       "      <td>22651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4282.896255</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>fraxtal</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>9.590000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.308326</td>\n",
       "      <td>24.308326</td>\n",
       "      <td>403.0</td>\n",
       "      <td>2.926409e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>unichain</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>40389.0</td>\n",
       "      <td>2.616902e+05</td>\n",
       "      <td>3.267941e-07</td>\n",
       "      <td>225.918355</td>\n",
       "      <td>225.918356</td>\n",
       "      <td>11506.0</td>\n",
       "      <td>9.941818e+09</td>\n",
       "      <td>17286.409511</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>scroll</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>21829.0</td>\n",
       "      <td>8.357274e+03</td>\n",
       "      <td>3.165665e-08</td>\n",
       "      <td>16.515600</td>\n",
       "      <td>16.515600</td>\n",
       "      <td>4846.0</td>\n",
       "      <td>3.022961e+08</td>\n",
       "      <td>245.796331</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arbitrum</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>1308099.0</td>\n",
       "      <td>1.579485e+06</td>\n",
       "      <td>1.360262e-06</td>\n",
       "      <td>958.562129</td>\n",
       "      <td>958.562131</td>\n",
       "      <td>354429.0</td>\n",
       "      <td>4.051124e+09</td>\n",
       "      <td>41028.034434</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2996 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      origin_key         dt  aa_last7d  app_fees_usd  costs_blobs_usd  \\\n",
       "2995        zora 2025-11-03        NaN           NaN              NaN   \n",
       "907          imx 2025-11-03        NaN           NaN              NaN   \n",
       "2722    unichain 2025-11-03        NaN           NaN              NaN   \n",
       "634     ethereum 2025-11-03        NaN           NaN              NaN   \n",
       "2813  worldchain 2025-11-03        NaN           NaN              NaN   \n",
       "...          ...        ...        ...           ...              ...   \n",
       "998        linea 2025-08-05   121068.0  3.258809e+04     4.091013e-08   \n",
       "635      fraxtal 2025-08-05     1350.0  9.590000e+02              NaN   \n",
       "2632    unichain 2025-08-05    40389.0  2.616902e+05     3.267941e-07   \n",
       "2178      scroll 2025-08-05    21829.0  8.357274e+03     3.165665e-08   \n",
       "0       arbitrum 2025-08-05  1308099.0  1.579485e+06     1.360262e-06   \n",
       "\n",
       "      costs_l1_usd  costs_total_usd       daa       fdv_usd  fees_paid_usd  \\\n",
       "2995           NaN              NaN       NaN  6.783436e+08            NaN   \n",
       "907            NaN              NaN       NaN  1.019553e+09            NaN   \n",
       "2722           NaN              NaN       NaN  5.861856e+09            NaN   \n",
       "634            NaN              NaN       NaN           NaN            NaN   \n",
       "2813           NaN              NaN       NaN  8.421315e+09            NaN   \n",
       "...            ...              ...       ...           ...            ...   \n",
       "998      16.138379        16.138379   22651.0           NaN    4282.896255   \n",
       "635      24.308326        24.308326     403.0  2.926409e+08            NaN   \n",
       "2632    225.918355       225.918356   11506.0  9.941818e+09   17286.409511   \n",
       "2178     16.515600        16.515600    4846.0  3.022961e+08     245.796331   \n",
       "0       958.562129       958.562131  354429.0  4.051124e+09   41028.034434   \n",
       "\n",
       "      ...  costs_l1_eth  costs_total_eth  fdv_eth  fees_paid_eth  \\\n",
       "2995  ...           NaN              NaN      NaN            NaN   \n",
       "907   ...           NaN              NaN      NaN            NaN   \n",
       "2722  ...           NaN              NaN      NaN            NaN   \n",
       "634   ...           NaN              NaN      NaN            NaN   \n",
       "2813  ...           NaN              NaN      NaN            NaN   \n",
       "...   ...           ...              ...      ...            ...   \n",
       "998   ...           NaN              NaN      NaN            NaN   \n",
       "635   ...           NaN              NaN      NaN            NaN   \n",
       "2632  ...           NaN              NaN      NaN            NaN   \n",
       "2178  ...           NaN              NaN      NaN            NaN   \n",
       "0     ...           NaN              NaN      NaN            NaN   \n",
       "\n",
       "      market_cap_eth  profit_eth  rent_paid_eth  txcosts_median_eth tvl_eth  \\\n",
       "2995             NaN         NaN            NaN                 NaN     NaN   \n",
       "907              NaN         NaN            NaN                 NaN     NaN   \n",
       "2722             NaN         NaN            NaN                 NaN     NaN   \n",
       "634              NaN         NaN            NaN                 NaN     NaN   \n",
       "2813             NaN         NaN            NaN                 NaN     NaN   \n",
       "...              ...         ...            ...                 ...     ...   \n",
       "998              NaN         NaN            NaN                 NaN     NaN   \n",
       "635              NaN         NaN            NaN                 NaN     NaN   \n",
       "2632             NaN         NaN            NaN                 NaN     NaN   \n",
       "2178             NaN         NaN            NaN                 NaN     NaN   \n",
       "0                NaN         NaN            NaN                 NaN     NaN   \n",
       "\n",
       "      stables_mcap_eth  \n",
       "2995               NaN  \n",
       "907                NaN  \n",
       "2722               NaN  \n",
       "634                NaN  \n",
       "2813               NaN  \n",
       "...                ...  \n",
       "998                NaN  \n",
       "635                NaN  \n",
       "2632               NaN  \n",
       "2178               NaN  \n",
       "0                  NaN  \n",
       "\n",
       "[2996 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_gtp_df.sort_values(by='dt', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 16:53:51,453 INFO root Attempt 1: Using service account credentials\n",
      "2025-11-03 16:53:51,454 WARNING root Service account init failed on attempt 1: [Errno 2] No such file or directory: '/Users/michaelsilberling/Documents/bq/oplabs-tools-data-0842f34ceb69.json'\n",
      "2025-11-03 16:53:51,454 INFO root Attempt 1: Using ADC/OIDC login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Writing api_table_uploads.l2beat_l2_metadata\n",
      "DataFrame columns: {'category', 'is_upcoming', 'websites', 'documentation', 'is_current_chain', 'layer', 'is_archived', 'explorerUrl', 'chainId', 'name', 'badges', 'provider_entity', 'slug', 'file_name', 'repositories', 'chain', 'provider', 'rpcUrl', 'hostChain', 'da_provider_name'}\n",
      "Schema columns: {'category', 'is_upcoming', 'websites', 'documentation', 'is_current_chain', 'layer', 'is_archived', 'explorerUrl', 'chainId', 'name', 'badges', 'provider_entity', 'slug', 'isArchived', 'file_name', 'repositories', 'chain', 'provider', 'rpcUrl', 'hostChain', 'da_provider_name'}\n",
      "Error on attempt 1: Schema mismatch. Missing: {'isArchived'}, Extra: set()\n",
      "Waiting before retry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 16:53:53,683 INFO root Attempt 1: Using service account credentials\n",
      "2025-11-03 16:53:53,684 WARNING root Service account init failed on attempt 1: [Errno 2] No such file or directory: '/Users/michaelsilberling/Documents/bq/oplabs-tools-data-0842f34ceb69.json'\n",
      "2025-11-03 16:53:53,685 INFO root Attempt 1: Using ADC/OIDC login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: {'category', 'is_upcoming', 'websites', 'documentation', 'is_current_chain', 'layer', 'is_archived', 'explorerUrl', 'chainId', 'name', 'badges', 'provider_entity', 'slug', 'file_name', 'repositories', 'chain', 'provider', 'rpcUrl', 'hostChain', 'da_provider_name'}\n",
      "Schema columns: {'category', 'is_upcoming', 'websites', 'documentation', 'is_current_chain', 'layer', 'is_archived', 'explorerUrl', 'chainId', 'name', 'badges', 'provider_entity', 'slug', 'isArchived', 'file_name', 'repositories', 'chain', 'provider', 'rpcUrl', 'hostChain', 'da_provider_name'}\n",
      "Error on attempt 2: Schema mismatch. Missing: {'isArchived'}, Extra: set()\n",
      "Waiting before retry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 16:53:56,564 INFO root Attempt 1: Using service account credentials\n",
      "2025-11-03 16:53:56,565 WARNING root Service account init failed on attempt 1: [Errno 2] No such file or directory: '/Users/michaelsilberling/Documents/bq/oplabs-tools-data-0842f34ceb69.json'\n",
      "2025-11-03 16:53:56,566 INFO root Attempt 1: Using ADC/OIDC login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: {'category', 'is_upcoming', 'websites', 'documentation', 'is_current_chain', 'layer', 'is_archived', 'explorerUrl', 'chainId', 'name', 'badges', 'provider_entity', 'slug', 'file_name', 'repositories', 'chain', 'provider', 'rpcUrl', 'hostChain', 'da_provider_name'}\n",
      "Schema columns: {'category', 'is_upcoming', 'websites', 'documentation', 'is_current_chain', 'layer', 'is_archived', 'explorerUrl', 'chainId', 'name', 'badges', 'provider_entity', 'slug', 'isArchived', 'file_name', 'repositories', 'chain', 'provider', 'rpcUrl', 'hostChain', 'da_provider_name'}\n",
      "Error on attempt 3: Schema mismatch. Missing: {'isArchived'}, Extra: set()\n",
      "All attempts failed\n",
      "An error occurred: Schema mismatch. Missing: {'isArchived'}, Extra: set()\n",
      "Exception type: ValueError\n",
      "Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/nl/qcdk9wr515b2h3s1kd4z08w80000gn/T/ipykernel_73475/4389974.py\", line 3, in <module>\n",
      "    bqu.write_df_to_bq_table(l2beat_meta, \"l2beat_l2_metadata\")\n",
      "  File \"/Users/michael/Documents/GitHub/op-analytics/other_chains_tracking/../helper_functions/google_bq_utils.py\", line 322, in write_df_to_bq_table\n",
      "    validate_schema(chunk_df, schema)\n",
      "  File \"/Users/michael/Documents/GitHub/op-analytics/other_chains_tracking/../helper_functions/google_bq_utils.py\", line 204, in validate_schema\n",
      "    raise ValueError(f\"Schema mismatch. Missing: {missing}, Extra: {extra}\")\n",
      "ValueError: Schema mismatch. Missing: {'isArchived'}, Extra: set()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BQ Upload\n",
    "try:\n",
    "    bqu.write_df_to_bq_table(l2beat_meta, \"l2beat_l2_metadata\")\n",
    "    # time.sleep(1)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(f\"Exception type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 16:54:06,644 INFO root Attempt 1: Using service account credentials\n",
      "2025-11-03 16:54:06,645 WARNING root Service account init failed on attempt 1: [Errno 2] No such file or directory: '/Users/michaelsilberling/Documents/bq/oplabs-tools-data-0842f34ceb69.json'\n",
      "2025-11-03 16:54:06,645 INFO root Attempt 1: Using ADC/OIDC login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Writing api_table_uploads.daily_growthepie_l2_activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/google/cloud/bigquery/_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/1 loaded successfully to api_table_uploads.daily_growthepie_l2_activity\n",
      "All data loaded successfully to api_table_uploads.daily_growthepie_l2_activity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 16:54:11,552 INFO root Attempt 1: Using service account credentials\n",
      "2025-11-03 16:54:11,552 WARNING root Service account init failed on attempt 1: [Errno 2] No such file or directory: '/Users/michaelsilberling/Documents/bq/oplabs-tools-data-0842f34ceb69.json'\n",
      "2025-11-03 16:54:11,553 INFO root Attempt 1: Using ADC/OIDC login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Writing api_table_uploads.growthepie_l2_metadata\n",
      "DataFrame columns: {'technology', 'excluded_metrics', 'gas_token', 'twitter', 'rhino_naming', 'supported_metrics', 'l2beat_id', 'website', 'colors', 'symbol', 'similar_chains', 'links', 'logo', 'evm_chain_id', 'rhino_listed', 'tab_status', 'description', 'bucket', 'chain_name', 'stack', 'raas', 'name', 'block_explorer', 'l2beat_stage', 'origin_key', 'enable_contracts', 'maturity', 'da_layer', 'l2beat_link', 'block_explorers', 'url_key', 'deployment', 'chain_type', 'ecosystem', 'caip2', 'company', 'launch_date', 'purpose'}\n",
      "Schema columns: {'technology', 'twitter', 'excluded_metrics', 'gas_token', 'rhino_naming', 'supported_metrics', 'l2beat_id', 'website', 'colors', 'symbol', 'similar_chains', 'links', 'logo', 'active_tabs', 'evm_chain_id', 'rhino_listed', 'tab_status', 'description', 'bucket', 'chain_name', 'stack', 'raas', 'name', 'block_explorer', 'l2beat_stage', 'origin_key', 'enable_contracts', 'maturity', 'da_layer', 'l2beat_link', 'block_explorers', 'url_key', 'deployment', 'chain_type', 'ecosystem', 'caip2', 'company', 'launch_date', 'purpose'}\n",
      "Error on attempt 1: Schema mismatch. Missing: {'active_tabs'}, Extra: set()\n",
      "Waiting before retry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 16:54:13,445 INFO root Attempt 1: Using service account credentials\n",
      "2025-11-03 16:54:13,446 WARNING root Service account init failed on attempt 1: [Errno 2] No such file or directory: '/Users/michaelsilberling/Documents/bq/oplabs-tools-data-0842f34ceb69.json'\n",
      "2025-11-03 16:54:13,447 INFO root Attempt 1: Using ADC/OIDC login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: {'technology', 'excluded_metrics', 'gas_token', 'twitter', 'rhino_naming', 'supported_metrics', 'l2beat_id', 'website', 'colors', 'symbol', 'similar_chains', 'links', 'logo', 'evm_chain_id', 'rhino_listed', 'tab_status', 'description', 'bucket', 'chain_name', 'stack', 'raas', 'name', 'block_explorer', 'l2beat_stage', 'origin_key', 'enable_contracts', 'maturity', 'da_layer', 'l2beat_link', 'block_explorers', 'url_key', 'deployment', 'chain_type', 'ecosystem', 'caip2', 'company', 'launch_date', 'purpose'}\n",
      "Schema columns: {'technology', 'twitter', 'excluded_metrics', 'gas_token', 'rhino_naming', 'supported_metrics', 'l2beat_id', 'website', 'colors', 'symbol', 'similar_chains', 'links', 'logo', 'active_tabs', 'evm_chain_id', 'rhino_listed', 'tab_status', 'description', 'bucket', 'chain_name', 'stack', 'raas', 'name', 'block_explorer', 'l2beat_stage', 'origin_key', 'enable_contracts', 'maturity', 'da_layer', 'l2beat_link', 'block_explorers', 'url_key', 'deployment', 'chain_type', 'ecosystem', 'caip2', 'company', 'launch_date', 'purpose'}\n",
      "Error on attempt 2: Schema mismatch. Missing: {'active_tabs'}, Extra: set()\n",
      "Waiting before retry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 16:54:16,388 INFO root Attempt 1: Using service account credentials\n",
      "2025-11-03 16:54:16,389 WARNING root Service account init failed on attempt 1: [Errno 2] No such file or directory: '/Users/michaelsilberling/Documents/bq/oplabs-tools-data-0842f34ceb69.json'\n",
      "2025-11-03 16:54:16,389 INFO root Attempt 1: Using ADC/OIDC login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: {'technology', 'excluded_metrics', 'gas_token', 'twitter', 'rhino_naming', 'supported_metrics', 'l2beat_id', 'website', 'colors', 'symbol', 'similar_chains', 'links', 'logo', 'evm_chain_id', 'rhino_listed', 'tab_status', 'description', 'bucket', 'chain_name', 'stack', 'raas', 'name', 'block_explorer', 'l2beat_stage', 'origin_key', 'enable_contracts', 'maturity', 'da_layer', 'l2beat_link', 'block_explorers', 'url_key', 'deployment', 'chain_type', 'ecosystem', 'caip2', 'company', 'launch_date', 'purpose'}\n",
      "Schema columns: {'technology', 'twitter', 'excluded_metrics', 'gas_token', 'rhino_naming', 'supported_metrics', 'l2beat_id', 'website', 'colors', 'symbol', 'similar_chains', 'links', 'logo', 'active_tabs', 'evm_chain_id', 'rhino_listed', 'tab_status', 'description', 'bucket', 'chain_name', 'stack', 'raas', 'name', 'block_explorer', 'l2beat_stage', 'origin_key', 'enable_contracts', 'maturity', 'da_layer', 'l2beat_link', 'block_explorers', 'url_key', 'deployment', 'chain_type', 'ecosystem', 'caip2', 'company', 'launch_date', 'purpose'}\n",
      "Error on attempt 3: Schema mismatch. Missing: {'active_tabs'}, Extra: set()\n",
      "All attempts failed\n",
      "An error occurred: Schema mismatch. Missing: {'active_tabs'}, Extra: set()\n",
      "Exception type: ValueError\n",
      "Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/nl/qcdk9wr515b2h3s1kd4z08w80000gn/T/ipykernel_73475/3328187188.py\", line 6, in <module>\n",
      "    bqu.write_df_to_bq_table(gtp_meta_api, \"growthepie_l2_metadata\")\n",
      "  File \"/Users/michael/Documents/GitHub/op-analytics/other_chains_tracking/../helper_functions/google_bq_utils.py\", line 322, in write_df_to_bq_table\n",
      "    validate_schema(chunk_df, schema)\n",
      "  File \"/Users/michael/Documents/GitHub/op-analytics/other_chains_tracking/../helper_functions/google_bq_utils.py\", line 204, in validate_schema\n",
      "    raise ValueError(f\"Schema mismatch. Missing: {missing}, Extra: {extra}\")\n",
      "ValueError: Schema mismatch. Missing: {'active_tabs'}, Extra: set()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if not combined_gtp_df.empty:\n",
    "        bqu.write_df_to_bq_table(combined_gtp_df, \"daily_growthepie_l2_activity\")\n",
    "        time.sleep(1)\n",
    "    if not gtp_meta_api.empty:\n",
    "        bqu.write_df_to_bq_table(gtp_meta_api, \"growthepie_l2_metadata\")\n",
    "        time.sleep(1)\n",
    "# bqu.write_df_to_bq_table(l2b_enriched_df, \"daily_l2beat_l2_activity\")\n",
    "# time.sleep(1)\n",
    "# bqu.write_df_to_bq_table(l2b_monthly_df, \"monthly_l2beat_l2_activity\")\n",
    "# time.sleep(1)\n",
    "# bqu.write_df_to_bq_table(l2b_weekly_df, \"weekly_l2beat_l2_activity\")\n",
    "# time.sleep(1)\n",
    "# bqu.append_and_upsert_df_to_bq_table(\n",
    "#     l2beat_aoc,\n",
    "#     \"daily_l2beat_aoc_by_token\",\n",
    "#     unique_keys=[\"dt\", \"chain\", \"token_type\", \"asset_id\", \"chain\", \"address\"],\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(f\"Exception type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post to Dune API\n",
    "try:\n",
    "    if not combined_gtp_df.empty:\n",
    "        d.write_dune_api_from_pandas(\n",
    "            combined_gtp_df, \"growthepie_l2_activity\", \"L2 Usage Activity from GrowThePie\"\n",
    "        )\n",
    "    if not gtp_meta_api.empty:\n",
    "        d.write_dune_api_from_pandas(\n",
    "            gtp_meta_api, \"growthepie_l2_metadata\", \"L2 Metadata from GrowThePie\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(f\"Exception type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())\n",
    "# d.write_dune_api_from_pandas(\n",
    "#     l2b_enriched_df, \"l2beat_l2_activity\", \"L2 Usage Activity from L2Beat\"\n",
    "# )\n",
    "# d.write_dune_api_from_pandas(\n",
    "#     l2b_monthly_df,\n",
    "#     \"l2beat_l2_activity_monthly\",\n",
    "#     \"Monthly L2 Usage Activity from L2Beat\",\n",
    "# )\n",
    "# d.write_dune_api_from_pandas(\n",
    "#     l2b_weekly_df, \"l2beat_l2_activity_weekly\", \"Weekly L2 Usage Activity from L2Beat\"\n",
    "# )\n",
    "# d.write_dune_api_from_pandas(\n",
    "#     l2beat_meta, \"l2beat_l2_metadata\", \"L2 Metadata from L2Beat\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to Dune\n",
    "print('upload bq to dune')\n",
    "sql = '''\n",
    "SELECT *\n",
    "FROM `views.daily_l2beat_breakdown`\n",
    "WHERE onchain_value_usd > 0\n",
    "AND dt_day >= DATE_SUB(CURRENT_DATE(), INTERVAL 365 DAY)\n",
    "'''\n",
    "bq_df = bqu.run_query_to_df(sql)\n",
    "\n",
    "dune_table_name = 'daily_l2beat_breakdown'\n",
    "d.write_dune_api_from_pandas(bq_df, dune_table_name,table_description = dune_table_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
