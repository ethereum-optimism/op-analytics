{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start l2 activity\")\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "import growthepieapi_utils as gtp\n",
    "import l2beat_utils as ltwo\n",
    "import csv_utils as cu\n",
    "import google_bq_utils as bqu\n",
    "import pandas_utils as pu\n",
    "import clickhouse_utils as ch\n",
    "\n",
    "sys.path.pop()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Usage\n",
    "gtp_api = gtp.get_growthepie_api_data()\n",
    "gtp_meta_api = gtp.get_growthepie_api_meta()\n",
    "gtp_api = gtp_api.rename(columns={\"date\": \"dt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update datatype for bq uploads\n",
    "if \"enable_contracts\" in gtp_meta_api:\n",
    "    gtp_meta_api[\"enable_contracts\"] = gtp_meta_api[\"enable_contracts\"].astype(bool)\n",
    "\n",
    "if \"colors\" in gtp_meta_api:\n",
    "    gtp_meta_api[\"colors\"] = gtp_meta_api[\"colors\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtp_meta_api.sample(10)\n",
    "# gtp_meta_api.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"getting assets onchain - l2beat\")\n",
    "l2beat_aoc = ltwo.get_daily_aoc_by_token()\n",
    "l2beat_aoc = l2beat_aoc.rename(columns={\"project\": \"chain\", \"date\": \"dt\"})\n",
    "time.sleep(3)  # rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"getting data - l2beat\")\n",
    "l2beat_df = ltwo.get_all_l2beat_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"getting metadata - l2beat\")\n",
    "l2beat_meta = ltwo.get_l2beat_metadata()\n",
    "l2beat_meta[\"chain\"] = l2beat_meta[\"slug\"]\n",
    "l2beat_meta[\"is_upcoming\"] = l2beat_meta[\"is_upcoming\"].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2beat_meta[l2beat_meta['chainId'] == '388']\n",
    "# # l2beat_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_l2b_df = l2beat_df.merge(\n",
    "    l2beat_meta[\n",
    "        [\n",
    "            \"chain\",\n",
    "            \"name\",\n",
    "            \"layer\",\n",
    "            \"chainId\",\n",
    "            \"provider\",\n",
    "            \"provider_entity\",\n",
    "            \"category\",\n",
    "            \"is_upcoming\",\n",
    "            \"is_archived\",\n",
    "            \"is_current_chain\",\n",
    "        ]\n",
    "    ],\n",
    "    on=\"chain\",\n",
    "    how=\"outer\",\n",
    ")\n",
    "\n",
    "combined_l2b_df[\"chainId\"] = combined_l2b_df[\"chainId\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"getting data - growthepie\")\n",
    "combined_gtp_df = gtp_api.merge(\n",
    "    gtp_meta_api[[\"origin_key\", \"chain_name\", \"evm_chain_id\"]],\n",
    "    on=\"origin_key\",\n",
    "    how=\"left\",\n",
    ")\n",
    "combined_gtp_df[\"dt\"] = pd.to_datetime(combined_gtp_df[\"dt\"], errors=\"coerce\")\n",
    "\n",
    "combined_gtp_df = combined_gtp_df.drop(columns=(\"index\"))\n",
    "# combined_gtp_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Columns\n",
    "# Assuming combined_gtp_df is your DataFrame\n",
    "column_names = combined_gtp_df.columns\n",
    "\n",
    "for col in column_names:\n",
    "    if col.endswith(\"_usd\"):\n",
    "        # Construct the new column name by replacing '_usd' with '_eth'\n",
    "        new_col_name = col.replace(\"_usd\", \"_eth\")\n",
    "\n",
    "        # Check if the new column name exists in the DataFrame\n",
    "        if new_col_name not in combined_gtp_df.columns:\n",
    "            # If it doesn't exist, create the column and fill it with nan values\n",
    "            combined_gtp_df[new_col_name] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Metadata\n",
    "opstack_metadata = opstack_metadata = pd.read_csv(\n",
    "    \"../op_chains_tracking/outputs/chain_metadata.csv\"\n",
    ")\n",
    "combined_l2b_df[\"l2beat_slug\"] = combined_l2b_df[\"chain\"]\n",
    "meta_cols = [\n",
    "    \"l2beat_slug\",\n",
    "    \"is_op_chain\",\n",
    "    \"mainnet_chain_id\",\n",
    "    \"op_based_version\",\n",
    "    \"alignment\",\n",
    "    \"chain_name\",\n",
    "    \"display_name\",\n",
    "]\n",
    "\n",
    "l2b_enriched_df = combined_l2b_df.merge(\n",
    "    opstack_metadata[meta_cols], on=\"l2beat_slug\", how=\"left\"\n",
    ")\n",
    "\n",
    "l2b_enriched_df[\"alignment\"] = l2b_enriched_df[\"alignment\"].fillna(\"Other EVMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = [\"is_op_chain\", \"is_upcoming\", \"is_archived\", \"is_current_chain\"]\n",
    "dfs = [l2b_enriched_df, l2beat_meta]\n",
    "\n",
    "for df in dfs:\n",
    "    for column in boolean_columns:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define aggregation functions for each column\n",
    "aggregations = {\n",
    "    \"totalUsd\": [\"min\", \"last\", \"mean\"],  # valueUsd\n",
    "    \"transactions\": [\"sum\", \"mean\"],\n",
    "    \"canonicalUsd\": [\"min\", \"last\", \"mean\"],  # cbvUsd\n",
    "    \"externalUsd\": [\"min\", \"last\", \"mean\"],  # ebvUsd\n",
    "    \"nativeUsd\": [\"min\", \"last\", \"mean\"],  # nmvUsd\n",
    "}\n",
    "\n",
    "\n",
    "# Function to perform aggregation based on frequency\n",
    "def aggregate_data(df, freq, date_col=\"timestamp\", groupby_cols=None, aggs=None):\n",
    "    if groupby_cols is None:\n",
    "        groupby_cols = [\n",
    "            \"chain\",\n",
    "            \"chainId\",\n",
    "            \"layer\",\n",
    "            \"is_op_chain\",\n",
    "            \"mainnet_chain_id\",\n",
    "            \"op_based_version\",\n",
    "            \"alignment\",\n",
    "            \"chain_name\",\n",
    "            \"display_name\",\n",
    "            \"provider\",\n",
    "            \"is_upcoming\",\n",
    "            \"is_archived\",\n",
    "            \"is_current_chain\",\n",
    "        ]\n",
    "    if aggs is None:\n",
    "        aggs = aggregations\n",
    "\n",
    "    # Group by the specified frequency and other columns, then apply aggregations\n",
    "    df_agg = (\n",
    "        df.groupby([pd.Grouper(key=date_col, freq=freq)] + groupby_cols, dropna=False)\n",
    "        .agg(aggs)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Flatten the hierarchical column index and concatenate aggregation function names with column names\n",
    "    df_agg.columns = [\"_\".join(filter(None, col)).rstrip(\"_\") for col in df_agg.columns]\n",
    "\n",
    "    # Rename the 'timestamp' column based on the frequency\n",
    "    date_col_name = \"month\" if freq == \"MS\" else \"week\"\n",
    "    df_agg.rename(columns={date_col: date_col_name}, inplace=True)\n",
    "\n",
    "    # Group by 'chain' and rank the rows within each group based on the date column\n",
    "    df_agg[f\"{date_col_name}s_live\"] = df_agg.groupby(\"chain\")[date_col_name].rank(\n",
    "        method=\"min\"\n",
    "    )\n",
    "\n",
    "    return df_agg\n",
    "\n",
    "\n",
    "# Perform monthly aggregation\n",
    "l2b_monthly_df = aggregate_data(l2b_enriched_df, freq=\"MS\")\n",
    "# Perform weekly aggregation\n",
    "l2b_weekly_df = aggregate_data(l2b_enriched_df, freq=\"W-MON\")\n",
    "\n",
    "# Sample output\n",
    "# l2b_weekly_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "folder = \"outputs/\"\n",
    "combined_gtp_df.to_csv(folder + \"growthepie_l2_activity.csv\", index=False)\n",
    "gtp_meta_api.to_csv(folder + \"growthepie_l2_metadata.csv\", index=False)\n",
    "l2b_enriched_df.to_csv(folder + \"l2beat_l2_activity.csv\", index=False)\n",
    "l2beat_meta.to_csv(folder + \"l2beat_l2_metadata.csv\", index=False)\n",
    "l2b_monthly_df.to_csv(folder + \"l2beat_l2_activity_monthly.csv\", index=False)\n",
    "l2b_weekly_df.to_csv(folder + \"l2beat_l2_activity_weekly.csv\", index=False)\n",
    "l2beat_aoc.to_csv(folder + \"l2beat_aoc_by_token.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BQ Upload\n",
    "bqu.write_df_to_bq_table(l2beat_meta, \"l2beat_l2_metadata\")\n",
    "time.sleep(1)\n",
    "bqu.write_df_to_bq_table(combined_gtp_df, \"daily_growthepie_l2_activity\")\n",
    "time.sleep(1)\n",
    "bqu.write_df_to_bq_table(gtp_meta_api, \"growthepie_l2_metadata\")\n",
    "time.sleep(1)\n",
    "bqu.write_df_to_bq_table(l2b_enriched_df, \"daily_l2beat_l2_activity\")\n",
    "time.sleep(1)\n",
    "bqu.write_df_to_bq_table(l2b_monthly_df, \"monthly_l2beat_l2_activity\")\n",
    "time.sleep(1)\n",
    "bqu.write_df_to_bq_table(l2b_weekly_df, \"weekly_l2beat_l2_activity\")\n",
    "time.sleep(1)\n",
    "bqu.append_and_upsert_df_to_bq_table(\n",
    "    l2beat_aoc,\n",
    "    \"daily_l2beat_aoc_by_token\",\n",
    "    unique_keys=[\"dt\", \"chain\", \"token_type\", \"asset_id\", \"chain\", \"address\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2beat_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post to Dune API\n",
    "d.write_dune_api_from_pandas(\n",
    "    combined_gtp_df, \"growthepie_l2_activity\", \"L2 Usage Activity from GrowThePie\"\n",
    ")\n",
    "d.write_dune_api_from_pandas(\n",
    "    gtp_meta_api, \"growthepie_l2_metadata\", \"L2 Metadata from GrowThePie\"\n",
    ")\n",
    "d.write_dune_api_from_pandas(\n",
    "    l2b_enriched_df, \"l2beat_l2_activity\", \"L2 Usage Activity from L2Beat\"\n",
    ")\n",
    "d.write_dune_api_from_pandas(\n",
    "    l2b_monthly_df,\n",
    "    \"l2beat_l2_activity_monthly\",\n",
    "    \"Monthly L2 Usage Activity from L2Beat\",\n",
    ")\n",
    "d.write_dune_api_from_pandas(\n",
    "    l2b_weekly_df, \"l2beat_l2_activity_weekly\", \"Weekly L2 Usage Activity from L2Beat\"\n",
    ")\n",
    "d.write_dune_api_from_pandas(\n",
    "    l2beat_meta, \"l2beat_l2_metadata\", \"L2 Metadata from L2Beat\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
