version: 2.1

orbs:
  gcp-cli: circleci/gcp-cli@3.0.1
  utils: ethereum-optimism/circleci-utils@0.0.11

parameters:
  run_job:
    type: enum
    default: "select_job"
    enum:
      [
        "select_job",
        "run_daily_api_upload",
        "daily_l2_aggregate_later_loads",
        "daily_l2_chain_data_uploads",
        "deploy_github_pages",
      ]

commands:
  setup-python-env:
    steps:
      - run:
          name: Install uv
          command: |
            curl -LsSf https://astral.sh/uv/install.sh | sh
      - run:
          name: Set up Python
          command: uv python install
      - run:
          name: Install project dependencies
          command: uv sync --all-extras --dev

  setup-python-3-10:
    steps:
      - run:
          name: Setup Python 3.10
          command: |
            if [ ! -d "~/miniconda3" ]; then
                wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
                bash Miniconda3-latest-Linux-x86_64.sh -b
            fi
            export PATH=$HOME/miniconda3/bin:$PATH
            ~/miniconda3/bin/conda create -n py310 python=3.10 -y
            echo "Python 3.10 environment setup complete"

  checkout-dep-1:
    parameters:
      base_git_project:
        type: string
        default: "."
    steps:
      - run:
          name: Clone repository and checkout branch with depth 1
          command: |
            git clone --depth 1 "$CIRCLE_REPOSITORY_URL" --branch "$CIRCLE_BRANCH" << parameters.base_git_project >>
            echo "Cloned repository folder name: << parameters.base_git_project >>"
  setup-python-3-10-project-dependencies:
    parameters:
      base_git_project:
        type: string
        default: "."
    steps:
      - run:
          name: Install Python 3.10 dependencies
          command: |
            cd "<< parameters.base_git_project >>"
            source ~/miniconda3/bin/activate py310
            python --version
            python -m pip install pipenv
            python -m pipenv install

jobs:
  setup-python-3-10-job:
    machine:
      image: ubuntu-2004:current
    steps:
      - checkout-dep-1:
          base_git_project: "op-analytics"
      - setup-python-3-10
      - setup-python-3-10-project-dependencies:
          base_git_project: "op-analytics"
      - persist_to_workspace:
          root: ~/
          paths:
            - miniconda3
            - .local

  convert-and-run-notebooks-to-py:
    description: "Convert and run notebooks to Python scripts"
    machine:
      image: ubuntu-2004:current
    parameters:
      notebook_paths:
        type: string
    steps:
      - attach_workspace:
          at: ~/
      - utils/gcp-oidc-authenticate:
          project_id: GCP_PROJECT_ID
          service_account_email: GCP_SERVICE_ACCOUNT_EMAIL
          workload_identity_pool_id: GCP_WIP_ID
          workload_identity_pool_provider_id: GCP_WIP_PROVIDER_ID
      - checkout-dep-1:
          base_git_project: "op-analytics"
      - run:
          name: Generate and run Python scripts
          command: |
            export PATH=~/miniconda3/bin:$PATH
            source ~/miniconda3/bin/activate py310

            cd "op-analytics"

            notebook_path="<< parameters.notebook_paths >>.ipynb"
            py_script_path="<< parameters.notebook_paths >>.py"
            directory=$(dirname "$notebook_path")
            cd $directory

            echo "Converting $notebook_path to $py_script_path"
            python -m pipenv run jupyter nbconvert --to python $(basename ${notebook_path})

            echo "Run $py_script_path"
            python -m pipenv run python $(basename ${py_script_path})

  convert-and-run-notebooks-to-py-and-push:
    description: "Convert and run notebooks to Python scripts and push changes to GitHub"
    parameters:
      notebook-paths:
        type: string
      commit-message:
        type: string
    machine:
      image: ubuntu-2004:current
    steps:
      - utils/gcp-oidc-authenticate:
          project_id: GCP_PROJECT_ID
          service_account_email: GCP_SERVICE_ACCOUNT_EMAIL
          workload_identity_pool_id: GCP_WIP_ID
          workload_identity_pool_provider_id: GCP_WIP_PROVIDER_ID
      - checkout-dep-1:
          base_git_project: "op-analytics"
      - setup-python-3-10
      - setup-python-3-10-project-dependencies:
          base_git_project: "op-analytics"
      - run:
          name: Generate and run Python scripts
          command: |
            export PATH=~/miniconda3/bin:$PATH
            source ~/miniconda3/bin/activate py310

            cd "op-analytics"

            echo '<< parameters.notebook-paths >>' | jq -c '.[]' | while read -r notebook; do
              dir=$(echo $notebook | jq -r '.dir')
              notebook=$(echo $notebook | jq -r '.notebook')

              cd "$dir"

              echo "Converting ${notebook}.ipynb to ${notebook}.py"
              python -m pipenv run jupyter nbconvert --to python ${notebook}.ipynb

              echo "Run ${notebook}.py"
              python -m pipenv run python ${notebook}.py

              cd - >/dev/null
            done

      - utils/get-github-access-token
      - utils/github-commit-and-push-changes:
          commit-message: "<< parameters.commit-message >>"
          skip-ci: true
          folder: "op-analytics"

  deploy-github-pages:
    machine:
      image: ubuntu-2004:current
    steps:
      - checkout-dep-1
      - setup-python-env
      - run:
          name: Build Static Content
          command: make html
      # Copy directories to serve
      - run:
          name: Copy Directories To Serve
          command: |
            #this copies everything from the build directory to the docs directory
            make html-copies
            tmp_dir="/tmp/docs"
            mkdir -p $tmp_dir
            cp -r docs/* $tmp_dir
            touch $tmp_dir/.nojekyll

      - utils/get-github-access-token
      - utils/github-pages-deploy:
          force-push: true
          src-pages-dir: /tmp/docs

  daily-uploads-other-tasks:
    machine:
      image: ubuntu-2004:current
    steps:
      - checkout-dep-1
      - setup-python-env
      - run:
          name: L2Beat
          command: uv run opdata pulls l2beat
          environment:
            OPLABS_RUNTIME: "gha"
            OPLABS_ENV: "prod"

workflows:
  version: 2
  run-daily-api-uploads:
    when:
      or:
        - equal: [<< pipeline.parameters.run_job >>, "run_daily_api_upload"]
        - equal: [<< pipeline.schedule.name >>, "run_daily_api_upload"]
    jobs:
      - daily-uploads-other-tasks:
          context: op-analytics
          filters:
            branches:
              only: main


  daily-l2-aggregate-later-loads:
    # when:
    #   or:
    #     - equal:
    #         [<< pipeline.schedule.name >>, "daily_l2_aggregate_later_loads"]
    #     - equal:
    #         [
    #           << pipeline.parameters.run_job >>,
    #           "daily_l2_aggregate_later_loads",
    #         ]
    jobs:
      - convert-and-run-notebooks-to-py-and-push:
          commit-message: "GH Action Update - Agg Downloads"
          notebook-paths: >-
            [
              {"dir": "op_chains_tracking", "notebook": "dune_opchain_uploads"},
              {"dir": "other_chains_tracking", "notebook": "get_filtered_deployers"},
              {"dir": "other_chains_tracking", "notebook": "total_chain_data_to_uploads"}
            ]
          context:
            - op-analytics-legacy
            - circleci-repo-op-analytics
            - op-analytics-gcp

  daily_l2_chain_data_uploads:
    when:
      or:
        - equal: [<< pipeline.schedule.name >>, "daily_l2_chain_data_uploads"]
        - equal:
            [<< pipeline.parameters.run_job >>, "daily_l2_chain_data_uploads"]
    jobs:
      - setup-python-3-10-job
      - convert-and-run-notebooks-to-py:
          requires:
            - setup-python-3-10-job
          context:
            - op-analytics-legacy
            - circleci-repo-op-analytics
            - op-analytics-gcp
          matrix:
            parameters:
              notebook_paths:
                - other_chains_tracking/chain_tvl_trends
                - other_chains_tracking/pull_l2_activity
                - other_chains_tracking/get_ethereum_chain_list
                - other_chains_tracking/get_dune_evms_info
                - other_chains_tracking/get_qualified_txs
                - other_chains_tracking/get_all_txs
                - other_chains_tracking/get_contract_labels
                - op_chains_tracking/get_superchain_token_list
                - op_chains_tracking/ch_gs_uploads
                - op_chains_tracking/dune_op_stack_chains_l1_data
                - op_collective_economics/opcollective_feesplit/op_collective_revenue
                - op_collective_economics/get_op_collective_net_revenue_balances

  github-pages:
    when:
      or:
        - equal: [<< pipeline.parameters.run_job >>, "deploy_github_pages"]
        - equal: [<< pipeline.git.branch >>, "main"]
    jobs:
      - deploy-github-pages:
          context:
            - circleci-repo-op-analytics
            - op-analytics
          filters:
            branches:
              only: main
